This is R-exts.info, produced by makeinfo version 4.7 from R-exts.texi.

INFO-DIR-SECTION Programming
START-INFO-DIR-ENTRY
* R Extensions: (R-exts).      Writing R Extensions.
END-INFO-DIR-ENTRY

   This is a guide to extending R.

   Copyright (C) 1999-2009 R Development Core Team

   Permission is granted to make and distribute verbatim copies of this
manual provided the copyright notice and this permission notice are
preserved on all copies.

   Permission is granted to copy and distribute modified versions of
this manual under the conditions for verbatim copying, provided that the
entire resulting derived work is distributed under the terms of a
permission notice identical to this one.

   Permission is granted to copy and distribute translations of this
manual into another language, under the above conditions for modified
versions, except that this permission notice may be stated in a
translation approved by the R Development Core Team.


File: R-exts.info,  Node: Top,  Next: Acknowledgements,  Prev: (dir),  Up: (dir)

Writing R Extensions
********************

This is a guide to extending R, describing the process of creating R
add-on packages, writing R documentation, R's system and foreign
language interfaces, and the R API.

   The current version of this document is 2.10.1 (2009-12-14).

   ISBN 3-900051-11-9

* Menu:

* Acknowledgements::
* Creating R packages::
* Writing R documentation files::
* Tidying and profiling R code::
* Debugging::
* System and foreign language interfaces::
* The R API::
* Generic functions and methods::
* Linking GUIs and other front-ends to R::
* Function and variable index::
* Concept index::


File: R-exts.info,  Node: Acknowledgements,  Next: Creating R packages,  Prev: Top,  Up: Top

Acknowledgements
****************

The contributions of Saikat DebRoy (who wrote the first draft of a guide
to using `.Call' and `.External') and of Adrian Trapletti (who provided
information on the C++ interface) are gratefully acknowledged.


File: R-exts.info,  Node: Creating R packages,  Next: Writing R documentation files,  Prev: Acknowledgements,  Up: Top

1 Creating R packages
*********************

Packages provide a mechanism for loading optional code and attached
documentation as needed.  The R distribution provides several packages.

   In the following, we assume that you know the `library()' command,
including its `lib.loc' argument, and we also assume basic knowledge of
the `INSTALL' utility.  Otherwise, please look at R's help pages

     ?library
     ?INSTALL

before reading on.

   A computing environment including a number of tools is assumed; the
"R Installation and Administration" manual describes what is needed.
Under a Unix-alike most of the tools are likely to be present by
default, but Microsoft Windows and Mac OS X will require careful setup.

   Once a source package is created, it must be installed by the
command `R CMD INSTALL'.  *Note Add-on-packages: (R-admin)Add-on
packages, for further details.

   Other types of extensions are supported: *Note Package types::.

* Menu:

* Package structure::
* Configure and cleanup::
* Checking and building packages::
* Writing package vignettes::
* Submitting a package to CRAN::
* Package name spaces::
* Writing portable packages::
* Diagnostic messages::
* Internationalization::
* CITATION files::
* Package types::
* Services::


File: R-exts.info,  Node: Package structure,  Next: Configure and cleanup,  Prev: Creating R packages,  Up: Creating R packages

1.1 Package structure
=====================

A package consists of a subdirectory containing a file `DESCRIPTION'
and the subdirectories `R', `data', `demo', `exec', `inst', `man', `po',
`src', and `tests' (some of which can be missing).  The package
subdirectory may also contain files `INDEX', `NAMESPACE', `configure',
`cleanup', `LICENSE', `LICENCE', `COPYING' and `NEWS'.  Other files
such as `INSTALL' (for non-standard installation instructions),
`README' or `ChangeLog' will be ignored by R, but may be useful to
end-users.

   The `DESCRIPTION' and `INDEX' files are described in the sections
below.  The `NAMESPACE' file is described in *Note Package name
spaces::.

   The optional files `configure' and `cleanup' are (Bourne shell)
script files which are executed before and (provided that option
`--clean' was given) after installation on Unix-alikes, see *Note
Configure and cleanup::.  For use on Windows there may be analogues
`configure.win' and `cleanup.win'

   The optional file `LICENSE'/`LICENCE' or `COPYING' (where the former
names are preferred) contains a copy of the license to the package,
e.g. a copy of the GNU public license.  Whereas you should feel free to
include a license file in your source distribution, please do not
arrange to _install_ yet another copy of the GNU `COPYING' or
`COPYING.LIB' files but refer to the copies on
`http://www.r-project.org/Licenses/' and included in the R distribution
(in directory `share/licenses').

   For the conventions for files `NEWS' and `ChangeLog' in the GNU
project see
`http://www.gnu.org/prep/standards/standards.html#Documentation'.

   The package subdirectory should be given the same name as the
package.  Because some file systems (e.g., those on Windows and by
default on Mac OS X) are not case-sensitive, to maintain portability it
is strongly recommended that case distinctions not be used to
distinguish different packages.  For example, if you have a package
named `foo', do not also create a package named `Foo'.

   To ensure that file names are valid across file systems and supported
operating system platforms, the ASCII control characters as well as the
characters `"', `*', `:', `/', `<', `>', `?', `\', and `|' are not
allowed in file names.  In addition, files with names `con', `prn',
`aux', `clock$', `nul', `com1' to `com9', and `lpt1' to `lpt9' after
conversion to lower case and stripping possible "extensions" (e.g.,
`lpt5.foo.bar'), are disallowed.  Also, file names in the same
directory must not differ only by case (see the previous paragraph).
In addition, the names of `.Rd' files will be used in URLs and so must
be ASCII and not contain `%'.  For maximal portability filenames should
only contain only ASCII characters not excluded already (that is
`A-Za-z0-9._!#$%&+,;=@^(){}'[]' we exclude space as many utilities do
not accept spaces in file paths): non-English alphabetic characters
cannot be guaranteed to be supported in all locales.  It would be good
practice to avoid the shell metacharacters `(){}'[]$'.

   A source package if possible should not contain binary executable
files: they are not portable, and a security risk if they are of the
appropriate architecture.  `R CMD check' will warn about them(1) unless
they are listed (one filepath per line) in a file `BinaryFiles' at the
top level of the package.  Note that CRAN will no longer accept
submissions containing binary files even if they are listed.

   The R function `package.skeleton' can help to create the structure
for a new package: see its help page for details.

* Menu:

* The DESCRIPTION file::
* The INDEX file::
* Package subdirectories::
* Package bundles::
* Data in packages::

   ---------- Footnotes ----------

   (1) false positives are possible, but only one has been seen so far.


File: R-exts.info,  Node: The DESCRIPTION file,  Next: The INDEX file,  Prev: Package structure,  Up: Package structure

1.1.1 The `DESCRIPTION' file
----------------------------

The `DESCRIPTION' file contains basic information about the package in
the following format:

          Package: pkgname
          Version: 0.5-1
          Date: 2004-01-01
          Title: My First Collection of Functions
          Author: Joe Developer <Joe.Developer@some.domain.net>, with
            contributions from A. User <A.User@whereever.net>.
          Maintainer: Joe Developer <Joe.Developer@some.domain.net>
          Depends: R (>= 1.8.0), nlme
          Suggests: MASS
          Description: A short (one paragraph) description of what
            the package does and why it may be useful.
          License: GPL (>= 2)
          URL: http://www.r-project.org, http://www.another.url

The format is that of a `Debian Control File' (see the help for
`read.dcf').  Continuation lines (for example, for descriptions longer
than one line) start with a space or tab.  The `Package', `Version',
`License', `Description', `Title', `Author', and `Maintainer' fields
are mandatory, the remaining fields (`Date', `Depends', `URL', ...) are
optional.

   The `DESCRIPTION' file should be written entirely in ASCII for
maximal portability.

   The `Package' and `Version' fields give the name and the version of
the package, respectively.  The name should consist of letters,
numbers, and the dot character and start with a letter.  The version is
a sequence of at least _two_ (and usually three) non-negative integers
separated by single `.' or `-' characters.  The canonical form is as
shown in the example, and a version such as `0.01' or `0.01.0' will be
handled as if it were `0.1-0'.  (Translation packages are allowed names
of the form `Translation-LL'.)

   The `License' field should specify the license of the package in the
following standardized form.  Alternatives are indicated _via_ vertical
bars.  Individual specifications must be one of
   * One of the "standard" short specifications
          GPL-2 GPL-3 LGPL-2 LGPL-2.1 LGPL-3 AGPL-3 Artistic-1.0 Artistic-2.0
     as made available _via_ `http://www.r-project.org/Licenses/' and
     contained in subdirectory `share/licenses' of the R source or home
     directory.

   * The names of abbreviations of free or open source software (FOSS,
     e.g., `http://en.wikipedia.org/wiki/FOSS') licenses as contained
     in the license data base in file `share/licenses/license.db' in
     the R source or home directory, possibly (for versioned licenses)
     followed by a version restriction of the form `(OP V)' with OP one
     of the comparison operators `<', `<=', `>', `>=', `==', or `!='
     and V a numeric version specification (strings of non-negative
     integers separated by `.'), possibly combined _via_ `,' (see below
     for an example).  For versioned licenses, one can also specify the
     name followed by the version, or combine an existing abbreviation
     and the version with a `-'.  Further free (see
     `http://www.fsf.org/licenses/license-list.html') or open software
     (see `http://www.opensource.org/licenses/bsd-license.php')
     licenses will be added to this data base if necessary.

   * One of the strings `file LICENSE' or `file LICENCE' referring to a
     file named `LICENSE' or `LICENCE' in the package (source and
     installation) top-level directory.

   * The string `Unlimited', meaning that there are no restrictions on
     distribution or use other than those imposed by relevant laws.
   If a package license _extends_ a base FOSS license (e.g., using
GPL-3 or AGPL-3 with an attribution clause), the extension should be
placed in file `LICENSE' (or `LICENCE'), and the string `+ file
LICENSE' (or `+ file LICENCE', respectively) should be appended to the
corresponding individual license specification.

   Examples for standardized specifications include
     License: GPL-2
     License: GPL (>= 2) | BSD
     License: LGPL (>= 2.0, < 3) | Mozilla Public License
     License: GPL-2 | file LICENCE
     License: Artistic-1.0 | AGPL-3 + file LICENSE
   Please note in particular that "Public domain" is not a valid
license.

   It is very important that you include this license information!
Otherwise, it may not even be legally correct for others to distribute
copies of the package.  Do not use the `License' field for copyright
information: if needed, use a `Copyright' field.

   Please ensure that the license you choose also covers any system
dependencies of your package: it is particularly important that any
restrictions on the use of such dependencies are evident to people
reading your `DESCRIPTION' file.

   The `Description' field should give a comprehensive description of
what the package does.  One can use several (complete) sentences, but
only one paragraph.

   The `Title' field should give a short description of the package.
Some package listings may truncate the title to 65 characters in order
to keep the overall size of the listing limited.  It should be
capitalized, not use any markup, not have any continuation lines, and
not end in a period.  Older versions of R used a separate file `TITLE'
for giving this information; this is now defunct, and the `Title' field
in `DESCRIPTION' is required.

   The `Author' field describes who wrote the package.  It is a plain
text field intended for human readers, but not for automatic processing
(such as extracting the email addresses of all listed contributors).

   The `Maintainer' field should give a _single_ name with a _valid_
(RFC 2822) email address in angle brackets (for sending bug reports
etc.).  It should not end in a period or comma.

   The optional `Date' field gives the release date of the current
version of the package.  It is strongly recommended to use the
yyyy-mm-dd format conforming to the ISO standard.

   The optional `Depends' field gives a comma-separated list of package
names which this package depends on.  The package name may be
optionally followed by a comment in parentheses.  The comment should
contain a comparison operator(1), whitespace and a valid version
number).  You can also use the special package name `R' if your package
depends on a certain version of R.  E.g., if the package works only
with R version 2.4.0 or newer, include `R (>= 2.4.0)' in the `Depends'
field.  Both `library' and the R package checking facilities use this
field, hence it is an error to use improper syntax or misuse the
`Depends' field for comments on other software that might be needed.
Other dependencies (external to the R system) should be listed in the
`SystemRequirements' field, possibly amplified in a separate `README'
file.  The R `INSTALL' facilities check if the version of R used is
recent enough for the package being installed, and the list of packages
which is specified will be attached (after checking version
requirements) before the current package, both when `library' is called
and when preparing for lazy-loading.

   As from R 2.7.0 a package (or `R') can appear more than once in the
`Depends', but only the first occurrence will be used in earlier
versions of R.  (Unfortunately all occurrences will be checked, so only
`>=' and `<=' can be used.)

   The optional `Imports' field lists packages whose name spaces are
imported from but which do not need to be attached.  Name spaces
accessed by the `::' and `:::' operators must be listed here, or in
`Suggests' or `Enhances' (see below).  Ideally this field will include
all the standard packages that are used, and it is important to include
S4-using packages (as their class definitions can change and the
`DESCRIPTION' file is used to decide which packages to re-install when
this happens).  Packages declared in the `Depends' field should not
also be in the `Imports' field.  Versions can be specified, but will
not be checked when the namespace is loaded.

   The optional `Suggests' field uses the same syntax as `Depends' and
lists packages that are not necessarily needed.  This includes packages
used only in examples or vignettes (*note Writing package vignettes::),
and packages loaded in the body of functions.  E.g., suppose an example
from package *foo* uses a dataset from package *bar*. Then it is not
necessary to have *bar* for routine use of *foo*, unless one wants to
execute the examples: it is nice to have *bar*, but not necessary.

   Finally, the optional `Enhances' field lists packages "enhanced" by
the package at hand, e.g., by providing methods for classes from these
packages.

   The general rules are

   * Packages whose name space only is needed to load the package using
     `library(PKGNAME)' must be listed in the `Imports' field and not
     in the `Depends' field.

   * Packages that need to be attached to successfully load the package
     using `library(PKGNAME)' must be listed in the `Depends' field,
     only.

   * All packages that are needed to successfully run `R CMD check' on
     the package must be listed in one of `Depends' or `Suggests' or
     `Imports'.

In particular, large packages providing "only" data for examples or
vignettes should be listed in `Suggests' rather than `Depends' in order
to make lean installations possible.

   Prior to R 2.9.0, adding version dependencies for packages only made
sense for the `Depends' field, as only `library' checks version
requirements, and only for the packages it loads _via_ the `Depends'
field.  As from R 2.9.0 other dependencies are used by
`install.packages'.

   The optional `URL' field may give a list of URLs separated by commas
or whitespace, for example the homepage of the author or a page where
additional material describing the software can be found.  These URLs
are converted to active hyperlinks in CRAN package listings.

   Base and recommended packages (i.e., packages contained in the R
source distribution or available from CRAN and recommended to be
included in every binary distribution of R) have a `Priority' field
with value `base' or `recommended', respectively.  These priorities
must not be used by other packages.

   An optional `Collate' field can be used for controlling the
collation order for the R code files in a package when these are
concatenated into a single file upon installation from source.  The
default is to try collating according to the `C' locale.  If present,
the collate specification must list _all_ R code files in the package
(taking possible OS-specific subdirectories into account, see *Note
Package subdirectories::) as a whitespace separated list of file paths
relative to the `R' subdirectory.  Paths containing white space or
quotes need to be quoted.  An OS-specific collation field
(`Collate.unix' or `Collate.windows') will be used instead of `Collate'.

   The optional `LazyLoad' and `LazyData' fields control whether the R
objects and the datasets (respectively) use lazy-loading: set the
field's value to `yes' or `true' for lazy-loading and `no' or `false'
for no lazy-loading.  (Capitalized values are also accepted.)  If the
package you are writing uses the *methods* package, specify `LazyLoad:
yes'.

   The optional `ZipData' field controls whether the automatic Windows
build will zip up the data directory or no: set this to `no' if your
package will not work with a zipped data directory.

   If the `DESCRIPTION' file is not entirely in ASCII it should contain
an `Encoding' field specifying an encoding.  This is used as the
encoding of the `DESCRIPTION' file itself and of the `R' and
`NAMESPACE' files, and as the default encoding of `.Rd' files.  The
examples are assumed to be in this encoding when running `R CMD check'.
As from R 2.8.0 it is used for the encoding of the `CITATION' file.
Only encoding names `latin1', `latin2' and `UTF-8' are known to be
portable.  (Do not specify an encoding unless one is actually needed:
doing so makes the package _less_ portable.)

   The optional `OS_type' field specifies the OS(es) for which the
package is intended.  If present, it should be one of `unix' or
`windows', and indicates that the package can only be installed on a
platform with `.Platform$OS.type' having that value.

   The optional `Type' field specifies the type of the package: *note
Package types::.

     Note: There should be no `Built' or `Packaged' fields, as these are
     added by the package management tools.

   One can add subject classifications for the content of the package
using the optional fields `Classification/ACM' (using the Computing
Classification System of the Association for Computing Machinery,
`http://www.acm.org/class/'), `Classification/JEL' (the Journal of
Economic Literature Classification System,
`http://www.aeaweb.org/journal/jel_class_system.html'), or
`Classification/MSC' (the Mathematics Subject Classification of the
American Mathematical Society, `http://www.ams.org/msc/').  The subject
classifications should be comma-separated lists of the respective
classification codes, e.g., `Classification/ACM: G.4, H.2.8, I.5.1'.

   Finally, an optional `Language' field can be used to indicate if the
package documentation is not in English: this should be a
comma-separated list of 2-letter ISO 639-1
(`http://en.wikipedia.org/wiki/ISO_639-1') or 3-letter ISO 639-3
(`http://en.wikipedia.org/wiki/ISO_639-3') language codes, or standard
(not private use or grandfathered) IETF language tags as currently
defined by RFC 4646 (`http://tools.ietf.org/html/rfc4646', see also
`http://en.wikipedia.org/wiki/IETF_language_tag').

   ---------- Footnotes ----------

   (1) only `>=' and `<=' were supported prior to R 2.7.0, and only
`>=' is supported for package versions by `install.packages'.


File: R-exts.info,  Node: The INDEX file,  Next: Package subdirectories,  Prev: The DESCRIPTION file,  Up: Package structure

1.1.2 The `INDEX' file
----------------------

The optional file `INDEX' contains a line for each sufficiently
interesting object in the package, giving its name and a description
(functions such as print methods not usually called explicitly might not
be included).  Normally this file is missing, and the corresponding
information is automatically generated from the documentation sources
(using `Rdindex()' from package *tools*) when installing from source
and when using the package builder (*note Checking and building
packages::).

   Rather than editing this file, it is preferable to put customized
information about the package into an overview man page (*note
Documenting packages::) and/or a vignette (*note Writing package
vignettes::).


File: R-exts.info,  Node: Package subdirectories,  Next: Package bundles,  Prev: The INDEX file,  Up: Package structure

1.1.3 Package subdirectories
----------------------------

The `R' subdirectory contains R code files, only.  The code files to be
installed must start with an ASCII (lower or upper case) letter or
digit and have one of the extensions `.R', `.S', `.q', `.r', or `.s'.
We recommend using `.R', as this extension seems to be not used by any
other software.  It should be possible to read in the files using
`source()', so R objects must be created by assignments.  Note that
there need be no connection between the name of the file and the R
objects created by it.  Ideally, the R code files should only directly
assign R objects and definitely should not call functions with side
effects such as `require' and `options'.  If computations are required
to create objects these can use code `earlier' in the package (see the
`Collate' field) plus, _only if lazyloading is used_, functions in the
`Depends' packages provided that the objects created do not depend on
those packages except _via_ name space imports.  (Packages without
namespaces will work under somewhat less restrictive assumptions.)

   Two exceptions are allowed: if the `R' subdirectory contains a file
`sysdata.rda' (a saved image of R objects) this will be lazy-loaded
into the name space/package environment - this is intended for system
datasets that are not intended to be user-accessible _via_ `data'.
Also, files ending in `.in' will be allowed in the `R' directory to
allow a `configure' script to generate suitable files.

   Only ASCII characters (and the control characters tab, formfeed, LF
and CR) should be used in code files.  Other characters are accepted in
comments, but then the comments may not be readable in e.g. a UTF-8
locale.  Non-ASCII characters in object names will normally(1) fail
when the package is installed.  Any byte will be allowed(2) in a quoted
character string (but `\uxxxx' escapes should not be used unless the
package depends on `R (>= 2.10)'), but non-ASCII character strings may
not be usable in some locales and may display incorrectly in others.

   Various R functions in a package can be used to initialize and clean
up.  For packages without a name space, these are `.First.lib' and
`.Last.lib'.  (*Note Load hooks::, for packages with a name space.)  It
is conventional to define these functions in a file called `zzz.R'.  If
`.First.lib' is defined in a package, it is called with arguments
`libname' and `pkgname' after the package is loaded and attached.  A
common use is to call `library.dynam' inside `.First.lib' to load
compiled code: another use is to call those functions with side
effects.  If `.Last.lib' exists in a package it is called (with
argument the full path to the installed package) just before the
package is detached.  It is uncommon to detach packages and rare to
have a `.Last.lib' function: one use is to call `library.dynam.unload'
to unload compiled code.

   The `man' subdirectory should contain (only) documentation files for
the objects in the package in "R documentation" (Rd) format.  The
documentation filenames must start with an ASCII (lower or upper case)
letter or digit and have the extension `.Rd' (the default) or `.rd'.
Further, the names must be valid in `file://' URLs, which means(3)
they must be entirely ASCII and not contain `%'.  *Note Writing R
documentation files::, for more information.  Note that all user-level
objects in a package should be documented; if a package PKG contains
user-level objects which are for "internal" use only, it should provide
a file `PKG-internal.Rd' which documents all such objects, and clearly
states that these are not meant to be called by the user.  See e.g. the
sources for package *grid* in the R distribution for an example.  Note
that packages which use internal objects extensively should hide those
objects in a name space, when they do not need to be documented (*note
Package name spaces::).

   Having a `man' directory containing no documentation files may give
an installation error.

   The `R' and `man' subdirectories may contain OS-specific
subdirectories named `unix' or `windows'.

   The sources and headers for the compiled code are in `src', plus
optionally a file `Makevars' or `Makefile'.  When a package is
installed using `R CMD INSTALL', `make' is used to control compilation
and linking into a shared object for loading into R.  There are default
variables and rules for this (determined when R is configured and
recorded in `R_HOME/etcR_ARCH/Makeconf'), providing support for C, C++,
FORTRAN 77, Fortran 9x(4), Objective C and Objective C++(5) with
associated extensions `.c', `.cc' or `.cpp' or `.C', `.f', `.f90' or
`.f95', `.m', and `.mm' or `.M', respectively.  We recommend using `.h'
for headers, also for C++(6) or Fortran 9x include files.

   It is not portable (and may not be possible at all) to mix all these
languages in a single package, and we do not support using both C++ and
Fortran 9x. Because R itself uses it, we know that C and FORTRAN 77 can
be used together and mixing C and C++ seems to be widely successful.

   The default rules can be tweaked by setting macros in a file
`src/Makevars' (*note Using Makevars::).  Note that this mechanism
should be general enough to eliminate the need for a package-specific
`src/Makefile'.  If such a file is to be distributed, considerable care
is needed to make it general enough to work on all R platforms.  If it
has any targets at all, it should have an appropriate first target
named `all' and a (possibly empty) target `clean' which removes all
files generated by Make (to be used by `R CMD INSTALL --clean' and `R
CMD INSTALL --preclean').  There are platform-specific file names on
Windows: `src/Makevars.win' takes precedence over `src/Makevars' and
`src/Makefile.win' must be used.

   The `data' subdirectory is for data files: *Note Data in packages::.

   The `demo' subdirectory is for R scripts (for running _via_
`demo()') that demonstrate some of the functionality of the package.
Demos may be interactive and are not checked automatically, so if
testing is desired use code in the `tests' directory.  The script files
must start with a (lower or upper case) letter and have one of the
extensions `.R' or `.r'.  If present, the `demo' subdirectory should
also have a `00Index' file with one line for each demo, giving its name
and a description separated by white space. (Note that it is not
possible to generate this index file automatically.)

   The contents of the `inst' subdirectory will be copied recursively
to the installation directory.  Subdirectories of `inst' should not
interfere with those used by R (currently, `R', `data', `demo', `exec',
`libs', `man', `help', `html', `latex', `R-ex' and `Meta').  The
copying of the `inst' happens after `src' is built so its `Makefile'
can create files to be installed.  Note that with the exceptions of
`INDEX', `LICENSE'/`LICENCE', `COPYING' and `NEWS' (from R 2.7.0),
information files at the top level of the package will _not_ be
installed and so not be known to users of Windows and Mac OS X compiled
packages (and not seen by those who use `R CMD INSTALL' or
`install.packages' on the tarball).  So any information files you wish
an end user to see should be included in `inst'.

   One thing you might like to add to `inst' is a `CITATION' file for
use by the `citation' function.  Note that if the named exceptions also
occur in `inst', the version in `inst' will be that seen in the
installed package.  If you want `NEWS' to be installed by your package
in earlier versions of R, you need to include it in `inst'.

   Subdirectory `tests' is for additional package-specific test code,
similar to the specific tests that come with the R distribution.  Test
code can either be provided directly in a `.R' file, or _via_ a `.Rin'
file containing code which in turn creates the corresponding `.R' file
(e.g., by collecting all function objects in the package and then
calling them with the strangest arguments).  The results of running a
`.R' file are written to a `.Rout' file.  If there is a corresponding
`.Rout.save' file, these two are compared, with differences being
reported but not causing an error.  The directory `tests' is copied to
the check area, and the tests are run with the copy as the working
directory and with `R_LIBS' set to ensure that the copy of the package
installed during testing will be found by `library(PKG_NAME)'.

   If `tests' has a subdirectory `Examples' containing a file
`PKG-Ex.Rout.save',  this is compared to the output file for running
the examples when the latter are checked.

   Subdirectory `exec' could contain additional executables the package
needs, typically scripts for interpreters such as the shell, Perl, or
Tcl.  This mechanism is currently used only by a very few packages, and
still experimental.

   Subdirectory `po' is used for files related to _localization_: *note
Internationalization::.

   ---------- Footnotes ----------

   (1) This is true for OSes which implement the `C' locale, unless
lazy-loading is not used, in which case it would fail if loaded in a
`C' locale. (Windows' idea of the `C' locale uses the WinAnsi charset.)

   (2) It is good practice to encode them as octal or hex escape
sequences.

   (3) More precisely, they can contain the English alphanumeric
characters and the symbols `$ - _ . + ! ' ( ) , ;  = &'.

   (4) Note that Ratfor is not supported.  If you have Ratfor source
code, you need to convert it to FORTRAN.  Only FORTRAN-77 (which we
write in upper case) is supported on all platforms, but most also
support Fortran-95 (for which we use title case).  If you want to ship
Ratfor source files, please do so in a subdirectory of `src' and not in
the main subdirectory.

   (5) either or both of which may not be supported on particular
platforms

   (6) Using `.hpp', although somewhat popular, is not guaranteed to be
portable.


File: R-exts.info,  Node: Package bundles,  Next: Data in packages,  Prev: Package subdirectories,  Up: Package structure

1.1.4 Package bundles
---------------------

Package bundles were deprecated in R 2.10.0 and support for installing
them will be removed in R 2.11.0.

   Unbundling a package bundle is straightforward: just replace the
`DESCRIPTION.in' file of each package by a suitable `DESCRIPTION' file
and distribute the individual packages (e.g.  _via_ tarballs created by
`R CMD build')).  The installed `DESCRIPTION' files provide a good
starting point, but the `Bundle', `Contains' and `BundleDescription'
fields should not appear.  It may be needed to add references in the
`Suggests' or `Imports' fields to other members of the former bundle.

   Prior to R 2.9.1, `update.packages()' will only update members of a
bundle by an updated bundle, whereas later versions of R will update
one or more members if an updated package of that name is available.
Thus when a bundle is unbundled, updating is transparent in R 2.9.1 and
later but needs to be done manually in earlier versions.


File: R-exts.info,  Node: Data in packages,  Prev: Package bundles,  Up: Package structure

1.1.5 Data in packages
----------------------

The `data' subdirectory is for data files, either to be made available
_via_ lazy-loading or for loading using `data()'.  (The choice is made
by the `LazyData' field in the `DESCRIPTION' file.)  It should not be
used for other data files needed by the package, and the convention has
grown up to use directory `inst/extdata' for such files.

   Data files can have one of three types as indicated by their
extension: plain R code (`.R' or `.r'), tables (`.tab', `.txt', or
`.csv', see `?data' for the file formats, and note that `.csv' is *not*
the standard(1) CSV format), or `save()' images (`.RData' or `.rda').
Note that R code should be "self-sufficient" and not make use of extra
functionality provided by the package, so that the data file can also be
used without having to load the package.

   If your data files are enormous and you are not using `LazyData' you
can speed up installation by providing a file `datalist' in the `data'
subdirectory.  This should have one line per topic that `data()' will
find, in the format `foo' if `data(foo)' provides `foo', or `foo: bar
bah' if `data(foo)' provides `bar' and `bah'.

   As from R 2.10.0 tables (`.tab', `.txt', or `.csv' files) can be
compressed by `gzip', `bzip2' or `xz', optionally with additional
extension `.gz', `.bz2' or `.xz'.

   If your package is to be distributed, do consider the resource
implications for your users of large datasets: they can make packages
very slow to download and use up unwelcome amounts of storage space, as
well as taking many seconds to load.  It is normally best to distribute
large datasets as `.rda' images prepared by `save(, compress = TRUE)'
(the default): there is no excuse for distributing ASCII saves.

   Using `bzip2' or `xz' compression will usually reduce the size of
both the package tarball and the installed package, in some cases by a
factor of two or more.  However, such compression can only be used with
R 2.10.0 or later, and so the package should have an appropriate
`Depends' entry in its DESCRIPTION file.

   Package *tools* has a couple of functions to help with data images:
`checkRdaFiles' reports on the way the image was saved, and
`resaveRdaFiles' will re-save in a different type of compression,
including choosing the best type for that particular image.

   ---------- Footnotes ----------

   (1) e.g `http://tools.ietf.org/html/rfc4180'.


File: R-exts.info,  Node: Configure and cleanup,  Next: Checking and building packages,  Prev: Package structure,  Up: Creating R packages

1.2 Configure and cleanup
=========================

Note that most of this section is Unix-specific: see the comments later
on about the Windows port of R.

   If your package needs some system-dependent configuration before
installation you can include an executable (Bourne shell) script
`configure' in your package which (if present) is executed by `R CMD
INSTALL' before any other action is performed.  This can be a script
created by the Autoconf mechanism, but may also be a script written by
yourself.  Use this to detect if any nonstandard libraries are present
such that corresponding code in the package can be disabled at install
time rather than giving error messages when the package is compiled or
used.  To summarize, the full power of Autoconf is available for your
extension package (including variable substitution, searching for
libraries, etc.).

   Under a Unix-alike only, an executable (Bourne shell) script
`cleanup' is executed as last thing by `R CMD INSTALL' if option
`--clean' was given, and by `R CMD build' when preparing the package
for building from its source.  It can be used to clean up the package
source tree.  In particular, it should remove all files created by
`configure'.

   As an example consider we want to use functionality provided by a (C
or FORTRAN) library `foo'.  Using Autoconf, we can create a configure
script which checks for the library, sets variable `HAVE_FOO' to `TRUE'
if it was found and with `FALSE' otherwise, and then substitutes this
value into output files (by replacing instances of `@HAVE_FOO@' in
input files with the value of `HAVE_FOO').  For example, if a function
named `bar' is to be made available by linking against library `foo'
(i.e., using `-lfoo'), one could use

     AC_CHECK_LIB(foo, FUN, [HAVE_FOO=TRUE], [HAVE_FOO=FALSE])
     AC_SUBST(HAVE_FOO)
     ......
     AC_CONFIG_FILES([foo.R])
     AC_OUTPUT

in `configure.ac' (assuming Autoconf 2.50 or later).

   The definition of the respective R function in `foo.R.in' could be

     foo <- function(x) {
         if(!@HAVE_FOO@)
           stop("Sorry, library 'foo' is not available"))
         ...

From this file `configure' creates the actual R source file `foo.R'
looking like

     foo <- function(x) {
         if(!FALSE)
           stop("Sorry, library 'foo' is not available"))
         ...

if library `foo' was not found (with the desired functionality).  In
this case, the above R code effectively disables the function.

   One could also use different file fragments for available and missing
functionality, respectively.

   You will very likely need to ensure that the same C compiler and
compiler flags are used in the `configure' tests as when compiling R or
your package.  Under Unix, you can achieve this by including the
following fragment early in `configure.ac'

     : ${R_HOME=`R RHOME`}
     if test -z "${R_HOME}"; then
       echo "could not determine R_HOME"
       exit 1
     fi
     CC=`"${R_HOME}/bin/R" CMD config CC`
     CFLAGS=`"${R_HOME}/bin/R" CMD config CFLAGS`
     CPPFLAGS=`"${R_HOME}/bin/R" CMD config CPPFLAGS`

(using `${R_HOME}/bin/R' rather than just `R' is necessary in order to
use the correct version of R when running the script as part of `R CMD
INSTALL'.)

   Note that earlier versions of this document recommended obtaining the
configure information by direct extraction (using `grep' and `sed')
from `R_HOME/etcR_ARCH/Makeconf', which only works for variables
recorded there as literals.  You can use `R CMD config' for getting the
value of the basic configuration variables, or the header and library
flags necessary for linking against R, see `R CMD config --help' for
details.  (This works on Windows as from R 2.6.0.)

   To check for an external BLAS library using the `ACX_BLAS' macro
from the official Autoconf Macro Archive, one can simply do

     F77=`"${R_HOME}/bin/R" CMD config F77`
     AC_PROG_F77
     FLIBS=`"${R_HOME}/bin/R" CMD config FLIBS`
     ACX_BLAS([], AC_MSG_ERROR([could not find your BLAS library], 1))

   Note that `FLIBS' as determined by R must be used to ensure that
FORTRAN 77 code works on all R platforms.  Calls to the Autoconf macro
`AC_F77_LIBRARY_LDFLAGS', which would overwrite `FLIBS', must not be
used (and hence e.g. removed from `ACX_BLAS').  (Recent versions of
Autoconf in fact allow an already set `FLIBS' to override the test for
the FORTRAN linker flags.  Also, recent versions of R can detect
external BLAS and LAPACK libraries.)

   You should bear in mind that the configure script will not be used on
Windows systems.  If your package is to be made publicly available,
please give enough information for a user on a non-Unix platform to
configure it manually, or provide a `configure.win' script to be used
on that platform.  (Optionally, there can be a `cleanup.win' script.
Both should be shell scripts to be executed by `ash', which is a
minimal version of Bourne-style `sh'.)

   In some rare circumstances, the configuration and cleanup scripts
need to know the location into which the package is being installed.  An
example of this is a package that uses C code and creates two shared
object/DLLs.  Usually, the object that is dynamically loaded by R is
linked against the second, dependent, object.  On some systems, we can
add the location of this dependent object to the object that is
dynamically loaded by R.  This means that each user does not have to
set the value of the `LD_LIBRARY_PATH' (or equivalent) environment
variable, but that the secondary object is automatically resolved.
Another example is when a package installs support files that are
required at run time, and their location is substituted into an R data
structure at installation time. (This happens with the Java Archive
files in the *SJava* package.)  The names of the top-level library
directory (i.e., specifiable _via_ the `-l' argument) and the directory
of the package itself are made available to the installation scripts
_via_ the two shell/environment variables `R_LIBRARY_DIR' and
`R_PACKAGE_DIR'.  Additionally, the name of the package (e.g.,
`survival' or `MASS') being installed is available from the shell
variable `R_PACKAGE_NAME'.

* Menu:

* Using Makevars::
* Configure example::
* Using F95 code::


File: R-exts.info,  Node: Using Makevars,  Next: Configure example,  Prev: Configure and cleanup,  Up: Configure and cleanup

1.2.1 Using `Makevars'
----------------------

Sometimes writing your own `configure' script can be avoided by
supplying a file `Makevars': also one of the most common uses of a
`configure' script is to make `Makevars' from `Makevars.in'.

   The most common use of a `Makevars' file is to set additional
preprocessor options (for example include paths) for C/C++ files _via_
`PKG_CPPFLAGS', and additional compiler flags by setting `PKG_CFLAGS',
`PKG_CXXFLAGS', `PKG_FFLAGS' and `PKG_FCFLAGS', for C, C++, FORTRAN or
Fortran 9x respectively (*note Creating shared objects::).

   `Makevars' can also be used to set flags for the linker, for example
`-L' and `-l' options, _via_ `PKG_LIBS'.

   When writing a `Makevars' file for a package you intend to
distribute, take care to ensure that it is not specific to your
compiler: flags such as `-O2 -Wall -pedantic' are all specific to GCC.

   There are some macros which are built whilst configuring the
building of R itself and are stored in `R_HOME/etcR_ARCH/Makeconf'.
That makefile is included as a `Makefile' _before_ `Makevars[.win]',
and so the macros it defines can be used in the latter.  These include

`FLIBS'
     A macro containing the set of libraries need to link FORTRAN code.
     This may need to be included in `PKG_LIBS': it will normally be
     included automatically if the package contains FORTRAN source
     files.

`BLAS_LIBS'
     A macro containing the BLAS libraries used when building R.  This
     may need to be included in `PKG_LIBS'.  Beware that if it is empty
     then the R executable will contain all the double-precision and
     double-complex BLAS routines, but no single-precision or complex
     routines.  If `BLAS_LIBS' is included, then `FLIBS' also needs to
     be(1), as most BLAS libraries are written at least partially in
     FORTRAN.

`LAPACK_LIBS'
     A macro containing the LAPACK libraries (and paths where
     appropriate) used when building R.  This may need to be included in
     `PKG_LIBS'.  It may point to a dynamic library `libRlapack' which
     contains all the double-precision LAPACK routines as well as those
     double-complex LAPACK and BLAS routines needed to build R, or it
     may point to an external LAPACK library, or may be empty if an
     external BLAS library also contains LAPACK.

     [There is no guarantee that the LAPACK library will provide more
     than all the double-precision and double-complex routines, and
     some do not provide all the auxiliary routines.]

     For portability, the macros `BLAS_LIBS' and `FLIBS' should always
     be included _after_ `LAPACK_LIBS'.

`SAFE_FFLAGS'
     A macro containing flags which are needed to circumvent
     over-optimization of FORTRAN code: it is typically `-g -O2
     -ffloat-store' on `ix86' platforms using `gfortran'.  Note that
     this is *not* an additional flag to be used as part of
     `PKG_FFLAGS', but a replacement for `FFLAGS', and that it is
     intended for the FORTRAN-77 compiler `F77' and not necessarily for
     the Fortran 90/95 compiler `FC'.  See the example later in this
     section.

   Setting certain macros in `Makevars' will prevent `R CMD SHLIB'
setting them: in particular if `Makevars' sets `OBJECTS' it will not be
set on the `make' command line.  This can be useful in conjunction with
implicit rules to allow other types of source code to be compiled and
included in the shared object.  Also, as from R 2.9.0 setting an empty
value for `OBJECTS' will prevent the shared object / DLL from being
made (possibly useful in conjunction with an `all' target as described
in the next paragraph).

   Note that `Makevars' should not normally contain targets, as it is
included before the default makefile and `make' is called with target
`all' which is defined in the default makefile.  If you really need to
circumvent that, use a suitable (phony) target `all' before any actual
targets in `Makevars.[win]': for example package *fastICA* has

     PKG_LIBS = @BLAS_LIBS@

     SLAMC_FFLAGS=$(R_XTRA_FFLAGS) $(FPICFLAGS) $(SHLIB_FFLAGS) $(SAFE_FFLAGS)

     all: $(SHLIB)

     slamc.o: slamc.f
             $(F77) $(SLAMC_FFLAGS) -c -o slamc.o slamc.f

needed to ensure that the LAPACK routines find some constants without
infinite looping.  The Windows equivalent is

     all: $(SHLIB)

     slamc.o: slamc.f
             $(F77) $(SAFE_FFLAGS) -c -o slamc.o slamc.f

(since the other macros are all empty on that platform, and R's internal
BLAS is not used).  Note that the first target in `Makevars' will be
called, but for back-compatibility it is best named `all'.

   If you want to create and then link to a library, say using code in a
subdirectory, use something like

     .PHONY: all mylibs

     all: $(SHLIB)
     $(SHLIB): mylibs

     mylibs:
             (cd subdir; make)

Be careful to create all the necessary dependencies, as there is a no
guarantee that the dependencies of `all' will be run in a particular
order (and some of the CRAN build machines use multiple CPUs and
parallel makes).

   It is sometimes useful to have a target `clean' in `Makevars' or
`Makevars.win': this will be used by `R CMD build'.

* Menu:

* Back-compatibility for Makevars::

   ---------- Footnotes ----------

   (1) at least on Unix-alikes: the Windows build currently resolves
such dependencies to a static FORTRAN library when `Rblas.dll' is built.


File: R-exts.info,  Node: Back-compatibility for Makevars,  Prev: Using Makevars,  Up: Using Makevars

1.2.1.1 Back-compatibility
..........................

The description above is for R 2.10.0 and later.  In versions of R
before 2.9.0 the mechanisms used on Unix-alikes and Windows were
completely separate and their operation differed in a number of details.
The current version was designed to be as compatible as possible with
both.

   On a Unix-alike the rules are unchanged.

   On Windows prior to R 2.9.0 any file `Makevars.win' or `Makevars'
was included in another makefile after its targets, so the target made
was always

     all:  before $(DLLNAME).dll after

     ## these targets are just here to allow packages to add to them.
     before:
     after:

This allows packages to set dependencies for targets `all', `before' or
`after'.  Pretty complete backwards compatibility can be obtained by
having no targets, or by having the first target in `Makevars.win' as

     all: before $(SHLIB) after

omitting `before' or `after' if they are unused.  Note however that
this is not compatible with the use of a parallel make.

   Note that as from R 2.10.0 the first target in `Makevars[.win]' will
be called if there is one, so for backwards compatibility this should
be named `all'.

   Some packages used undocumented macros under Windows, notably `DPKG'
(use `R_PACKAGE_DIR' instead).


File: R-exts.info,  Node: Configure example,  Next: Using F95 code,  Prev: Using Makevars,  Up: Configure and cleanup

1.2.2 Configure example
-----------------------

It may be helpful to give an extended example of using a `configure'
script to create a `src/Makevars' file: this is based on that in the
*RODBC* package.

   The `configure.ac' file follows: `configure' is created from this by
running `autoconf' in the top-level package directory (containing
`configure.ac').

          AC_INIT([RODBC], 1.1.8) dnl package name, version

          dnl A user-specifiable option
          odbc_mgr=""
          AC_ARG_WITH([odbc-manager],
                      AC_HELP_STRING([--with-odbc-manager=MGR],
                                     [specify the ODBC manager, e.g. odbc or iodbc]),
                      [odbc_mgr=$withval])

          if test "$odbc_mgr" = "odbc" ; then
            AC_PATH_PROGS(ODBC_CONFIG, odbc_config)
          fi

          dnl Select an optional include path, from a configure option
          dnl or from an environment variable.
          AC_ARG_WITH([odbc-include],
                      AC_HELP_STRING([--with-odbc-include=INCLUDE_PATH],
                                     [the location of ODBC header files]),
                      [odbc_include_path=$withval])
          RODBC_CPPFLAGS="-I."
          if test [ -n "$odbc_include_path" ] ; then
             RODBC_CPPFLAGS="-I. -I${odbc_include_path}"
          else
            if test [ -n "${ODBC_INCLUDE}" ] ; then
               RODBC_CPPFLAGS="-I. -I${ODBC_INCLUDE}"
            fi
          fi

          dnl ditto for a library path
          AC_ARG_WITH([odbc-lib],
                      AC_HELP_STRING([--with-odbc-lib=LIB_PATH],
                                     [the location of ODBC libraries]),
                      [odbc_lib_path=$withval])
          if test [ -n "$odbc_lib_path" ] ; then
             LIBS="-L$odbc_lib_path ${LIBS}"
          else
            if test [ -n "${ODBC_LIBS}" ] ; then
               LIBS="-L${ODBC_LIBS} ${LIBS}"
            else
              if test -n "${ODBC_CONFIG}"; then
                odbc_lib_path=`odbc_config --libs | sed s/-lodbc//`
                LIBS="${odbc_lib_path} ${LIBS}"
              fi
            fi
          fi

          dnl Now find the compiler and compiler flags to use
          : ${R_HOME=`R RHOME`}
          if test -z "${R_HOME}"; then
            echo "could not determine R_HOME"
            exit 1
          fi
          CC=`"${R_HOME}/bin/R" CMD config CC`
          CPP=`"${R_HOME}/bin/R" CMD config CPP`
          CFLAGS=`"${R_HOME}/bin/R" CMD config CFLAGS`
          CPPFLAGS=`"${R_HOME}/bin/R" CMD config CPPFLAGS`
          AC_PROG_CC
          AC_PROG_CPP


          if test -n "${ODBC_CONFIG}"; then
            RODBC_CPPFLAGS=`odbc_config --cflags`
          fi
          CPPFLAGS="${CPPFLAGS} ${RODBC_CPPFLAGS}"

          dnl Check the headers can be found
          AC_CHECK_HEADERS(sql.h sqlext.h)
          if test "${ac_cv_header_sql_h}" = no ||
             test "${ac_cv_header_sqlext_h}" = no; then
             AC_MSG_ERROR("ODBC headers sql.h and sqlext.h not found")
          fi

          dnl search for a library containing an ODBC function
          if test [ -n "${odbc_mgr}" ] ; then
            AC_SEARCH_LIBS(SQLTables, ${odbc_mgr}, ,
                AC_MSG_ERROR("ODBC driver manager ${odbc_mgr} not found"))
          else
            AC_SEARCH_LIBS(SQLTables, odbc odbc32 iodbc, ,
                AC_MSG_ERROR("no ODBC driver manager found"))
          fi

          dnl for 64-bit ODBC need SQL[U]LEN, and it is unclear where they are defined.
          AC_CHECK_TYPES([SQLLEN, SQLULEN], , , [# include <sql.h>])
          dnl for unixODBC header
          AC_CHECK_SIZEOF(long, 4)

          dnl substitute RODBC_CPPFLAGS and LIBS
          AC_SUBST(RODBC_CPPFLAGS)
          AC_SUBST(LIBS)
          AC_CONFIG_HEADERS([src/config.h])
          dnl and do substitution in the src/Makevars.in and src/config.h
          AC_CONFIG_FILES([src/Makevars])
          AC_OUTPUT

where `src/Makevars.in' would be simply

          PKG_CPPFLAGS = @RODBC_CPPFLAGS@
          PKG_LIBS = @LIBS@

   A user can then be advised to specify the location of the ODBC driver
manager files by options like (lines broken for easier reading)

     R CMD INSTALL
       --configure-args='--with-odbc-include=/opt/local/include
       --with-odbc-lib=/opt/local/lib --with-odbc-manager=iodbc'
       RODBC

or by setting the environment variables `ODBC_INCLUDE' and `ODBC_LIBS'.


File: R-exts.info,  Node: Using F95 code,  Prev: Configure example,  Up: Configure and cleanup

1.2.3 Using F95 code
--------------------

R assumes that source files with extension `.f' are FORTRAN 77, and
passes them to the compiler specified by `F77'.  On most but not all
platforms that compiler will accept Fortran 90/95 code: some platforms
have a separate Fortran 90/95 compiler and a few (typically older)
platforms have no Fortran 90/95 support.

   This means that portable packages need to be written in correct
FORTRAN 77, which will also be valid Fortran 95.  See
`http://developer.r-project.org/Portability.html' for reference
resources.  In particular, _free source form_ F95 code is not portable.

   On some systems an alternative F95 compiler is available: from the
`gcc' family this might be `gfortran' or `g95'.  Configuring R will try
to find a compiler which (from its name) appears to be a Fortran 90/95
compiler, and set it in macro `FC'.  Note that it does not check that
such a compiler is fully (or even partially) compliant with Fortran
90/95.  Packages making use of Fortran 90/95 features should use file
extension `.f90' or `.f95' for the source files: the variable
`PKG_FCFLAGS' specifies any special flags to be used.  There is no
guarantee that compiled Fortran 90/95 code can be mixed with any other
type of compiled code, nor that a build of R will have support for such
packages.


File: R-exts.info,  Node: Checking and building packages,  Next: Writing package vignettes,  Prev: Configure and cleanup,  Up: Creating R packages

1.3 Checking and building packages
==================================

Before using these tools, please check that your package can be
installed and loaded.  `R CMD check' will _inter alia_ do this, but you
may get more detailed error messages doing the checks directly.

* Menu:

* Checking packages::
* Building packages::
* Customizing checking and building::


File: R-exts.info,  Node: Checking packages,  Next: Building packages,  Prev: Checking and building packages,  Up: Checking and building packages

1.3.1 Checking packages
-----------------------

Using `R CMD check', the R package checker, one can test whether
_source_ R packages work correctly.  It can be run on one or more
directories, or gzipped package `tar' archives(1)  with extension
`.tar.gz' or `.tgz'.  This runs a series of checks, including

  1. The package is installed.  This will warn about missing
     cross-references and duplicate aliases in help files.

  2. The file names are checked to be valid across file systems and
     supported operating system platforms.

  3. The files and directories are checked for sufficient permissions
     (Unix only).

  4. The files are checked for binary executables, using a suitable
     version of `file' if available.  (There may be rare false
     positives.)

  5. The `DESCRIPTION' file is checked for completeness, and some of its
     entries for correctness.  Unless installation tests are skipped,
     checking is aborted if the package dependencies cannot be resolved
     at run time.  (You may need to set `R_LIBS' if dependent packages
     are in a separate library tree.) One check is that the package
     name is not that of a standard package, nor one of the defunct
     standard packages (`ctest', `eda', `lqs', `mle', `modreg', `mva',
     `nls', `stepfun' and `ts').  Another check is that all packages
     mentioned in `library' or `require's or from which the `NAMESPACE'
     file imports or are called _via_ `::' or `:::' are listed (in
     `Depends', `Imports', `Suggests' or `Contains'): this is not an
     exhaustive check of the actual imports.

  6. Available index information (in particular, for demos and
     vignettes) is checked for completeness.

  7. The package subdirectories are checked for suitable file names and
     for not being empty.  The checks on file names are controlled by
     the option `--check-subdirs=VALUE'.  This defaults to `default',
     which runs the checks only if checking a tarball: the default can
     be overridden by specifying the value as `yes' or `no'.  Further,
     the check on the `src' directory is only run if the package does
     not contain a `configure' script (which corresponds to the value
     `yes-maybe') and there is no `src/Makefile' or `src/Makefile.in'.

     To allow a `configure' script to generate suitable files, files
     ending in `.in' will be allowed in the `R' directory.

     A warning is given for directory names that look like R package
     check directories - many packages have been submitted to CRAN
     containing these.

  8. The R files are checked for syntax errors.  Bytes which are
     non-ASCII are reported as warnings, but these should be regarded
     as errors unless it is known that the package will always be used
     in the same locale.

  9. It is checked that the package can be loaded, first with the usual
     default packages and then only with package *base* already loaded.
     If the package has a namespace, it is checked if this can be
     loaded in an empty session with only the *base* namespace loaded.
     (Namespaces and packages can be loaded very early in the session,
     before the default packages are available, so packages should work
     then.)

 10. The R files are checked for correct calls to `library.dynam' (with
     no extension).  In addition, it is checked whether methods have all
     arguments of the corresponding generic, and whether the final
     argument of replacement functions is called `value'.  All foreign
     function calls (`.C', `.Fortran', `.Call' and `.External' calls)
     are tested to see if they have a `PACKAGE' argument, and if not,
     whether the appropriate DLL might be deduced from the name space of
     the package.  Any other calls are reported.  (The check is
     generous, and users may want to supplement this by examining the
     output of `tools::checkFF("mypkg", verbose=TRUE)', especially if
     the intention were to always use a `PACKAGE' argument)

 11. The Rd files are checked for correct syntax and meta data,
     including the presence of the mandatory (`\name', `\alias',
     `\title' and `\description') fields.  The Rd name and title are
     checked for being non-empty, and there is a check for missing
     cross-references (links).

 12. A check is made for missing documentation entries, such as
     undocumented user-level objects in the package.

 13. Documentation for functions, data sets, and S4 classes is checked
     for consistency with the corresponding code.

 14. It is checked whether all function arguments given in `\usage'
     sections of Rd files are documented in the corresponding
     `\arguments' section.

 15. C, C++ and FORTRAN source and header files are tested for portable
     (LF-only) line endings.  If there is a `Makefile' or `Makefile.in'
     or `Makevars' or `Makevars.in' in the `src' directory, it is
     checked for portable line endings and the correct use of
     `$(BLAS_LIBS)'.

 16. The examples provided by the package's documentation are run.
     (*note Writing R documentation files::, for information on using
     `\examples' to create executable example code.)  If there is a file
     `tests/Examples/PKG-Ex.Rout.save', the output of running the
     examples is compared to that file.

     Of course, released packages should be able to run at least their
     own examples.  Each example is run in a `clean' environment (so
     earlier examples cannot be assumed to have been run), and with the
     variables `T' and `F' redefined to generate an error unless they
     are set in the example: *Note Logical vectors: (R-intro)Logical
     vectors.

 17. If the package sources contain a `tests' directory then the tests
     specified in that directory are run.  (Typically they will consist
     of a set of `.R' source files and target output files
     `.Rout.save'.)  Please note that the comparison will be done in the
     end user's locale, so the target output files should be ASCII if
     at all possible - this may require using(2)
     `options(useFancyQuotes=FALSE)' in the source files.

 18. The code in package vignettes (*note Writing package vignettes::)
     is executed, and the vignettes made from the sources as a check of
     completeness.

 19. If a working `pdflatex' or `latex' program is available, the
     `.pdf' or `.dvi' version, respectively, of the package's manual is
     created (to check that the Rd files can be converted successfully).

   Use `R CMD check --help' to obtain more information about the usage
of the R package checker.  A subset of the checking steps can be
selected by adding flags.

   You do need to ensure that the package is checked in a suitable
locale if it contains non-ASCII characters.  Such packages are likely
to fail some of the checks in a `C' locale, and `R CMD check' will warn
if it spots the problem.  You should be able to check any package in a
UTF-8 locale (if one is available).  Beware that although a `C' locale
is rarely used at a console, it may be the default if logging in
remotely or for batch jobs.

   ---------- Footnotes ----------

   (1) This may require GNU `tar': the command used can be set with
environment variable `TAR'.

   (2) this is done automatically as from R 2.9.0.


File: R-exts.info,  Node: Building packages,  Next: Customizing checking and building,  Prev: Checking packages,  Up: Checking and building packages

1.3.2 Building packages
-----------------------

Using `R CMD build', the R package builder, one can build R packages
from their sources (for example, for subsequent release).

   Prior to actually building the package in the standard gzipped tar
file format, a few diagnostic checks and cleanups are performed.  In
particular, it is tested whether object indices exist and can be assumed
to be up-to-date, and C, C++ and FORTRAN source files and relevant make
files are tested and converted to LF line-endings if necessary.

   Run-time checks whether the package works correctly should be
performed using `R CMD check' prior to invoking the build procedure.

   To exclude files from being put into the package, one can specify a
list of exclude patterns in file `.Rbuildignore' in the top-level source
directory.  These patterns should be Perl regexps, one per line, to be
matched against the file names relative to the top-level source
directory.  In addition, directories from source control systems(1),
directories with names ending `.Rcheck' or `Old' or `old' and files
`GNUMakefile', `Read-and-delete-me' or with base names starting with
`.#', or starting and ending with `#', or ending in `~', `.bak' or
`.swp', are excluded by default.  In addition, those files in the `R',
`demo' and `man' directories which are flagged by `R CMD check' as
having invalid names will be excluded.

   Use `R CMD build --help' to obtain more information about the usage
of the R package builder.

   Unless `R CMD build' is invoked with the `--no-vignettes' option, it
will attempt to rebuild the vignettes (*note Writing package
vignettes::) in the package.  To do so it installs the current package
into a temporary library tree, but any dependent packages need to be
installed in an available library tree (see the Note: below).

   One of the checks that `R CMD build' runs is for empty source
directories.  These are in most cases unintentional, in which case they
should be removed and the build re-run.

   It can be useful to run `R CMD check --check-subdirs=yes' on the
built tarball as a final check on the contents.

   `R CMD build' can also build pre-compiled version of packages for
binary distributions, but `R CMD INSTALL --build' is preferred (and is
considerably more flexible).

     Note: `R CMD check' and `R CMD build' run R with `--vanilla', so
     none of the user's startup files are read.  If you need `R_LIBS'
     set (to find packages in a non-standard library) you will need to
     set it in the environment.

     Note to Windows users: `R CMD check' and `R CMD build' need you to
     have installed the files for building source packages (which is
     the default), as well as the Windows toolset and Perl (see the "R
     Installation and Administration" manual).  You may need to set
     `TMPDIR' to point to a suitable writable directory with a path not
     containing spaces - use forward slashes for the separators.  Also,
     the directory needs to be on a case-honouring file system (some
     network-mounted file systems are not).

   ---------- Footnotes ----------

   (1) called `CVS' or `.svn' or `.arch-ids' or `.bzr' or `.git'.


File: R-exts.info,  Node: Customizing checking and building,  Prev: Building packages,  Up: Checking and building packages

1.3.3 Customizing checking and building
---------------------------------------

In addition to the available command line options, `R CMD check' also
allows customization by setting (Perl) configuration variables in a
configuration file, the location of which can be specified _via_ the
`--rcfile' option and defaults to `$HOME/.R/check.conf' provided that
the environment variable `HOME' is set.

   The following configuration variables are currently available.

`$R_check_use_install_log'
     If true, record the output from installing a package as part of its
     check to a log file (`00install.out' by default), even when running
     interactively.  Default: true.

`$R_check_all_non_ISO_C'
     If true, do not ignore compiler (typically GCC) warnings about non
     ISO C code in _system_ headers.  Default: false.

`$R_check_weave_vignettes'
     If true, weave package vignettes in the process of checking them.
     Default: true.

`$R_check_latex_vignettes'
     If true (and `$R_check_weave_vignettes' is also true), `latex'
     package vignettes in the process of checking them: this will show
     up `Sweave' source errors, including missing source files.
     Default: true.

`$R_check_subdirs_nocase'
     If true, check the case of directories such as `R' and `man'.
     Default: false.

`$R_check_subdirs_strict'
     Initial setting for `--check-subdirs'.  Default: `default' (which
     checks only tarballs, and checks in the `src' only if there is no
     `configure' file).

`$R_check_force_suggests'
     If true, give an error if suggested packages are not available.
     Default: true.

`$R_check_use_codetools'
     If true, make use of the *codetools* package, which provides a
     detailed analysis of visibility of objects (but may give false
     positives).  Default: true.

`$R_check_Rd_style'
     If true, check whether Rd usage entries for S3 methods use the full
     function name rather than the appropriate `\method' markup.
     Default: true.

`$R_check_Rd_xrefs'
     If true, check the cross-references in `.Rd' files.  Default: true.

   Values `1' or a string with lower-cased version `"yes"' or `"true"'
can be used for setting the variables to true; similarly, `0' or
strings with lower-cased version `"no"' or `"false"' give false.

   For example, a configuration file containing

     $R_check_use_install_log = "TRUE";
     $R_check_weave_vignettes = 0;

results in using install logs and turning off weaving.

   Future versions of R may enhance this customization mechanism, and
provide a similar scheme for `R CMD build'.

   There are other internal settings that can be changed _via_
environment variables `_R_CHECK_*_':  *Note Tools: (R-ints)Tools, (and
the source code for `check').


File: R-exts.info,  Node: Writing package vignettes,  Next: Submitting a package to CRAN,  Prev: Checking and building packages,  Up: Creating R packages

1.4 Writing package vignettes
=============================

In addition to the help files in Rd format, R packages allow the
inclusion of documents in arbitrary other formats.  The standard
location for these is subdirectory `inst/doc' of a source package, the
contents will be copied to subdirectory `doc' when the package is
installed.  Pointers from package help indices to the installed
documents are automatically created.  Documents in `inst/doc' can be in
arbitrary format, however we strongly recommend to provide them in PDF
format, such that users on all platforms can easily read them.  To
ensure that they can be accessed from a browser, the file names should
start with an ASCII letter and be comprised entirely of ASCII letters
or digits or hyphen or underscore.

   A special case are documents in Sweave format, which we call
_package vignettes_.  Sweave allows the integration of LaTeX documents
and R code and is contained in package *utils* which is part of the
base R distribution, see the `Sweave' help page for details on the
document format.  Package vignettes found in directory `inst/doc' are
tested by `R CMD check' by executing all R code chunks they contain to
ensure consistency between code and documentation.  (Code chunks with
option `eval=FALSE' are not tested.) The R working directory for all
vignette tests in `R CMD check' is the _installed_ version of the `doc'
subdirectory. Make sure all files needed by the vignette (data sets,
...) are accessible by either placing them in the `inst/doc' hierarchy
of the source package, or using calls to `system.file()'.

   `R CMD build' will automatically create PDF versions of the
vignettes for distribution with the package sources.  By including the
PDF version in the package sources it is not necessary that the
vignettes can be compiled at install time, i.e., the package author can
use private LaTeX extensions which are only available on his machine.
(1)

   By default `R CMD build' will run `Sweave' on all files in Sweave
format.  If no `Makefile' is found in directory `inst/doc', then
`texi2dvi --pdf' is run on all vignettes.  Whenever a `Makefile' is
found, then `R CMD build' will try to run `make' after the `Sweave'
step, so PDF manuals can be created from arbitrary source formats
(plain LaTeX files, ...).  The first target in the `Makefile' should
take care of both creation of PDF files and cleaning up afterwards,
i.e., delete all files that shall not appear in the final package
archive.  Note that the `make' step is executed independently from the
presence of any files in Sweave format.

   It is no longer necessary to provide a `00Index.dcf' file in the
`inst/doc' directory--the corresponding information is generated
automatically from the `\VignetteIndexEntry' statements in all Sweave
files when installing from source, or when using the package builder
(*note Checking and building packages::).  The `\VignetteIndexEntry'
statement is best placed in LaTeX comment, as then no definition of the
command is necessary.

   At install time an HTML index for all vignettes is automatically
created from the `\VignetteIndexEntry' statements unless a file
`index.html' exists in directory `inst/doc'. This index is linked into
the HTML help system for each package.  If you do supply a
`inst/doc/html/index.html' file it should contain relative links only
to files under the installed `doc' directory, or perhaps (not really an
index) to HTML help files or to the `DESCRIPTION' file.

   ---------- Footnotes ----------

   (1) provided the conditions of the package's licence are met: many
would see this as incompatible with an Open Source licence.


File: R-exts.info,  Node: Submitting a package to CRAN,  Next: Package name spaces,  Prev: Writing package vignettes,  Up: Creating R packages

1.5 Submitting a package to CRAN
================================

CRAN is a network of WWW sites holding the R distributions and
contributed code, especially R packages.  Users of R are encouraged to
join in the collaborative project and to submit their own packages to
CRAN.

   Before submitting a package MYPKG, do run the following steps to
test it is complete and will install properly.  (Run from the directory
containing `MYPKG' as a subdirectory.)

  1. Run `R CMD build' to make the release `.tar.gz' file.

  2. Run `R CMD check' on the `.tar.gz' file to check that the package
     will install and will run its examples, and that the documentation
     is complete and can be processed.  If the package contains code
     that needs to be compiled, try to enable a reasonable amount of
     diagnostic messaging ("warnings") when compiling, such as e.g.
     `-Wall -pedantic' for tools from GCC, the Gnu Compiler Collection.
     If R was not configured accordingly, one can achieve this _via_
     personal `Makevars' files.  *Note Customizing package compilation:
     (R Installation and Administration)Customizing package compilation,

  3. Study the outout from running your examples, in file
     `PKG.Rcheck/PKG-Ex.Rout'.  Often warnings there indicate actual
     errors, and warnings about your mistakes (which the R developers
     are warning you that they are working around for you) will just
     annoy or confuse your users.

     If your package has tests, study their output too.

  4. Look for any problems with help file conversions.  For example, you
     should
        * Read through the PDF manual that was produced by `R CMD
          check' at `MYPKG.Rcheck/MYPKG-manual.pdf', or produce another
          copy by `R CMD Rd2dvi --pdf MYPKG'.

        * Look at the rendering of your help pages in text from within
          R.

     Many aspects of help rendering changed in R 2.10.0, and in
     particular the interpretation of comment lines (which are rendered
     as blank lines, so do not put comment lines in the middle of a
     paragraph of text).  Also, the conversion does not currently
     expand tabs in `.Rd' files, and this may need to be done manually.


Please ensure that you can run through the complete procedure with only
warnings that you understand and have reasons not to eliminate.  In
principle, packages must pass `R CMD check' without warnings to be
admitted to the main CRAN package area.  If there are warnings you
cannot eliminate (for example because you believe them to be spurious)
send an explanatory note with your submission.

   When all the testing is done, upload the `.tar.gz' file, using
`anonymous' as log-in name and your e-mail address as password, to
`ftp://CRAN.R-project.org/incoming/' (note: use `ftp'(1) and not `sftp'
to connect to this server) and send a message to <CRAN@R-project.org>
about it.  The CRAN maintainers will run these tests before putting a
submission in the main archive.

   Note also that for running LaTeX, the Debian GNU/Linux CRAN check
systems use reasonably recent versions of the Debian TexLive
distribution (`http://packages.debian.org/de/sid/texlive'); for the
Windows CRAN server, a reasonably recent version of MikTeX (including
all packages available directly for MikTeX) is employed: the Mac OS X
builders use a current full version of MacTeX.  Developers wanting to
have their vignettes use TeX packages or style files not (yet) included
in these distributions should add the corresponding style files to the
`inst/doc' subdirectory of their package.

   Note that CRAN does not accept submissions of precompiled binaries
due to security concerns, and does not allow binary executables in
packages.  Maintainers who need additional software for the Windows
binaries of their packages on CRAN have three options
  1. To arrange for installation of the package to download the
     additional software from a URL, as e.g. package *Cairo* does.

  2. To negotiate with Uwe Ligges to host the additional components on
     WinBuilder, and write a `configure.win' file to install them.
     There are many examples, e.g. package *rgdal*.

  3. To negotiate with Brian Ripley to host the package on CRAN extras,
     as was done for package *BRugs*.

Be aware that in all cases license requirements will need to be met so
you may need to supply the sources for the additional components (and
will if your package has a GPL-like license).

   ---------- Footnotes ----------

   (1) for Windows users the simplest way may be to open that URL in
Internet Explorer and (depending on the version) follow the
instructions to view it as a folder, then copy the submission to the
folder.


File: R-exts.info,  Node: Package name spaces,  Next: Writing portable packages,  Prev: Submitting a package to CRAN,  Up: Creating R packages

1.6 Package name spaces
=======================

R has a name space management system for packages.  This system allows
the package writer to specify which variables in the package should be
_exported_ to make them available to package users, and which variables
should be _imported_ from other packages.

   The current mechanism for specifying a name space for a package is to
place a `NAMESPACE' file in the top level package directory.  This file
contains _name space directives_ describing the imports and exports of
the name space.  Additional directives register any shared objects to
be loaded and any S3-style methods that are provided.  Note that
although the file looks like R code (and often has R-style comments) it
is not processed as R code.  Only very simple conditional processing of
`if' statements is implemented.

   Like other packages, packages with name spaces are loaded and
attached to the search path by calling `library'.  Only the exported
variables are placed in the attached frame.  Loading a package that
imports variables from other packages will cause these other packages to
be loaded as well (unless they have already been loaded), but they will
_not_ be placed on the search path by these implicit loads.

   Name spaces are _sealed_ once they are loaded.  Sealing means that
imports and exports cannot be changed and that internal variable
bindings cannot be changed.  Sealing allows a simpler implementation
strategy for the name space mechanism.  Sealing also allows code
analysis and compilation tools to accurately identify the definition
corresponding to a global variable reference in a function body.

   Note that adding a name space to a package changes the search
strategy.  The package name space comes first in the search, then the
imports, then the base name space and then the normal search path.

* Menu:

* Specifying imports and exports::
* Registering S3 methods::
* Load hooks::
* An example::
* Summary -- converting an existing package::
* Name spaces with S4 classes and methods::


File: R-exts.info,  Node: Specifying imports and exports,  Next: Registering S3 methods,  Prev: Package name spaces,  Up: Package name spaces

1.6.1 Specifying imports and exports
------------------------------------

Exports are specified using the `export' directive in the `NAMESPACE'
file.  A directive of the form

     export(f, g)

specifies that the variables `f' and `g' are to be exported.  (Note
that variable names may be quoted, and reserved words and non-standard
names such as `[<-.fractions' must be.)

   For packages with many variables to export it may be more convenient
to specify the names to export with a regular expression using
`exportPattern'.  The directive

     exportPattern("^[^\\.]")

exports all variables that do not start with a period.

   A package with a name space implicitly imports the base name space.
Variables exported from other packages with name spaces need to be
imported explicitly using the directives `import' and `importFrom'.
The `import' directive imports all exported variables from the
specified package(s).  Thus the directives

     import(foo, bar)

specifies that all exported variables in the packages *foo* and *bar*
are to be imported.  If only some of the exported variables from a
package are needed, then they can be imported using `importFrom'.  The
directive

     importFrom(foo, f, g)

specifies that the exported variables `f' and `g' of the package *foo*
are to be imported.

   It is possible to export variables from a name space that it has
imported from other namespaces.

   If a package only needs a few objects from another package it can
use a fully qualified variable reference in the code instead of a formal
import.  A fully qualified reference to the function `f' in package
*foo* is of the form `foo:::f'.  This is less efficient than a formal
import and also loses the advantage of recording all dependencies in
the `NAMESPACE' file, so this approach is usually not recommended.
Evaluating `foo:::f' will cause package *foo* to be loaded, but not
attached, if it was not loaded already--this can be an advantage is
delaying the loading of a rarely used package.

   Using `foo:::f' allows access to unexported objects: to confine
references to exported objects use `foo::f'.


File: R-exts.info,  Node: Registering S3 methods,  Next: Load hooks,  Prev: Specifying imports and exports,  Up: Package name spaces

1.6.2 Registering S3 methods
----------------------------

The standard method for S3-style `UseMethod' dispatching might fail to
locate methods defined in a package that is imported but not attached
to the search path.  To ensure that these methods are available the
packages defining the methods should ensure that the generics are
imported and register the methods using `S3method' directives.  If a
package defines a function `print.foo' intended to be used as a `print'
method for class `foo', then the directive

     S3method(print, foo)

ensures that the method is registered and available for `UseMethod'
dispatch.  The function `print.foo' does not need to be exported.
Since the generic `print' is defined in *base* it does not need to be
imported explicitly.  This mechanism is intended for use with generics
that are defined in a name space.  Any methods for a generic defined in
a package that does not use a name space should be exported, and the
package defining and exporting the methods should be attached to the
search path if the methods are to be found.

   (Note that function and class names may be quoted, and reserved words
and non-standard names such as `[<-' and `function' must be.)


File: R-exts.info,  Node: Load hooks,  Next: An example,  Prev: Registering S3 methods,  Up: Package name spaces

1.6.3 Load hooks
----------------

There are a number of hooks that apply to packages with name spaces.
See `help(".onLoad")' for more details.

   Packages with name spaces do not use the `.First.lib' function.
Since loading and attaching are distinct operations when a name space is
used, separate hooks are provided for each.  These hook functions are
called `.onLoad' and `.onAttach'.  They take the same arguments as
`.First.lib'; they should be defined in the name space but not exported.

   However, packages with name spaces _do_ use the `.Last.lib' function
(provided it is exported from the name space) when `detach' is called
on the package.  There is also a hook `.onUnload' which is called when
the name space is unloaded (_via_ a call to `unloadNamespace', perhaps
called by `detach(unload=TRUE)') with argument the full path to the
installed package's directory.  `.onUnload' should be defined in the
name space and not exported, but `.Last.lib' does need to be exported.

   Packages are not likely to need `.onAttach' (except perhaps for a
start-up banner); code to set options and load shared objects should be
placed in a `.onLoad' function, or use made of the `useDynLib'
directive described next.

   There can be one or more `useDynLib' directives which allows shared
objects that need to be loaded to be specified in the `NAMESPACE' file.
The directive

     useDynLib(foo)

registers the shared object `foo' for loading with `library.dynam'.
Loading of registered object(s) occurs after the package code has been
loaded and before running the load hook function.  Packages that would
only need a load hook function to load a shared object can use the
`useDynLib' directive instead.

   User-level hooks are also available: see the help on function
`setHook'.

   The `useDynLib' directive also accepts the names of the native
routines that are to be used in R _via_ the `.C', `.Call', `.Fortran'
and `.External' interface functions.  These are given as additional
arguments to the directive, for example,

     useDynLib(foo, myRoutine, myOtherRoutine)

   By specifying these names in the `useDynLib' directive, the native
symbols are resolved when the package is loaded and R variables
identifying these symbols are added to the package's name space with
these names.  These can be used in the `.C', `.Call', `.Fortran' and
`.External' calls in place of the name of the routine and the `PACKAGE'
argument.  For instance, we can call the routine `myRoutine' from R
with the code

      .Call(myRoutine, x, y)

rather than

      .Call("myRoutine", x, y, PACKAGE = "foo")

   There are at least two benefits to this approach.  Firstly, the
symbol lookup is done just once for each symbol rather than each time
it the routine is invoked. Secondly, this removes any ambiguity in
resolving symbols that might be present in several compiled DLLs.

   In some circumstances, there will already be an R variable in the
package with the same name as a native symbol. For example, we may have
an R function in the package named `myRoutine'.  In this case, it is
necessary to map the native symbol to a different R variable name. This
can be done in the `useDynLib' directive by using named arguments. For
instance, to map the native symbol name `myRoutine' to the R variable
`myRoutine_sym', we would use

     useDynLib(foo, myRoutine_sym = myRoutine, myOtherRoutine)

   We could then call that routine from R using the command

      .Call(myRoutine_sym, x, y)

   Symbols without explicit names are assigned to the R variable with
that name.

   In some cases, it may be preferable not to create R variables in the
package's name space that identify the native routines.  It may be too
costly to compute these for many routines when the package is loaded if
many of these routines are not likely to be used.  In this case, one
can still perform the symbol resolution correctly using the DLL, but do
this each time the routine is called.  Given a reference to the DLL as
an R variable, say `dll', we can call the routine `myRoutine' using the
expression

      .Call(dll$myRoutine, x, y)

   The `$' operator resolves the routine with the given name in the DLL
using a call to `getNativeSymbol'.  This is the same computation as
above where we resolve the symbol when the package is loaded. The only
difference is that this is done each time in the case of
`dll$myRoutine'.

   In order to use this dynamic approach (e.g., `dll$myRoutine'), one
needs the reference to the DLL as an R variable in the package.  The
DLL can be assigned to a variable by using the `variable = dllName'
format used above for mapping symbols to R variables.  For example, if
we wanted to assign the DLL reference for the DLL `foo' in the example
above to the variable `myDLL', we would use the following directive in
the `NAMESPACE' file:

     myDLL = useDynLib(foo, myRoutine_sym = myRoutine, myOtherRoutine)

   Then, the R variable `myDLL' is in the package's name space and
available for calls such as `myDLL$dynRoutine' to access routines that
are not explicitly resolved at load time.

   If the package has registration information (see *Note Registering
native routines::), then we can use that directly rather than
specifying the list of symbols again in the `useDynLib' directive in the
`NAMESPACE' file.  Each routine in the registration information is
specified by giving a name by which the routine is to be specified along
with the address of the routine and any information about the number and
type of the parameters.  Using the `.registration' argument of
`useDynLib', we can instruct the name space mechanism to create R
variables for these symbols.  For example, suppose we have the
following registration information for a DLL named `myDLL':

     R_CMethodDef cMethods[] = {
        {"foo", &foo, 4, {REALSXP, INTSXP, STRSXP, LGLSXP}},
        {"bar_sym", &bar, 0},
        {NULL, NULL, 0}
     };

     R_CallMethodDef callMethods[] = {
        {"R_call_sym", &R_call, 4},
        {"R_version_sym", &R_version, 0},
        {NULL, NULL, 0}
     };

   Then, the directive in the `NAMESPACE' file

     useDynLib(myDLL, .registration = TRUE)

causes the DLL to be loaded and also for the R variables `foo',
`bar_sym', `R_call_sym' and `R_version_sym' to be defined in the
package's name space.

   Note that the names for the R variables are taken from the entry in
the registration information and do not need to be the same as the name
of the native routine.  This allows the creator of the registration
information to map the native symbols to non-conflicting variable names
in R, e.g. `R_version' to `R_version_sym' for use in an R function such
as

     R_version <- function()
     {
       .Call(R_version_sym)
     }

   Using argument `.fixes' allows an automatic prefix to be added to
the registered symbols, which can be useful when working with an
existing package.  For example, package *KernSmooth* has

     useDynLib(KernSmooth, .registration = TRUE, .fixes = "F_")

which makes the R variables corresponding to the FORTRAN symbols
`F_bkde' and so on, and so avoid clashes with R code in the name space.

   More information about this symbol lookup, along with some approaches
for customizing it, is available from
`http://www.omegahat.org/examples/RDotCall'.


File: R-exts.info,  Node: An example,  Next: Summary -- converting an existing package,  Prev: Load hooks,  Up: Package name spaces

1.6.4 An example
----------------

As an example consider two packages named *foo* and *bar*.  The R code
for package *foo* in file `foo.R' is

          x <- 1
          f <- function(y) c(x,y)
          foo <- function(x) .Call("foo", x, PACKAGE="foo")
          print.foo <- function(x, ...) cat("<a foo>\n")

Some C code defines a C function compiled into DLL `foo' (with an
appropriate extension).  The `NAMESPACE' file for this package is

          useDynLib(foo)
          export(f, foo)
          S3method(print, foo)

The second package *bar* has code file `bar.R'

          c <- function(...) sum(...)
          g <- function(y) f(c(y, 7))
          h <- function(y) y+9

and `NAMESPACE' file

          import(foo)
          export(g, h)

Calling `library(bar)' loads *bar* and attaches its exports to the
search path.  Package *foo* is also loaded but not attached to the
search path.  A call to `g' produces

     > g(6)
     [1]  1 13

This is consistent with the definitions of `c' in the two settings: in
*bar* the function `c' is defined to be equivalent to `sum', but in
*foo* the variable `c' refers to the standard function `c' in *base*.


File: R-exts.info,  Node: Summary -- converting an existing package,  Next: Name spaces with S4 classes and methods,  Prev: An example,  Up: Package name spaces

1.6.5 Summary - converting an existing package
----------------------------------------------

To summarize, converting an existing package to use a name space
involves several simple steps:

   * Identify the public definitions and place them in `export'
     directives.

   * Identify S3-style method definitions and write corresponding
     `S3method' declarations.

   * Identify dependencies and replace any `require' calls by `import'
     directives (and make appropriate changes in the `Depends' and
     `Imports' fields of the `DESCRIPTION' file).

   * Replace `.First.lib' functions with `.onLoad' functions or
     `useDynLib' directives.


File: R-exts.info,  Node: Name spaces with S4 classes and methods,  Prev: Summary -- converting an existing package,  Up: Package name spaces

1.6.6 Name spaces with S4 classes and methods
---------------------------------------------

Some additional steps are needed for packages which make use of formal
(S4-style) classes and methods (unless these are purely used
internally).  The package should have `Depends: methods' in its
`DESCRIPTION' file and any classes and methods which are to be exported
need to be declared in the `NAMESPACE' file.  For example, the *stats4*
package has

     export(mle)
     importFrom(graphics, plot)
     importFrom(stats, AIC, coef, confint, logLik, optim, profile,
     	   qchisq, update, vcov)
     exportClasses(mle, profile.mle, summary.mle)
     exportMethods(BIC, coef, confint, logLik, plot, profile,
                   summary, show, update, vcov)
     export(AIC)

All S4 classes need to be listed in an `exportClasses' directive.
Alternatively, a pattern can be specified using `exportClassPattern'.
Generics for which S4 methods are defined need to be declared in an
`exportMethods' directive, and where the generics are formed by taking
over existing functions, those functions need to be imported
(explicitly unless they are defined in the `base' name space).

   Note that exporting methods on a generic in the namespace will also
export the generic, and exporting a generic in the namespace will also
export its methods.  Where a generic has been created in the package
solely to add S4 methods to it, it can be declared _via_ either or both
of `exports' or `exportMethods', but the latter seems clearer (and is
used in the *stats4* example above).  On the other hand, where a
generic is created in a package without setting any methods for it
(such as `AIC' in *stats4*), `exports' must be used.

   Further, a package using classes and methods defined in another
package needs to import them, with directives

     importClassesFrom(package, ...)
     importMethodsFrom(package, ...)

listing the classes and functions with methods respectively.  Suppose we
had two small packages *A* and *B* with *B* using *A*.  Then they could
have `NAMESPACE' files

          export(f1, ng1)
          exportMethods("[")
          exportClasses(c1)

and

          importFrom(A, ng1)
          importClassesFrom(A, c1)
          importMethodsFrom(A, f1)
          export(f4, f5)
          exportMethods(f6, "[")
          exportClasses(c1, c2)

respectively.

   Note that `importMethodsFrom' will also import any generics defined
in the namespace on those methods.

   If your package imports the whole of a name space, it will
automatically import the classes from that namespace.  It will also
import methods, but it is best to do so explicitly, especially where
there are methods being imported from more than one namespace.


File: R-exts.info,  Node: Writing portable packages,  Next: Diagnostic messages,  Prev: Package name spaces,  Up: Creating R packages

1.7 Writing portable packages
=============================

* Menu:

* Encoding issues::

   Portable packages should have simple file names: use only
alphanumeric ASCII characters and `.', and avoid those names not
allowed under Windows which are mentioned above.

   `R CMD check' provides a basic set of checks, but often further
problems emerge when people try to install and use packages submitted to
CRAN - many of these involve compiled code.  Here are some further
checks that you can do to make your package more portable.

   * If your package has a `configure' script, provide a
     `configure.win' script to be used on Windows.  The CRAN binary
     packages for Windows are built automatically, and if your package
     does not build without intervention it is unlikely to be easily
     available to a high proportion of R users.

   * Make use of the abilities of your compilers to check the
     standards-conformance of your code.  For example, `gcc' can be used
     with options `-Wall -pedantic' to alert you to potential problems.
     Do not be tempted to assume that these are pure pedantry: for
     example R is still used on platforms where the C compiler does not
     accept C++/C99 comments (starting `//').

     If you use FORTRAN, `ftnchek'
     (`http://www.dsm.fordham.edu/~ftnchek/') provides thorough testing
     of conformance to the standard.

   * Do be very careful with passing arguments between R, C and FORTRAN
     code.  In particular, `long' in C will be 32-bit on most R
     platforms (including those mostly used by the CRAN maintainers),
     but 64-bit on many modern Unix and Linux platforms.  It is rather
     unlikely that the use of `long' in C code has been thought
     through: if you need a longer type than `int' you should use a
     configure test for a C99 type such as `int_fast64_t' (and failing
     that, `long long') and typedef your own type to be `long' or `long
     long', or use another suitable type (such as `size_t').  Note that
     `integer' in FORTRAN corresponds to `int' in C on all R platforms.

   * Errors in memory allocation and reading/writing outside arrays are
     very common causes of crashes (e.g., segfaults) on some machines.
     See *Note Using valgrind:: for a tool which can be used to look
     for this.

   * Many platforms will allow unsatisfied entry points in compiled
     code, but will crash the application (here R) if they are ever
     used.  Some (notably Windows) will not.  Looking at the output of

          nm -pg mypkg.so  # or other extension such as `.sl' or `.dylib'

     and checking if any of the symbols marked `U' is unexpected is a
     good way to avoid this.

   * Conflicts between symbols in DLLs are handled in very
     platform-specific ways.  Good ways to avoid trouble are to make as
     many symbols as possible static (check with `nm -pg'), and to use
     unusual names, as well as ensuring you have used the `PACKAGE'
     argument that `R CMD check' checks for.



File: R-exts.info,  Node: Encoding issues,  Prev: Writing portable packages,  Up: Writing portable packages

1.7.1 Encoding issues
---------------------

Care is needed if your package contains non-ASCII text, and in
particular if it is intended to be used in more than one locale.  It is
possible to mark the encoding used in the `DESCRIPTION' file and in
`.Rd' files, as discussed elsewhere in this manual.  What was not
possible before R 2.5.0 was to mark the encoding used by character
strings in R: if you want your package to work with earlier versions of
R please consult the advice in the R 2.4.x version of this manual.

   First, consider carefully if you really need non-ASCII text.  Most
users of R will only be able to view correctly text in their native
language group (e.g. Western European, Eastern European, Simplified
Chinese) and ASCII.  Other characters may not be rendered at all,
rendered incorrectly, or cause your R code to give an error.  For
documentation, marking the encoding and including ASCII
transliterations is likely to do a reasonable job.

   Function `showNonASCII' in package *tools* can help in finding
non-ASCII bytes in files.

   The most favourable circumstance is using UTF-8-encoded text in a
package that will only ever be used in a UTF-8 locale (and hence not on
Windows, for example).  In that case it is likely that text will be
rendered correctly in the terminal/console used to run R, and files
written will be readable by other UTF-8-aware applications.  However,
plotting will be problematic.  On-screen plotting using the `X11()'
device needs to find a font that covers the glyphs used, and this will
be machine-dependent: you may have Russian or Japanese fonts installed
but your users may not.  Using `postscript' or `pdf' will choose a
default 8-bit encoding depending on the language of the UTF-8 locale,
and your users would need to be told how to select the `encoding'
argument.  As from R 2.7.0 UTF-8-encoded text works reasonably well on
Windows using the `Rgui' console and the `windows' family of devices,
since they work internally in Unicode (UCS-2).

   Another fairly common scenario is where a package will only be used
in one language, e.g. French.  It is not very safe to assume that all
such users would have their computers set to a French locale, but let us
assume so.  The problem then is that there are several possible
encodings for French locales, the most common ones being `CP1252'
(Windows), `ISO 8859-1' (latin-1), `ISO 8859-15' (latin-9 which
includes the Euro), and `UTF-8'.  For characters in the French language
the first three agree, but they do not agree with `UTF-8'.  Further,
you (or different users of your machine) can run R in different locales
in different sessions, say `fr_CA.utf8' one day and `fr_CH.iso88591'
the next.  Declaring the encoding as either `latin1' or `UTF-8' in the
`DESCRIPTION' file will enable this to work.  If you have character
data in `.rda' files (for use by `data' or LazyData) these need to have
been prepared and `save'd in R 2.5.0 or later in an appropriate locale
(or marked _via_ `Encoding').  For example (from package *FactoMineR*
version `1.02'):

     > library(FactoMineR)
     > data(wine)
     > Encoding(names(wine)) <- "latin1"
     > Encoding(levels(wine$Terroir)) <- "latin1"
     > save(wine, file="wine.rda")

was used to update a `.rda' file.

   From R 2.10.0 there is a fairly portable(1) way to have arbitrary
text in character strings (only) in your R code, which is to supply
them in Unicode as `\uxxxx' escapes.  If there are any characters not
in the current encoding the parser will encode the character string as
UTF-8 and mark it as such.  A variation of this approach that has
worked for Latin-1 text since R 2.5.0 is to enter the text with `\x'
escapes and using `Encoding(x) <- "latin1"' to declare its encoding,
but that may not work in future versions of R.

   If you want to run `R CMD check' on a Unix-alike over a package that
sets the encoding you may need to specify a suitable locale _via_
environment variable `R_ENCODING_LOCALES'.  The default is equivalent
to the value

     "latin1=en_US:latin2=pl_PL:UTF-8=en_US.utf8:latin9=fr_FR.iso885915@euro"

(which is appropriate for a system based on `glibc') except that if the
current locale is UTF-8 when the package code is translated to UTF-8
for syntax checking.

   ---------- Footnotes ----------

   (1) this has worked on Windows since R 2.7.0, and works now on all
platforms.


File: R-exts.info,  Node: Diagnostic messages,  Next: Internationalization,  Prev: Writing portable packages,  Up: Creating R packages

1.8 Diagnostic messages
=======================

Now that diagnostic messages can be made available for translation, it
is important to write them in a consistent style.  Using the tools
described in the next section to extract all the messages can give a
useful overview of your consistency (or lack of it).

   Some guidelines follow.

   * Messages are sentence fragments, and not viewed in isolation.  So
     it is conventional not to capitalize the first word and not to end
     with a period (or other punctuation).

   * Try not to split up messages into small pieces.  In C error
     messages use a single format string containing all English words
     in the messages.

     In R error messages do not construct a message with `paste' (such
     messages will not be translated) but _via_ multiple arguments to
     `stop' or `warning', or _via_ `gettextf'.

   * Do not use colloquialisms such as "can't" and "don't".

   * If possible, make quotation marks part of your message as different
     languages have different conventions.  In R messages this means not
     using `sQuote' or `dQuote' except where the argument is a variable.

     Conventionally single quotation marks are used for quotations such
     as

          'ord' must be a positive integer, at most the number of knots

     and double quotation marks when referring to an R character string
     such as

          'format' must be "normal" or "short" - using "normal"

     Since ASCII does not contain directional quotation marks, it is
     best to use `'' and let the translator (including automatic
     translation) use directional quotations where available.  The
     range of quotation styles is immense: unfortunately we cannot
     reproduce them in a portable `texinfo' document.  But as a taster,
     some languages use `up' and `down' (comma) quotes rather than left
     or right quotes, and some use guillemets (and some use what Adobe
     calls `guillemotleft' to start and others use it to end).

   * Occasionally messages need to be singular or plural (and in other
     languages there may be no such concept or several plural forms -
     Slovenian has four).  So avoid constructions such as was once used
     in `library'

          if((length(nopkgs) > 0) && !missing(lib.loc)) {
              if(length(nopkgs) > 1)
                  warning("libraries ",
                          paste(sQuote(nopkgs), collapse = ", "),
                          " contain no packages")
              else
                  warning("library ", paste(sQuote(nopkgs)),
                          " contains no package")
          }

     and was replaced by

          if((length(nopkgs) > 0) && !missing(lib.loc)) {
              pkglist <- paste(sQuote(nopkgs), collapse = ", ")
              msg <- sprintf(ngettext(length(nopkgs),
                               "library %s contains no packages",
                               "libraries %s contain no packages"),
                             pkglist)
              warning(msg, domain=NA)
          }

     Note that it is much better to have complete clauses as here, since
     in another language one might need to say `There is no package in
     library %s' or `There are no packages in libraries %s'.



File: R-exts.info,  Node: Internationalization,  Next: CITATION files,  Prev: Diagnostic messages,  Up: Creating R packages

1.9 Internationalization
========================

There are mechanisms to translate the R- and C-level error and warning
messages.  There are only available if R is compiled with NLS support
(which is requested by `configure' option `--enable-nls', the default).

   The procedures make use of `msgfmt' and `xgettext' which are part of
GNU `gettext' and this will need to be installed: Windows users can
find pre-compiled binaries at the GNU archive mirrors and packaged with
the `poEdit' package
(`http://poedit.sourceforge.net/download.php#win32').

* Menu:

* C-level messages::
* R messages::
* Installing translations::
* Makefile support::


File: R-exts.info,  Node: C-level messages,  Next: R messages,  Prev: Internationalization,  Up: Internationalization

1.9.1 C-level messages
----------------------

The process of enabling translations is

   * In a header file that will be included in all the C files
     containing messages that should be translated, declare

          #include <R.h>  /* to include Rconfig.h */

          #ifdef ENABLE_NLS
          #include <libintl.h>
          #define _(String) dgettext ("PKG", String)
          /* replace PKG as appropriate */
          #else
          #define _(String) (String)
          #endif

   * For each message that should be translated, wrap it in `_(...)',
     for example

          error(_("'ord' must be a positive integer"));

     If you want to use different messages for singular and plural
     forms, you need to add

          #ifndef ENABLE_NLS
          #define dngettext(pkg, String, StringP, N) (N > 1 ? StringP: String)
          #endif

     and mark strings by

          dngettext(("PKG", <SINGULAR STRING>, <PLURAL STRING>, n)

     (This is only supported as from R 2.10.0, and will not work on
     Windows for earlier versions of R.)

   * In the package's `src' directory run

          xgettext --keyword=_ -o PKG.pot *.c


   The file `src/PKG.pot' is the template file, and conventionally this
is shipped as `po/PKG.pot'.  A translator to another language makes a
copy of this file and edits it (see the `gettext' manual) to produce
say `LL.po', where LL is the code for the language in which the
translation is to be used.  (This file would be shipped in the `po'
directory.)  Next run `msgfmt' on `LL.po' to produce `LL.mo', and copy
that to `inst/po/LL/LC_MESSAGES/PKG.mo'.  Now when the package is
loaded after installation it will look for translations of its messages
in the `po/LANG/LC_MESSAGES/PKG.mo' file for any language LANG that
matches the user's preferences (_via_ the setting of the `LANGUAGE'
environment variable or from the locale settings).


File: R-exts.info,  Node: R messages,  Next: Installing translations,  Prev: C-level messages,  Up: Internationalization

1.9.2 R messages
----------------

Mechanisms to support the automatic translation of R `stop', `warning'
and `message' messages are in place, most easily if the package has a
name space.  They make use of message catalogs in the same way as
C-level messages, but using domain `R-PKG' rather than `PKG'.
Translation of character strings inside `stop', `warning' and `message'
calls is automatically enabled, as well as other messages enclosed in
calls to `gettext' or `gettextf'.  (To suppress this, use argument
`domain=NA'.)

   Tools to prepare the `R-PKG.pot' file are provided in package
*tools*: `xgettext2pot' will prepare a file from all strings occurring
inside `gettext'/`gettextf', `stop', `warning' and `message' calls.
Some of these are likely to be spurious and so the file is likely to
need manual editing.  `xgettext' extracts the actual calls and so is
more useful when tidying up error messages.

   Translation of messages which might be singular or plural can be very
intricate: languages can have up to four different forms.  The R
function `ngettext' provides an interface to the C function of the same
name, and will choose an appropriate singular or plural form for the
selected language depending on the value of its first argument `n'.

   Packages without name spaces will need to use `domain="R-PKG"'
explicitly in calls to `stop', `warning', `message',
`gettext'/`gettextf' and `ngettext'.


File: R-exts.info,  Node: Installing translations,  Next: Makefile support,  Prev: R messages,  Up: Internationalization

1.9.3 Installing translations
-----------------------------

Once the template files have been created, translations can be made.
Conventional translations have file extension `.po' and are placed in
the `po' subdirectory of the package with a name that is either `LL.po'
or `R-LL.po' for translations of the C and R messages respectively to
language with code `LL'.

   *Note Localization of messages: (R-admin)Localization of messages,
for details of language codes.

   Translations need to be prepared and installed in `inst/po/' to be
usable once the package is installed.  To do this use the appropriate
lines of

     mkdir -p inst/po/LL/LC_MESSAGES
     msgfmt -c --statistics -o inst/po/LL/LC_MESSAGES/R-PKG.mo po/R-LL.po
     msgfmt -c --statistics -o inst/po/LL/LC_MESSAGES/PKG.mo po/LL.po

from the package's top-level directory.  Using `-c' does some useful
validity checks, and `--statistics' notes the coverage.


File: R-exts.info,  Node: Makefile support,  Prev: Installing translations,  Up: Internationalization

1.9.4 Makefile support
----------------------

As from R 2.10.0 there is some makefile support in the `po' directory
of the R sources.  To use this to create the template files, use

     mkdir -p PKGDIR/po

where `PKGDIR' is the top-level directory of the package sources.  If
the package has C source files in its `src' directory that are marked
for translation, use

     touch PKGDIR/po/PKG.pot

to create a dummy template file.  Then

     cd R_BUILD_DIR/po
     make pkg-update PKG=PKG PKGDIR=PKGDIR

will create a template file of R messages and update any template of C
messages.  It will also prepare and install a translation for the
`en@quot' pseudo-language, which if selected interprets (single and
double) quotes in their directional forms in suitable (e.g. UTF-8)
locales.

   If translations to new languages are added in the `PKGDIR/po'
directory, running the same `make' command will check and then install
the translations.

   If the package sources are updated, the same `make' command will
update the template files, merge the changes into the translation `.po'
files and then installed the updated translations.  You will often see
that merging marks translations as `fuzzy' and this is reported in the
coverage statistics.  As fuzzy translations are _not_ used, this is an
indication that the translation files need human attention.

   This support is only for Unix-alikes, and the tools did not work
correctly on at least one Mac OS X system.


File: R-exts.info,  Node: CITATION files,  Next: Package types,  Prev: Internationalization,  Up: Creating R packages

1.10 CITATION files
===================

An installed file named `CITATION' will be used by the `citation()'
function.  (To be installed, it needed to be in the `inst' subdirectory
of the package sources.)

   The `CITATION' file is parsed as R code (in the package's declared
encoding(1), defaulting to latin-1).  If no such file is present,
`citation' generates a standard contents, and an example of what that
would look like as a `CITATION' file can be seen in recommended package
*nlme* (see below): recommended packages *boot*, *cluster* and *mgcv*
have further examples.

   A `CITATION' file will contain calls to the functions `citHeader',
`citEntry' and (optionally) `citFooter'. Here is that for *nlme*,
re-formatted:

     citHeader("To cite package 'nlme' in publications use:")

     desc <- packageDescription("nlme")
     year <- sub(".*(2[[:digit:]]{3})-.*", "\\1", desc$Date)
     vers <- paste("R package version", desc$Version)

     citEntry(entry="Manual",
              title = "nlme: Linear and Nonlinear Mixed Effects Models",
              author = personList(as.person("Jose Pinheiro"),
                                  as.person("Douglas Bates"),
                                  as.person("Saikat DebRoy"),
                                  as.person("Deepayan Sarkar"),
                                  as.person("the R Core team")),
              year = year,
              note = vers,

              textVersion =
              paste("Jose Pinheiro, Douglas Bates, Saikat DebRoy,",
                    "Deepayan Sarkar and the R Core team (",
                    year,
                    "). nlme: Linear and Nonlinear Mixed Effects Models. ",
                    vers, ".", sep=""))

   Note the way that information that may need to be updated is picked
up from the `DESCRIPTION' file - it is tempting to hardcode such
information, but it normally then gets outdated.  See `?citEntry' for
further details of the information which can be provided.

   The `CITATION' file should itself produce no output when `source'-d.

   ---------- Footnotes ----------

   (1) as from R 2.8.0: R 2.7.x read it in latin-1, and earlier
versions in the current encoding of the R session


File: R-exts.info,  Node: Package types,  Next: Services,  Prev: CITATION files,  Up: Creating R packages

1.11 Package types
==================

The `DESCRIPTION' file has an optional field `Type' which if missing is
assumed to be `Package', the sort of extension discussed so far in this
chapter.  Currently two other types are recognized, both of which need
write permission in the R installation tree.

* Menu:

* Frontend::
* Translation::


File: R-exts.info,  Node: Frontend,  Next: Translation,  Prev: Package types,  Up: Package types

1.11.1 Frontend
---------------

This is a rather general mechanism, designed for adding new front-ends
such as the former *gnomeGUI* package (see the `Archve' area on CRAN).
If a `configure' file is found in the top-level directory of the
package it is executed, and then if a `Makefile' is found (often
generated by `configure'), `make' is called.  If `R CMD INSTALL
--clean' is used `make clean' is called.  No other action is taken.

   `R CMD build' can package up this type of extension, but `R CMD
check' will check the type and skip it.


File: R-exts.info,  Node: Translation,  Prev: Frontend,  Up: Package types

1.11.2 Translation
------------------

Conventionally, a translation package for language LL is called
*Translation-LL* and has `Type: Translation'.  It needs to contain the
directories `share/locale/LL' and `library/PKGNAME/po/LL', or at least
those for which translations are available.  The files `.mo' are
installed in the parallel places in the R installation tree.

   For example, a package *Translation-it* might be prepared from an
installed (and tested) version of R by

     mkdir Translation-it
     cd Translation-it
     (cd $R_HOME; tar cf - share/locale/it library/*/po/it) | tar xf -
     # the next step is not needed on Windows
     msgfmt -c -o share/locale/it/LC_MESSAGES/RGui.mo $R_SRC_HOME/po/RGui-it.gmo
     # create a DESCRIPTION file
     cd ..
     R CMD build Translation-it

   It is probably appropriate to give the package a version number
based on the version of R which has been translated.  So the
`DESCRIPTION' file might look like

     Package: Translation-it
     Type: Translation
     Version: 2.2.1-1
     Title: Italian Translations for R 2.2.1
     Description: Italian Translations for R 2.2.1
     Author: The translators
     Maintainer: Some Body <somebody@some.where.net>
     License: GPL (>= 2)


File: R-exts.info,  Node: Services,  Prev: Package types,  Up: Creating R packages

1.12 Services
=============

Several members of the R project have set up services to assist those
writing R packages, particularly those intended for public distribution.

   win-builder.r-project.org (http://win-builder.r-project.org) offers
the automated preparation of Windows binaries from well-tested source
packages.

   R-Forge (R-Forge.r-project.org (http://R-Forge.r-project.org)) and
RForge (www.rforge.net (http://www.rforge.net)) are similar services
with similar names.  Both provide source-code management through SVN,
daily building and checking, mailing lists and a repository that can be
accessed _via_ `install.packages' (and as from R 2.9.0, R-Forge can be
selected by `setRepositories' and the GUI menus that use it).  Package
developers have the opportunity to present their work on the basis of
project websites or news announcements.  Mailing lists, forums or wikis
provide useRs with convenient instruments for discussions and for
exchanging information between developers and/or interested useRs.


File: R-exts.info,  Node: Writing R documentation files,  Next: Tidying and profiling R code,  Prev: Creating R packages,  Up: Top

2 Writing R documentation files
*******************************

* Menu:

* Rd format::
* Sectioning::
* Marking text::
* Lists and tables::
* Cross-references::
* Mathematics::
* Insertions::
* Indices::
* Platform-specific sections::
* Conditional text::
* Dynamic pages::
* Encoding::
* Processing Rd format::
* Back-compatibility issues::


File: R-exts.info,  Node: Rd format,  Next: Sectioning,  Prev: Writing R documentation files,  Up: Writing R documentation files

2.1 Rd format
=============

R objects are documented in files written in "R documentation" (Rd)
format, a simple markup language much of which closely resembles
(La)TeX, which can be processed into a variety of formats, including
LaTeX, HTML and plain text.  The translation is carried out by
functions in the *tools* package called by the script `Rdconv' in
`R_HOME/bin' and by the installation scripts for packages.

   The R distribution contains more than 1200 such files which can be
found in the `src/library/PKG/man' directories of the R source tree,
where PKG stands for one of the standard packages which are included in
the R distribution.

   As an example, let us look at a simplified version of
`src/library/base/man/load.Rd' which documents the R function `load'.

          % File src/library/base/man/load.Rd
          \name{load}
          \alias{load}
          \title{Reload Saved Datasets}
          \description{
            Reload the datasets written to a file with the function
            \code{save}.
          }
          \usage{
          load(file, envir = parent.frame())
          }
          \arguments{
            \item{file}{a connection or a character string giving the
              name of the file to load.}
            \item{envir}{the environment where the data should be
              loaded.}
          }
          \seealso{
            \code{\link{save}}.
          }
          \examples{
          ## save all data
          save(list = ls(), file= "all.Rdata")

          ## restore the saved values to the current environment
          load("all.Rdata")

          ## restore the saved values to the workspace
          load("all.Rdata", .GlobalEnv)
          }
          \keyword{file}

   An Rd file consists of three parts.  The header gives basic
information about the name of the file, the topics documented, a title,
a short textual description and R usage information for the objects
documented.  The body gives further information (for example, on the
function's arguments and return value, as in the above example).
Finally, there is an optional footer with keyword information.  The
header is mandatory.

   See "Guidelines for Rd files"
(http://developer.r-project.org/Rds.html) for guidelines for writing
documentation in Rd format which should be useful for package writers.  The
R generic function `prompt' is used to construct a bare-bones Rd file
ready for manual editing.  Methods are defined for documenting
functions (which fill in the proper function and argument names) and
data frames.  There are also functions `promptData', `promptPackage',
`promptClass', and `promptMethods' for other types of Rd file.

   The general syntax of Rd files is summarized below.  For a detailed
technical discussion of current Rd syntax, see "Parsing Rd files"
(http://developer.r-project.org/parseRd.pdf).  Note that there have
been a number of changes to the Rd format over the years, which can be
important if a package is intended to be used with earlier versions of
R.  See *Note Back-compatibility issues:: for notes on earlier versions
of the Rd format.

   As of R 2.10.0, the syntax of Rd files consists of three types of
text input.  The most common is LaTeX-like, with the backslash used as
a prefix on markup (e.g. `\alias'), and braces used to indicate
arguments (e.g. `{load}').  The least common type of text is verbatim
text, where no markup is processed. The third type is R-like, intended
for R code, but allowing some embedded macros.  Quoted strings within
R-like text are handled specially: regular character escapes such as
`\n' may be entered as-is.  Only markup starting with `\l' (e.g.
`\link') or `\v' (e.g. `\var') will be recognized within quoted
strings.  The rarely used vertical tab `\v' must be entered as `\\v'.

   Each macro defines the input type for its argument.  For example, the
file initially uses LaTeX-like syntax, and this is also used in the
`\description' section, but the `\usage' section uses R-like syntax,
and the `\alias' macro uses verbatim syntax.  Comments run from a
percent symbol `%' to the end of the line in all types of text (as on
the first line of the `load' example).

   Because backslashes, braces and percent symbols have special
meaning, to enter them into text sometimes requires escapes using a
backslash.  In general balanced braces do not need to be escaped, but
percent symbols always do.  For the complete list of macros and rules
for escapes, see "Parsing Rd files"
(http://developer.r-project.org/parseRd.pdf).

* Menu:

* Documenting functions::
* Documenting data sets::
* Documenting S4 classes and methods::
* Documenting packages::


File: R-exts.info,  Node: Documenting functions,  Next: Documenting data sets,  Prev: Rd format,  Up: Rd format

2.1.1 Documenting functions
---------------------------

The basic markup commands used for documenting R objects (in
particular, functions) are given in this subsection.

`\name{NAME}'
     NAME typically(1) is the basename of the Rd file containing the
     documentation.  It is the "name" of the Rd object represented by
     the file and has to be unique in a package.  To avoid problems
     with indexing the package manual, it may not contain `!' `|' nor
     `@'.  (LaTeX special characters are allowed, but may not be
     collated correctly in the index.)  There can only be one `\name'
     entry in a file, and it must not contain any markup.

`\alias{TOPIC}'
     The `\alias' entries specify all "topics" the file documents.
     This information is collected into index data bases for lookup by
     the on-line (plain text and HTML) help systems.  The TOPIC can
     contain spaces, but (for historical reasons) leading and trailing
     spaces will be stripped.  Percent has always needed to be escaped
     by backslash, and as from R 2.9.0 a left brace should be.

     There may be several `\alias' entries.  Quite often it is
     convenient to document several R objects in one file.  For example,
     file `Normal.Rd' documents the density, distribution function,
     quantile function and generation of random variates for the normal
     distribution, and hence starts with

          \name{Normal}
          \alias{Normal}
          \alias{dnorm}
          \alias{pnorm}
          \alias{qnorm}
          \alias{rnorm}

     Also, it is often convenient to have several different ways to
     refer to an R object, and an `\alias' does not need to be the name
     of an object.

     Note that the `\name' is not necessarily a topic documented, and if
     so desired it needs to have an explicit `\alias' entry (as in this
     example).

`\title{TITLE}'
     Title information for the Rd file.  This should be capitalized,
     not end in a period, and not use any markup (which would cause
     problems for hypertext search).  Use of characters other than
     English text and punctuation (e.g., `<') may limit portability.
     There must be one (and one only) `\title' section in a help file.

`\description{...}'
     A short description of what the function(s) do(es) (one paragraph,
     a few lines only).  (If a description is "too long" and cannot
     easily be shortened, the file probably tries to document too much
     at once.)  This is mandatory except for package-overview files.

`\usage{FUN(ARG1, ARG2, ...)}'
     One or more lines showing the synopsis of the function(s) and
     variables documented in the file.  These are set in typewriter
     font.  This is an R-like command.

     The usage information specified should match the function
     definition _exactly_ (such that automatic checking for consistency
     between code and documentation is possible).

     It is no longer advisable to use `\synopsis' for the actual
     synopsis and show modified synopses in the `\usage'.  Support for
     `\synopsis' will be removed eventually.  To indicate that a
     function can be "used" in several different ways, depending on the
     named arguments specified, use section `\details'.  E.g.,
     `abline.Rd' contains

          \details{
            Typical usages are
          \preformatted{
          abline(a, b, untf = FALSE, \dots)
          ......
          }

     Use `\method{GENERIC}{CLASS}' to indicate the name of an S3 method
     for the generic function GENERIC for objects inheriting from class
     `"CLASS"'.  In the printed versions, this will come out as GENERIC
     (reflecting the understanding that methods should not be invoked
     directly but _via_ method dispatch), but `codoc()' and other QC
     tools always have access to the full name.

     For example, `print.ts.Rd' contains

          \usage{
          \method{print}{ts}(x, calendar, \dots)
          }

     which will print as

          Usage:

               ## S3 method for class 'ts':
               print(x, calendar, ...)

     Usage for replacement functions should be given in the style of
     `dim(x) <- value' rather than explicitly indicating the name of the
     replacement function (`"dim<-"' in the above).  Similarly, one can
     use `\method{GENERIC}{CLASS}(ARGLIST) <- value' to indicate the
     usage of an S3 replacement method for the generic replacement
     function `"GENERIC<-"' for objects inheriting from class `"CLASS"'.

     Usage for S3 methods for extracting or replacing parts of an
     object, S3 methods for members of the Ops group, and S3 methods
     for user-defined (binary) infix operators (`%XXX%') follows the
     above rules, using the appropriate function names.  E.g.,
     `Extract.factor.Rd' contains

          \usage{
          \method{[}{factor}(x, \dots, drop = FALSE)
          \method{[[}{factor}(x, \dots)
          \method{[}{factor}(x, \dots) <- value
          }

     which will print as

          Usage:

               ## S3 method for class 'factor':
               x[..., drop = FALSE]
               ## S3 method for class 'factor':
               x[[...]]
               ## S3 replacement method for class 'factor':
               x[...] <- value

     Versions of R since at least 2.0.0 accept `\S3method' as an
     alternative to `\method'.

`\arguments{...}'
     Description of the function's arguments, using an entry of the form

          \item{ARG_I}{DESCRIPTION OF ARG_I.}

     for each element of the argument list.  (Note that there is no
     whitespace between the three parts of the entry.) There may be
     optional text outside the `\item' entries, for example to give
     general information about groups of parameters.

`\details{...}'
     A detailed if possible precise description of the functionality
     provided, extending the basic information in the `\description'
     slot.

`\value{...}'
     Description of the function's return value.

     If a list with multiple values is returned, you can use entries of
     the form

          \item{COMP_I}{DESCRIPTION OF COMP_I.}

     for each component of the list returned.  Optional text may
     precede(2)  this list (see for example the help for `rle').  Note
     that `\value' is implicitly a `\describe' environment, so that
     environment should not be used for listing components, just
     individual `\item{}{}' entries.

`\references{...}'
     A section with references to the literature.  Use `\url{}' for web
     pointers.

`\note{...}'
     Use this for a special note you want to have pointed out.

     For example, `pie.Rd' contains

          \note{
            Pie charts are a very bad way of displaying information.
            The eye is good at judging linear measures and bad at
            judging relative areas.
            ......
          }

`\author{...}'
     Information about the author(s) of the Rd file.  Use `\email{}'
     without extra delimiters (`( )' or `< >') to specify email
     addresses, or `\url{}' for web pointers.

`\seealso{...}'
     Pointers to related R objects, using `\code{\link{...}}' to refer
     to them (`\code' is the correct markup for R object names, and
     `\link' produces hyperlinks in output formats which support this.
     *Note Marking text::, and *Note Cross-references::).

`\examples{...}'
     Examples of how to use the function.  Code in this section is set
     in typewriter font without reformatting and is run by `example()'
     unless marked otherwise (see below).

     Examples are not only useful for documentation purposes, but also
     provide test code used for diagnostic checking of R code.  By
     default, text inside `\examples{}' will be displayed in the output
     of the help page and run by `example()' and by `R CMD check'.  You
     can use `\dontrun{}' for text that should only be shown, but not
     run, and `\dontshow{}' for extra commands for testing that should
     not be shown to users, but will be run by `example()'.
     (Previously this was called `\testonly', and that is still
     accepted.)

     Text inside `\dontrun{}' is verbatim, but the other parts of the
     `\examples' section are R-like text.

     For example,

          x <- runif(10)       # Shown and run.
          \dontrun{plot(x)}    # Only shown.
          \dontshow{log(x)}    # Only run.

     Thus, example code not included in `\dontrun' must be executable!
     In addition, it should not use any system-specific features or
     require special facilities (such as Internet access or write
     permission to specific directories).  Text included in `\dontrun'
     is indicated by comments in the processed help files: it need not
     be valid R code but the escapes must still be used for `%', `\'
     and unpaired braces as in other verbatim text.

     Data needed for making the examples executable can be obtained by
     random number generation (for example, `x <- rnorm(100)'), or by
     using standard data sets listed by `data()' (see `?data' for more
     info).

     Finally, there is `\donttest', used (at the beginning of a separate
     line) to mark code that should be run by `examples()' but not by
     `R CMD check'.  This should be needed only occasionally but can be
     used for code which might fail in circumstances that are hard to
     test for, for example in some locales.  (Use e.g. `capabilities()'
     to test for features needed in the examples wherever possible, and
     you can also use `try()' or `trycatch()'.)

     There should be only one `\examples' section per file, and only the
     first will be used.

`\keyword{KEY}'
     Each `\keyword' entry should specify a single keyword, preferably
     one of the standard keywords as listed in file `KEYWORDS' in the R
     documentation directory (default `R_HOME/doc').  Use e.g.
     `RShowDoc("KEYWORDS")' to inspect the standard keywords from within
     R.  There can be more than one `\keyword' entry if the R object
     being documented falls into more than one category, or none.

     The special keyword `internal' marks a page of internal objects
     that are not part of the package's API.  If the help page for
     object `foo' has keyword `internal', then `help(foo)' gives this
     help page, but `foo' is excluded from several object indices,
     including the alphabetical list of objects in the HTML help system.

     `help.search()' can search by keyword, including user-defined
     values: however the `Search Engine & Keywords' HTML page accessed
     _via_ `help.start()' provides single-click access only to a
     pre-defined list of keywords.

   ---------- Footnotes ----------

   (1) There can be exceptions: for example Rd files are not allowed to
start with a dot, and have to be uniquely named on a case-insensitive
file system.

   (2) Text between or after list items was discarded prior to R
2.10.0, and is discouraged.


File: R-exts.info,  Node: Documenting data sets,  Next: Documenting S4 classes and methods,  Prev: Documenting functions,  Up: Rd format

2.1.2 Documenting data sets
---------------------------

The structure of Rd files which document R data sets is slightly
different.  Sections such as `\arguments' and `\value' are not needed
but the format and source of the data should be explained.

   As an example, let us look at `src/library/datasets/man/rivers.Rd'
which documents the standard R data set `rivers'.

          \name{rivers}
          \docType{data}
          \alias{rivers}
          \title{Lengths of Major North American Rivers}
          \description{
            This data set gives the lengths (in miles) of 141 \dQuote{major}
            rivers in North America, as compiled by the US Geological
            Survey.
          }
          \usage{rivers}
          \format{A vector containing 141 observations.}
          \source{World Almanac and Book of Facts, 1975, page 406.}
          \references{
            McNeil, D. R. (1977) \emph{Interactive Data Analysis}.
            New York: Wiley.
          }
          \keyword{datasets}

   This uses the following additional markup commands.

`\docType{...}'
     Indicates the "type" of the documentation object.  Always `data'
     for data sets, and `package' for `PKG-package.Rd' overview files.

`\format{...}'
     A description of the format of the data set (as a vector, matrix,
     data frame, time series, ...).  For matrices and data frames this
     should give a description of each column, preferably as a list or
     table.  *Note Lists and tables::, for more information.

`\source{...}'
     Details of the original source (a reference or URL).  In addition,
     section `\references' could give secondary sources and usages.

   Note also that when documenting data set BAR,

   * The `\usage' entry is always `BAR' or (for packages which do not
     use lazy-loading of data) `data(BAR)'.  (In particular, only
     document a _single_ data object per Rd file.)

   * The `\keyword' entry should always be `datasets'.

   If `BAR' is a data frame, documenting it as a data set can be
initiated _via_ `prompt(BAR)'.  Otherwise, the `promptData' function
may be used.


File: R-exts.info,  Node: Documenting S4 classes and methods,  Next: Documenting packages,  Prev: Documenting data sets,  Up: Rd format

2.1.3 Documenting S4 classes and methods
----------------------------------------

There are special ways to use the `?'  operator, namely `class?TOPIC'
and `methods?TOPIC', to access documentation for S4 classes and
methods, respectively.  This mechanism depends on conventions for the
topic names used in `\alias' entries.  The topic names for S4 classes
and methods respectively are of the form

     CLASS-class
     GENERIC,SIGNATURE_LIST-method

where SIGNATURE_LIST contains the names of the classes in the signature
of the method (without quotes) separated by `,' (without whitespace),
with `ANY' used for arguments without an explicit specification.  E.g.,
`genericFunction-class' is the topic name for documentation for the S4
class `"genericFunction"', and `coerce,ANY,NULL-method' is the topic
name for documentation for the S4 method for `coerce' for signature
`c("ANY", "NULL")'.

   Skeletons of documentation for S4 classes and methods can be
generated by using the functions `promptClass()' and `promptMethods()'
from package *methods*.  If it is necessary or desired to provide an
explicit function declaration (in a `\usage' section) for an S4 method
(e.g., if it has "surprising arguments" to be mentioned explicitly),
one can use the special markup

     \S4method{GENERIC}{SIGNATURE_LIST}(ARGUMENT_LIST)

(e.g., `\S4method{coerce}{ANY,NULL}(from, to)').

   To make full use of the potential of the on-line documentation
system, all user-visible S4 classes and methods in a package should at
least have a suitable `\alias' entry in one of the package's Rd files.
If a package has methods for a function defined originally somewhere
else, and does not change the underlying default method for the
function, the package is responsible for documenting the methods it
creates, but not for the function itself or the default method.

   An S4 replacement method is documented in the same way as an S3 one:
see the description of  `\method' in *Note Documenting functions::.

   See `help("Documentation", package = "methods")' for more
information on using and creating on-line documentation for S4 classes
and methods.


File: R-exts.info,  Node: Documenting packages,  Prev: Documenting S4 classes and methods,  Up: Rd format

2.1.4 Documenting packages
--------------------------

Packages may have an overview help page with an `\alias'
`PKGNAME-package', e.g. `utils-package' for the *utils* package, when
`package?PKGNAME' will open that help page.  If a topic named `PKGNAME'
does not exist in another Rd file, it is helpful to use this as an
additional `\alias'.

   Skeletons of documentation for a package can be generated using the
function `promptPackage()'.  If the `final = TRUE' argument is used,
then the Rd file will be generated in final form, containing the
information that would be produced up to `library(help = PKGNAME)'.
Otherwise (the default) comments will be inserted giving suggestions
for content.

   Apart from the mandatory `\name' and `\title' and the
`PKGNAME-package' alias, the only requirement for the package overview
page is that it include a `\docType{package}' statement.  All other
content is optional.  We suggest that it should be a short overview, to
give a reader unfamiliar with the package enough information to get
started.  More extensive documentation is better placed into a package
vignette (*note Writing package vignettes::) and referenced from this
page, or into individual man pages for the functions, datasets, or
classes.


File: R-exts.info,  Node: Sectioning,  Next: Marking text,  Prev: Rd format,  Up: Writing R documentation files

2.2 Sectioning
==============

To begin a new paragraph or leave a blank line in an example, just
insert an empty line (as in (La)TeX).  To break a line, use `\cr'.  

   In addition to the predefined sections (such as `\description{}',
`\value{}', etc.), you can "define" arbitrary ones by
`\section{SECTION_TITLE}{...}'.  For example

     \section{Warning}{
       You must not call this function unless ...
     }

For consistency with the pre-assigned sections, the section name (the
first argument to `\section') should be capitalized (but not all upper
case).  Whitespace between the first and second braced expressions is
not allowed as from R 2.10.0.  Markup (e.g. `\code') within the section
title may cause problems with the latex conversion (depending on the
version of macro packages such as `hyperref') and so should be avoided.

   Note that additional named sections are always inserted at a fixed
position in the output (before `\note', `\seealso' and the examples),
no matter where they appear in the input (but in the same order amongst
themselves as in the input).


File: R-exts.info,  Node: Marking text,  Next: Lists and tables,  Prev: Sectioning,  Up: Writing R documentation files

2.3 Marking text
================

The following logical markup commands are available for emphasizing or
quoting text.

`\emph{TEXT}'
`\strong{TEXT}'
     Emphasize TEXT using _italic_ and *bold* font if possible;
     `\strong' is regarded as stronger (more emphatic).

`\bold{TEXT}'
     Set TEXT in bold font if possible.

`\sQuote{TEXT}'
`\dQuote{TEXT}'
     Portably single or double quote TEXT (without hard-wiring the
     characters used for quotation marks).

   Each of the above commands takes LaTeX-like input, so other macros
may be used within TEXT.

   The following logical markup commands are available for indicating
specific kinds of text.  Except as noted, these take verbatim text
input, and so other macros may not be used within them.  Some characters
will need to be escaped (*note Insertions::).

`\code{TEXT}'
     Indicate text that is a literal example of a piece of an R program,
     e.g., a fragment of R code or the name of an R object.  Text is
     entered in R-like syntax, and displayed using `typewriter' font if
     possible.  Macros `\var' and `\link' are interpreted within TEXT.

`\preformatted{TEXT}'
     Indicate text that is a literal example of a piece of a program.
     Text is displayed using `typewriter' font if possible.  Formatting,
     e.g. line breaks, is preserved.

     Due to limitations in LaTeX as of this writing, this macro may not
     be nested within other markup macros other than `\dQuote' and
     `\sQuote', as errors or bad formatting may result.

`\kbd{KEYBOARD-CHARACTERS}'
     Indicate keyboard input, using `slanted typewriter' font if
     possible, so users can distinguish the characters they are
     supposed to type from computer output.  Text is entered verbatim.

`\samp{TEXT}'
     Indicate text that is a literal example of a sequence of
     characters, entered verbatim.  No wrapping or reformatting will
     occur.  Displayed using `typewriter' font if possible.

`\verb{TEXT}'
     Indicate text that is a literal example of a sequence of
     characters, with no interpretation of e.g. `\var', but which will
     be included within word-wrapped text.  Displayed using
     `typewriter' font if possible.

`\pkg{PACKAGE_NAME}'
     Indicate the name of an R package.  LaTeX-like.

`\file{FILE_NAME}'
     Indicate the name of a file.  Text is LaTeX-like, so backslash
     needs to be escaped.  Displayed using a distinct font if possible.

`\email{EMAIL_ADDRESS}'
     Indicate an electronic mail address.  LaTeX-like, will be rendered
     as a hyperlink in HTML and PDF conversion.  Displayed using
     `typewriter' font if possible.

`\url{UNIFORM_RESOURCE_LOCATOR}'
     Indicate a uniform resource locator (URL) for the World Wide Web.
     The argument is handled verbatim, and rendered as a hyperlink in
     HTML and PDF conversion.  Displayed using `typewriter' font if
     possible.

`\var{METASYNTACTIC_VARIABLE}'
     Indicate a metasyntactic variable.  In some cases this will be
     rendered distinctly, e.g. in italic, but not in all(1). LaTeX-like.

`\env{ENVIRONMENT_VARIABLE}'
     Indicate an environment variable. Verbatim.  Displayed using
     `typewriter' font if possible

`\option{OPTION}'
     Indicate a command-line option.  Verbatim.  Displayed using
     `typewriter' font if possible.

`\command{COMMAND_NAME}'
     Indicate the name of a command. LaTeX-like, so `\var' is
     interpreted.  Displayed using `typewriter' font if possible.

`\dfn{TERM}'
     Indicate the introductory or defining use of a term. LaTeX-like.

`\cite{REFERENCE}'
     Indicate a reference without a direct cross-reference _via_ `\link'
     (*note Cross-references::), such as the name of a book. LaTeX-like.

`\acronym{ACRONYM}'
     Indicate an acronym (an abbreviation written in all capital
     letters), such as GNU. LaTeX-like.

   ---------- Footnotes ----------

   (1) Currently it is rendered differently only in HTML conversions,
and LaTeX conversion outside `\usage' and `\examples' environments.


File: R-exts.info,  Node: Lists and tables,  Next: Cross-references,  Prev: Marking text,  Up: Writing R documentation files

2.4 Lists and tables
====================

The `\itemize' and `\enumerate' commands take a single argument, within
which there may be one or more `\item' commands.  The text following
each `\item' is formatted as one or more paragraphs, suitably indented
and with the first paragraph marked with a bullet point (`\itemize') or
a number (`\enumerate').

   `\itemize' and `\enumerate' commands may be nested.

   The `\describe' command is similar to `\itemize' but allows initial
labels to be specified.  Each `\item' takes two arguments, the label
and the body of the item, in exactly the same way as an argument or
value `\item'.  `\describe' commands are mapped to `<DL>' lists in HTML
and `\description' lists in LaTeX.

   The `\tabular' command takes two arguments.  The first gives for
each of the columns the required alignment (`l' for left-justification,
`r' for right-justification or `c' for centring.)  The second argument
consists of an arbitrary number of lines separated by `\cr', and with
fields separated by `\tab'.  For example:

       \tabular{rlll}{
         [,1] \tab Ozone   \tab numeric \tab Ozone (ppb)\cr
         [,2] \tab Solar.R \tab numeric \tab Solar R (lang)\cr
         [,3] \tab Wind    \tab numeric \tab Wind (mph)\cr
         [,4] \tab Temp    \tab numeric \tab Temperature (degrees F)\cr
         [,5] \tab Month   \tab numeric \tab Month (1--12)\cr
         [,6] \tab Day     \tab numeric \tab Day of month (1--31)
       }

There must be the same number of fields on each line as there are
alignments in the first argument, and they must be non-empty (but can
contain only spaces).  (There is no whitespace between `\tabular' and
the first argument, nor between the two arguments.)


File: R-exts.info,  Node: Cross-references,  Next: Mathematics,  Prev: Lists and tables,  Up: Writing R documentation files

2.5 Cross-references
====================

The markup `\link{FOO}' (usually in the combination
`\code{\link{FOO}}') produces a hyperlink to the help for FOO.  Here
FOO is a _topic_, that is the argument of `\alias' markup in another Rd
file (possibly in another package).  Hyperlinks are supported in some
of the formats to which Rd files are converted, for example HTML and
PDF, but ignored in others, e.g.  the text format.

   One main usage of `\link' is in the `\seealso' section of the help
page, *note Rd format::.

   Note that whereas leading and trailing spaces are stripped when
extracting a topic from a `\alias', they are not stripped when looking
up the topic of a `\link'.

   You can specify a link to a different topic than its name by
`\link[=DEST]{NAME}' which links to topic DEST with name NAME.  This
can be used to refer to the documentation for S3/4 classes, for example
`\code{"\link[=abc-class]{abc}"}' would be a way to refer to the
documentation of an S4 class `"abc"' defined in your package, and
`\code{"\link[=terms.object]{terms}"}' to the S3 `"terms"' class (in
package *stats*).  To make these easy to read in the source file,
`\code{"\linkS4class{abc}"}' expands to the form given above.

   There are two other forms of optional argument specified as
`\link[PKG]{FOO}' and `\link[PKG:BAR]{FOO}' to link to the package
*PKG*, to _files_ `FOO.html' and `BAR.html' respectively.  These are
rarely needed, perhaps to refer to not-yet-installed packages (but
there the HTML help system will resolve the link at run time) or in the
normally undesirable event that more than one package offers help on a
topic(1) (in which case the present package has precedence so this is
only needed to refer to other packages).  They are currently only used
in HTML help (and ignored for hyperlinks in LaTeX conversions of help
pages), and link to the file rather than the topic (since there is no
way to know which topics are in which files in an uninstalled package).
The *only* reason to use these forms for base and recommended packages
is to force a reference to a package that might be further down the
search path.  Because they have been frequently misused, as from R
2.10.0 the HTML help system looks for topic `FOO' in package *PKG* if
it does not find file `FOO.html'.

   ---------- Footnotes ----------

   (1) a common example in CRAN packages is `\link[mgcv]{gam}'.


File: R-exts.info,  Node: Mathematics,  Next: Insertions,  Prev: Cross-references,  Up: Writing R documentation files

2.6 Mathematics
===============

Mathematical formulae should be set beautifully for printed
documentation yet we still want something useful for text and HTML
online help.  To this end, the two commands `\eqn{LATEX}{ASCII}' and
`\deqn{LATEX}{ASCII}' are used.  Whereas `\eqn' is used for "inline"
formulae (corresponding to TeX's `$...$'), `\deqn' gives "displayed
equations" (as in LaTeX's `displaymath' environment, or TeX's
`$$...$$').  Both arguments are treated as verbatim text.

   Both commands can also be used as `\eqn{LATEXASCII}' (only _one_
argument) which then is used for both LATEX and ASCII.  No whitespace
is allowed between command and the first argument, nor (prior to Rd
version 1.1) between the first and second arguments.

   The following example is from `Poisson.Rd':

       \deqn{p(x) = \frac{\lambda^x e^{-\lambda}}{x!}}{%
             p(x) = lambda^x exp(-lambda)/x!}
       for \eqn{x = 0, 1, 2, \ldots}.

   For HTML and text on-line help we get

              p(x) = lambda^x exp(-lambda)/x!

          for x = 0, 1, 2, ....

   See *Note Back-compatibility issues:: for earlier problems with
`\eqn' with one argument immediately followed by a right brace.

   Note that only basic LaTeX can be used, there being no provision to
specify LaTeX style files such as the AMS extensions.


File: R-exts.info,  Node: Insertions,  Next: Indices,  Prev: Mathematics,  Up: Writing R documentation files

2.7 Insertions
==============

Use `\R' for the R system itself.  Use `\dots' for the dots in function
argument lists `...', and `\ldots' for ellipsis dots in ordinary
text.(1)  These can be followed by `{}', and should be unless followed
by whitespace.

   After an unescaped `%', you can put your own comments regarding the
help text.  The rest of the line (but not the newline at the end) will
be completely disregarded.  Therefore, you can also use it to make part
of the "help" invisible.

   You can produce a backslash (`\') by escaping it by another
backslash.  (Note that `\cr' is used for generating line breaks.)

   The "comment" character `%' and unpaired braces(2) _almost always_
need to be escaped by `\', and `\\' can be used for backslash and needs
to be when there two or more adjacent backslashes).  In R-like code
literal strings are slightly more forgiving; see "Parsing Rd files"
(http://developer.r-project.org/parseRd.pdf) for details.

   All of `% { } \' should be escaped in LaTeX-like text.

   Text which might need to be represented differently in different
encodings should be marked by `\enc', e.g.  `\enc{Jreskog}{Joreskog}'
(with no whitespace between the braces) where the first argument will
be used where encodings are allowed and the second should be ASCII (and
is used for e.g.  the text conversion).  (This is intended to be used
for individual words, not whole sentences or paragraphs.)

   ---------- Footnotes ----------

   (1) There is only a fine distinction between `\dots' and `\ldots'.
It is technically incorrect to use `\ldots' in code blocks and
`tools::checkRd' will warn about this--on the other hand the current
converters treat them the same way in code blocks, and elsewhere apart
from the small distinction between the two in LaTeX.

   (2) See the examples section in the file `Paren.Rd' for an example.


File: R-exts.info,  Node: Indices,  Next: Platform-specific sections,  Prev: Insertions,  Up: Writing R documentation files

2.8 Indices
===========

The `\alias' command (*note Documenting functions::) is used to specify
the "topics" documented, which should include _all_ R objects in a
package such as functions and variables, data sets, and S4 classes and
methods (*note Documenting S4 classes and methods::).  The on-line help
system searches the index data base consisting of all alias topics.

   In addition, it is possible to provide "concept index entries" using
`\concept', which can be used for `help.search()' lookups.  E.g., file
`cor.test.Rd' in the standard package *stats* contains

     \concept{Kendall correlation coefficient}
     \concept{Pearson correlation coefficient}
     \concept{Spearman correlation coefficient}

so that e.g. `??Spearman' will succeed in finding the help page for the
test for association between paired samples using Spearman's rho.

   (Note that `help.search()' only uses "sections" of documentation
objects with no additional markup.)

   If you want to cross reference such items from other help files _via_
`\link', you need to use `\alias' and not `\concept'.


File: R-exts.info,  Node: Platform-specific sections,  Next: Conditional text,  Prev: Indices,  Up: Writing R documentation files

2.9 Platform-specific documentation
===================================

Sometimes the documentation needs to differ by platform.  Currently two
OS-specific options are available, `unix' and `windows', and lines in
the help source file can be enclosed in

     #ifdef OS
        ...
     #endif

or

     #ifndef OS
        ...
     #endif

for OS-specific inclusion or exclusion.  Such blocks should not be
nested, and should be entirely within a block (that, is between the
opening and closing brace of a section or item), or at top-level contain
one or more complete sections.

   If the differences between platforms are extensive or the R objects
documented are only relevant to one platform, platform-specific Rd files
can be put in a `unix' or `windows' subdirectory.


File: R-exts.info,  Node: Conditional text,  Next: Dynamic pages,  Prev: Platform-specific sections,  Up: Writing R documentation files

2.10 Conditional text
=====================

Occasionally the best content for one output format is different from
the best content for another.  For this situation, the
`\if{FORMAT}{TEXT}' or `\ifelse{FORMAT}{TEXT}{ALTERNATE}' markup is
used.  Here FORMAT is a comma separated list of formats in which the
TEXT should be rendered.  The ALTERNATE will be rendered if the format
does not match.  Both TEXT and ALTERNATE may be any sequence of text
and markup.

   Currently the following formats are recognized:  `example', `html',
`latex' and `text'.  These select output for the corresponding targets.
(Note that `example' refers to extracted example code rather than the
displayed example in some other format.)  Also accepted are `TRUE'
(matching all formats) and `FALSE' (matching no formats).  These could
be the output of the `\Sexpr' macro (*note Dynamic pages::).

   The `\out{LITERAL}' macro would usually be used within the TEXT part
of `\if{FORMAT}{TEXT}'.  It causes the renderer to output the literal
text exactly, with no attempt to escape special characters.  For
example, use the following to output the markup necessary to display
the Greek letter in LaTeX or HTML, and the text string `alpha' in other
formats:
     \if{latex}{\out{\alpha}}\ifelse{html}{\out{&alpha;}}{alpha}


File: R-exts.info,  Node: Dynamic pages,  Next: Encoding,  Prev: Conditional text,  Up: Writing R documentation files

2.11 Dynamic pages
==================

Two new macros supporting dynamically generated man pages were
introduced in R 2.10.0, `\Sexpr' and `\RdOpts'.  These are modelled
after Sweave, and are intended to contain executable R expressions in
the Rd file.

   The main argument to `\Sexpr' must be valid R code that can be
executed. It may also take options in square brackets before the main
argument. Depending on the options, the code may be executed at package
build time, package install time, or man page rendering time.

   The options follow the same format as in Sweave, but different
options are supported.  Currently the allowed options and their
defaults are:

   * `eval=TRUE' Whether the R code should be evaluated.

   * `echo=FALSE' Whether the R code should be echoed.  If `TRUE', a
     display will be given in a preformatted block.  For example,
     `\Sexpr[echo=TRUE]{ x <- 1 }' will be displayed as
          > x <- 1

   * `keep.source=TRUE' Whether to keep the author's formatting when
     displaying the code, or throw it away and use a deparsed version.

   * `results=text' How should the results be displayed?  The
     possibilities are:

        - `results=text' Apply `as.character()' to the result of the
          code, and insert it as a text element.

        - `results=verbatim' Print the results of the code just as if
          it was executed at the console, and include the printed
          results verbatim.  (Invisible results will not print.)

        - `results=rd' The result is assumed to be a character vector
          containing markup to be passed to `parse_Rd(fragment=TRUE)',
          with the result inserted in place.  This could be used to
          insert computed aliases, for instance.

        - `results=hide' Insert no output.

   * `strip.white=TRUE' Remove leading and trailing white space from
     each line of output if `strip.white=TRUE'.  With
     `strip.white=all', also remove blank lines.

   * `stage=install' Control when this macro is run.  Possible values
     are
        - `stage=build' The macro is run when building a source
          tarball.  Currently this stage is not processed.

        - `stage=install' The macro is run when installing from source.

        - `stage=render' The macro is run when displaying the help page.

     Conditionals such as `#ifdef' (*note Platform-specific sections::)
     are applied after the `build' macros but before the `install'
     macros.  In some situations (e.g. installing directly from a
     source directory without a tarball, or building a binary package)
     the above descriptions may not be accurate, but authors should be
     able to rely on the sequence being `build', `#ifdef', `install',
     `render', with all stages executed(1).

     Code is only run once in each stage, so a `\Sexpr[results=rd]'
     macro can output an `\Sexpr' macro designed for a later stage, but
     not for the current one or any earlier stage.

   * `width, height, fig' These options are currently allowed but
     ignored.

   The `\RdOpts' macro is used to set new defaults for options to apply
to following uses of `\Sexpr'.

   For more details, see the online document "Parsing Rd files"
(http://developer.r-project.org/parseRd.pdf).

   ---------- Footnotes ----------

   (1) As noted above, the `build' stage is not currently implemented.


File: R-exts.info,  Node: Encoding,  Next: Processing Rd format,  Prev: Dynamic pages,  Up: Writing R documentation files

2.12 Encoding
=============

Rd files are text files and so it is impossible to deduce the encoding
they are written in unless ASCII: files with 8-bit characters could be
UTF-8, Latin-1, Latin-9, KOI8-R, EUC-JP, _etc_.  So the `\encoding{}'
directive must be used to specify the encoding if it is not ASCII.
(The `\encoding{}' directive must be on a line by itself, and in
particular one containing no non-ASCII characters.  There should be
only one `\encoding{}' directive per file, but only the first will be
used.  As from R 2.6.0 the encoding declared in the `DESCRIPTION' file
will be used if none is declared in the file.)  This is for input:
internally, the Rd files are converted to the UTF-8 encoding.  It is
also used for output in the case of LaTeX conversions, while HTML is
output in UTF-8 and text is output in the local encoding.

   Wherever possible, avoid non-ASCII chars in Rd files, and even
symbols such as `<', `>', `$', `^', `&', `|', `@', `~', and `*' outside
verbatim environments (since they may disappear in fonts designed to
render text).  (Function `showNonASCII' in package *tools* can help in
finding non-ASCII bytes in the files.)

   For convenience, encoding names `latin1' and `latin2' are always
recognized: these and `UTF-8' are likely to work fairly widely.
However, this does not mean that all characters in UTF-8 will be
recognized, and the coverage of non-Latin characters(1) is low.

   The `\enc' command (*note Insertions::) can be used to provide
transliterations which will be used in conversions that do not support
the declared encoding.

   The LaTeX conversion converts an explicit encoding of the file to a

     \inputencoding{SOME_ENCODING}

command, and this needs to be matched by a suitable invocation of the
`\usepackage{inputenc}' command.  The R utility `R CMD Rd2dvi' looks at
the converted code and includes the encodings used: it might for
example use

     \usepackage[latin1,latin9,utf8]{inputenc}

(Use of `utf8' as an encoding requires LaTeX dated 2003/12/01 or later.
Also, the use of Cyrillic characters in `UTF-8' appears to also need
`\usepackage[T2A]{fontenc}', and `R CMD Rd2dvi' includes this
conditionally on the file `t2aenc.def' being present and environment
variable `_R_CYRILLIC_TEX_' being set.)

   Note that this mechanism works best with Latin letters and for
example the copyright symbol may be rendered as a superscript and the
plus-minus symbol cannot be used in text.

   ---------- Footnotes ----------

   (1) R 2.9.0 added support for UTF-8 Cyrillic characters in LaTeX,
but on some OSes this will need Cyrillic support added to LaTeX, so
environment variable `_R_CYRILLIC_TEX_' needs to be set to a non-empty
value to enable this.


File: R-exts.info,  Node: Processing Rd format,  Next: Back-compatibility issues,  Prev: Encoding,  Up: Writing R documentation files

2.13 Processing Rd format
=========================

There are several commands to process Rd files from the system command
line.

   Using `R CMD Rdconv' one can convert R documentation format to other
formats, or extract the executable examples for run-time testing.  The
currently supported conversions are to plain text, HTML and LaTeX as
well as extraction of the examples.

   `R CMD Rd2dvi' generates DVI (or, if option `--pdf' is given, PDF)
output from documentation in Rd files, which can be specified either
explicitly or by the path to a directory with the sources of a package.
In the latter case, a reference manual for all documented objects in
the package is created, including the information in the `DESCRIPTION'
files.

   `R CMD Sd2Rd' converts S version 3 documentation files (which use an
extended Nroff format) and S version 4 documentation (which uses SGML
markup) to Rd format.  This is useful when porting a package originally
written for the S system to R.  S version 3 files usually have
extension `.d', whereas version 4 ones have extension `.sgml' or
`.sgm'.  (This command is deprecated, and requires Perl to be
installed.)

   `R CMD Sweave' and `R CMD Stangle' process `Sweave' documentation
files (usually with extension `.Snw' or `.Rnw'): `R CMD Stangle' is use
to extract the R code fragments.

   The exact usage and a detailed list of available options for all of
these commands can be obtained by running `R CMD COMMAND --help', e.g.,
`R CMD Rdconv --help'.  All available commands can be listed using `R
--help' (or `Rcmd --help' under Windows).

   All of these work under Windows. You will need to have installed the
files in the R binary Windows distribution for installing source
packages (this is true for a default installation), and for `R CMD
Rd2dvi' also the tools to build packages from source as described in the
"R Installation and Administration" manual.


File: R-exts.info,  Node: Back-compatibility issues,  Prev: Processing Rd format,  Up: Writing R documentation files

2.14 Back-compatibility issues
==============================

Packages that are intended to work with earlier versions of R need to
be written in a different dialect, and some notes follow.  R 2.10.0
processes Rd files as version 2 (as described here); R 2.9.X assumed
files were version 1 (unnumbered) unless they were declared to be
version 1.1; R 2.8.1 and earlier used version 1 (unnumbered)

   Some package authors have included arbitrary pieces of LaTeX
mathematical notation into text descriptions, e.g. `$\mu$g' and
`$^\circ$C'.  Whether this works even in latex conversion depends on
the version of R, and it has always given ugly results in other
conversions.  If mathematical notation is necessary (and it seems it is
not in the examples given), use `\eqn'.

* Menu:

* Changes in R 2.10.0::
* Changes in R 2.9.0::
* Unnumbered versions::


File: R-exts.info,  Node: Changes in R 2.10.0,  Next: Changes in R 2.9.0,  Prev: Back-compatibility issues,  Up: Back-compatibility issues

2.14.1 Changes in R 2.10.0
--------------------------

We now convert `.Rd' files in R (rather than in Perl).  Differences
from version 1.1 include

   * `%' never escapes the newline: it used to in text-like modes but
     not in e.g. `\usage' and `\examples' sections.  This means that
     constructions like
          \deqn{
            latex version
          }{%
            text version
          }

     are rendered in text conversion with an extra line, and inter-line
     comments like

            \item{x, y}{logical (or \dQuote{number-like}, i.e., of type
              \code{\link{double}} (class \code{\link{numeric}}), \code{\link{integer}},
              %% incl. factor
              \code{\link{complex}} or \code{\link{raw}}) vectors, or objects for
              which methods have been written.}

     start a new paragraph.

   * Unmatched right braces are an error, not just a warning.

   * No whitespace is allowed between the first and second arguments of
     a macro such as `\item' -- files parse with a warning but may not
     be converted correctly.

   * `\code' is intended _only_ for R code, and as such its argument
     must be syntactically valid once macros such as `\link' and `\var'
     have been substituted.  This means that quotes must balance.  Use
     `\verb' (only in R 2.10.0 or later) or `\samp' or `\kbd' for code
     snippets and code in other languages.

   * `\preformatted' is verbatim, so `\var' is not interpreted.

   * Both arguments of `\dean' and `\eqn' are verbatim, so for example
     `\code' is not rendered there.



File: R-exts.info,  Node: Changes in R 2.9.0,  Next: Unnumbered versions,  Prev: Changes in R 2.10.0,  Up: Back-compatibility issues

2.14.2 Changes in R 2.9.0
-------------------------

Rd version 1.1 was introduced in R 2.9.0.  The main changes were

   * `$' is treated literally in text, even for latex conversion.

   * `\' is only an escape before `% { } \', and these should always be
     escaped (although paired braces inside `\code' will be still be
     handled if unescaped).  `#', `_' and `&' must not be escaped.

   * `\R{}' is accepted as an alternative to `\R'.  Similarly for
     `\dots' and `\ldots'.

   * Whitespace is allowed between the first and second arguments of
     `\item' and `\section'.

   * Interpretation of `\Alpha' etc is no longer done.


File: R-exts.info,  Node: Unnumbered versions,  Prev: Changes in R 2.9.0,  Up: Back-compatibility issues

2.14.3 Unnumbered versions
--------------------------

Prior to version 1.1, `$' needs to be escaped by backslash in "regular"
text (not verbatim-like, not in the first argument of `\eqn', ...), and
`#', `_' and `&' can be.

   For historical reasons, the TeX/LaTeX commands `\alpha', `\Alpha',
`\beta', `\Gamma', `\epsilon', `\lambda', `\mu', `\pi', `\sigma',
`\Sigma', `\le', `\ge', `\left(' and `\right)' were accepted, and
interpreted in text and HTML conversions.  The preferred way to handle
these is as part of `\eqn' or `\deqn'.

   Further, `^', `~', `<', `>' and `|' were not in general safe to use
in non-code text.  The advice was to enter `^' as
`\eqn{\mbox{\textasciicircum}}{^}', and `~' by
`\eqn{\mbox{\textasciitilde}}{~}' or `\eqn{\sim}{~}' (for a short and
long tilde respectively).  Also, `<', `>', and `|' could only be used
safely in math mode, i.e., within the first argument of `\eqn' or
`\deqn'.

   `\R', `\dots' and `\ldots' were not followed by `{~}'

   Versions of R prior to 2.8.1 failed to process correctly
constructions such as

     \item{name}{some text \eqn{x}}

the problem being the one- or two-argument command `\eqn' immediately
followed by a right brace.  In many cases this can be resolved by
adding punctuation, and even space before the final brace sufficed.

   It was never intended to allow whitespace between arguments to
two-argument commands, e.g.

     \item{name} {some text}

had always been an error.  However, prior to R 2.9.0 this error was not
looked for and resulted in incorrect output (often by omitting entirely
the text for the item, sometimes with a warning).  R 2.9.0 detected and
fixed most cases of this error, with a warning unless the file was
declared as version 1.1 or later.  As of R 2.10.0, it is an error.

   A `\value' block is implicitly a `\itemize' environment, but quite a
few package writers have ignored this.  As from R 2.8.1 this is
detected, and the `\itemize' command (but not its contents) removed,
with a warning.


File: R-exts.info,  Node: Tidying and profiling R code,  Next: Debugging,  Prev: Writing R documentation files,  Up: Top

3 Tidying and profiling R code
******************************

* Menu:

* Tidying R code::
* Profiling R code for speed::
* Profiling R code for memory use::
* Profiling compiled code::

   R code which is worth preserving in a package and perhaps making
available for others to use is worth documenting, tidying up and perhaps
optimizing. The last two of these activities are the subject of this
chapter.


File: R-exts.info,  Node: Tidying R code,  Next: Profiling R code for speed,  Prev: Tidying and profiling R code,  Up: Tidying and profiling R code

3.1 Tidying R code
==================

R treats function code loaded from packages and code entered by users
differently.  Code entered by users has the source code stored in an
attribute, and when the function is listed, the original source is
reproduced.  Loading code from a package (by default) discards the
source code, and the function listing is re-created from the parse tree
of the function.

   Normally keeping the source code is a good idea, and in particular it
avoids comments being moved around in the source.  However, we can make
use of the ability to re-create a function listing from its parse tree
to produce a tidy version of the function, for example with consistent
indentation and spaces around operators.  This tidied version is much
easier to read, not least by other users who are used to the standard
format.  Although the deparsing cannot do so, we recommend the
consistent use of the preferred assignment operator `<-' (rather than
`=') for assignment.

   We can subvert the keeping of source in two ways.

  1. The option `keep.source' can be set to `FALSE' before the code is
     loaded into R.

  2. The stored source code can be removed by removing the `source'
     attribute, for example by

          attr(myfun, "source") <- NULL


In each case if we then list the function we will get the standard
layout.

   Suppose we have a file of functions `myfuns.R' that we want to tidy
up.  Create a file `tidy.R' containing

     options(keep.source = FALSE)
     source("myfuns.R")
     dump(ls(all = TRUE), file = "new.myfuns.R")

and run R with this as the source file, for example by `R --vanilla <
tidy.R' or by pasting into an R session.  Then the file `new.myfuns.R'
will contain the functions in alphabetical order in the standard
layout.  Warning:  comments in your functions will be lost.

   The standard format provides a good starting point for further
tidying.  Many package authors use a version of Emacs (on Unix or
Windows) to edit R code, using the ESS[S] mode of the ESS Emacs package.
See *Note R coding standards: (R-ints)R coding standards.  for style
options within the ESS[S] mode recommended for the source code of R
itself.


File: R-exts.info,  Node: Profiling R code for speed,  Next: Profiling R code for memory use,  Prev: Tidying R code,  Up: Tidying and profiling R code

3.2 Profiling R code for speed
==============================

It is possible to profile R code on Windows and most(1) Unix-like
versions of R.

   The command `Rprof' is used to control profiling, and its help page
can be consulted for full details.  Profiling works by recording at
fixed intervals(2) (by default every 20 msecs) which R function is
being used, and recording the results in a file (default `Rprof.out' in
the working directory).  Then the function `summaryRprof' or the
command-line utility `R CMD Rprof RPROF.OUT' can be used to summarize
the activity.

   As an example, consider the following code (from Venables & Ripley,
2002).

     library(MASS); library(boot)
     storm.fm <- nls(Time ~ b*Viscosity/(Wt - c), stormer,
                     start = c(b=30.401, c=2.2183))
     st <- cbind(stormer, fit=fitted(storm.fm))
     storm.bf <- function(rs, i) {
         st$Time <-  st$fit + rs[i]
         tmp <- nls(Time ~ (b * Viscosity)/(Wt - c), st,
                    start = coef(storm.fm))
         tmp$m$getAllPars()
     }
     rs <- scale(resid(storm.fm), scale = FALSE) # remove the mean
     Rprof("boot.out")
     storm.boot <- boot(rs, storm.bf, R = 4999) # pretty slow
     Rprof(NULL)

Having run this we can summarize the results by

     R CMD Rprof boot.out

     Each sample represents 0.02 seconds.
     Total run time: 80.74 seconds.

     Total seconds: time spent in function and callees.
     Self seconds: time spent in function alone.

        %       total       %       self
      total    seconds     self    seconds    name
     100.00     80.74      0.22      0.18     "boot"
      99.65     80.46      1.19      0.96     "statistic"
      96.33     77.78      2.68      2.16     "nls"
      50.21     40.54      1.54      1.24     "<Anonymous>"
      47.11     38.04      1.83      1.48     ".Call"
      23.06     18.62      2.43      1.96     "eval"
      19.87     16.04      0.67      0.54     "as.list"
      18.97     15.32      0.64      0.52     "switch"
      17.88     14.44      0.47      0.38     "model.frame"
      17.41     14.06      1.73      1.40     "model.frame.default"
      17.41     14.06      2.80      2.26     "nlsModel"
      15.43     12.46      1.88      1.52     "qr.qty"
      13.40     10.82      3.07      2.48     "assign"
      12.73     10.28      2.33      1.88     "storage.mode<-"
      12.34      9.96      1.81      1.46     "qr.coef"
      10.13      8.18      5.42      4.38     "paste"
       ...

        %       self        %       total
      self     seconds    total    seconds    name
       5.42      4.38     10.13      8.18     "paste"
       3.37      2.72      6.71      5.42     "as.integer"
       3.29      2.66      5.00      4.04     "as.double"
       3.20      2.58      4.29      3.46     "seq.default"
       3.07      2.48     13.40     10.82     "assign"
       2.92      2.36      5.95      4.80     "names"
       2.80      2.26     17.41     14.06     "nlsModel"
       2.68      2.16     96.33     77.78     "nls"
       2.53      2.04      2.53      2.04     ".Fortran"
       2.43      1.96     23.06     18.62     "eval"
       2.33      1.88     12.73     10.28     "storage.mode<-"
       ...

This often produces surprising results and can be used to identify
bottlenecks or pieces of R code that could benefit from being replaced
by compiled code.

   `R CMD Rprof' uses a Perl script that may be a little faster than
`summaryRprof' for large files.  On the other hand `summaryRprof' does
not require Perl and provides the results as an R object.

   Two warnings: profiling does impose a small performance penalty, and
the output files can be very large if long runs are profiled.

   Profiling short runs can sometimes give misleading results.  R from
time to time performs _garbage collection_ to reclaim unused memory,
and this takes an appreciable amount of time which profiling will
charge to whichever function happens to provoke it.  It may be useful
to compare profiling code immediately after a call to `gc()' with a
profiling run without a preceding call to `gc'.

   More detailed analysis of the output can be achieved by the tools in
the CRAN packages *proftools* and *prof*: in particular these allow
call graphs to be studied.

   ---------- Footnotes ----------

   (1) R has to be built to enable this, but the option
`--enable-R-profiling' is the default.

   (2) For Unix-alikes these are intervals of CPU time, and for Windows
of elapsed time.


File: R-exts.info,  Node: Profiling R code for memory use,  Next: Profiling compiled code,  Prev: Profiling R code for speed,  Up: Tidying and profiling R code

3.3 Profiling R code for memory use
===================================

Measuring memory use in R code is useful either when the code takes
more memory than is conveniently available or when memory allocation
and copying of objects is responsible for slow code. There are three
ways to profile memory use over time in R code. All three require R to
have been compiled with `--enable-memory-profiling', which is not the
default. All can be misleading, for different reasons.

   In understanding the memory profiles it is useful to know a little
more about R's memory allocation. Looking at the results of `gc()'
shows a division of memory into `Vcells' used to store the contents of
vectors and `Ncells' used to store everything else, including all the
administrative overhead for vectors such as type and length
information.  In fact the vector contents are divided into two pools.
Memory for small vectors (by default 128 bytes or less) is obtained in
large chunks and then parcelled out by R; memory for larger vectors is
obtained directly from the operating system.

   Some memory allocation is obvious in interpreted code, for example,

     y <- x + 1

allocates memory for a new vector `y'. Other memory allocation is less
obvious and occurs because `R' is forced to make good on its promise of
`call-by-value' argument passing.  When an argument is passed to a
function it is not immediately copied. Copying occurs (if necessary)
only when the argument is modified.  This can lead to surprising memory
use. For example, in the `survey' package we have

     print.svycoxph <- function (x, ...)
     {
         print(x$survey.design, varnames = FALSE, design.summaries = FALSE,
             ...)
         x$call <- x$printcall
         NextMethod()
     }

It may not be obvious that the assignment to `x$call' will cause the
entire object `x' to be copied.  This copying to preserve the
call-by-value illusion is usually done by the internal C function
`duplicate'.

   The main reason that memory-use profiling is difficult is garbage
collection. Memory is allocated at well-defined times in an R program,
but is freed whenever the garbage collector happens to run.

* Menu:

* Memory statistics from Rprof::
* Tracking memory allocations::
* Tracing copies of an object::


File: R-exts.info,  Node: Memory statistics from Rprof,  Next: Tracking memory allocations,  Prev: Profiling R code for memory use,  Up: Profiling R code for memory use

3.3.1 Memory statistics from `Rprof'
------------------------------------

The sampling profiler `Rprof' described in the previous section can be
given the option `memory.profiling=TRUE'. It then writes out the total
R memory allocation in small vectors, large vectors, and cons cells or
nodes at each sampling interval. It also writes out the number of calls
to the internal function `duplicate', which is called to copy R
objects. `summaryRprof' provides summaries of this information.  The
main reason that this can be misleading is that the memory use is
attributed to the function running at the end of the sampling interval.
A second reason is that garbage collection can make the amount of
memory in use decrease, so a function appears to use little memory.
Running under `gctorture' helps with both problems: it slows down the
code to effectively increase the sampling frequency and it makes each
garbage collection release a smaller amount of memory.  Changing the
memory limits with `mem.limits()' may also be useful, to see how the
code would run under different memory conditions.


File: R-exts.info,  Node: Tracking memory allocations,  Next: Tracing copies of an object,  Prev: Memory statistics from Rprof,  Up: Profiling R code for memory use

3.3.2 Tracking memory allocations
---------------------------------

The second method of memory profiling uses a memory-allocation
profiler, `Rprofmem()', which writes out a stack trace to an output
file every time a large vector is allocated (with a user-specified
threshold for `large') or a new page of memory is allocated for the R
heap. Summary functions for this output are still being designed.

   Running the example from the previous section with

     > Rprofmem("boot.memprof",threshold=1000)
     > storm.boot <- boot(rs, storm.bf, R = 4999)
     > Rprofmem(NULL)

shows that apart from some initial and final work in `boot' there are
no vector allocations over 1000 bytes.


File: R-exts.info,  Node: Tracing copies of an object,  Prev: Tracking memory allocations,  Up: Profiling R code for memory use

3.3.3 Tracing copies of an object
---------------------------------

The third method of memory profiling involves tracing copies made of a
specific (presumably large) R object. Calling `tracemem' on an object
marks it so that a message is printed to standard output when the
object is copied _via_ `duplicate' or coercion to another type, or when
a new object of the same size is created in arithmetic operations. The
main reason that this can be misleading is that copying of subsets or
components of an object is not tracked. It may be helpful to use
`tracemem' on these components.

   In the example above we can run `tracemem' on the data frame `st'

     > tracemem(st)
     [1] "<0x9abd5e0>"
     > storm.boot <- boot(rs, storm.bf, R = 4)
     memtrace[0x9abd5e0->0x92a6d08]: statistic boot
     memtrace[0x92a6d08->0x92a6d80]: $<-.data.frame $<- statistic boot
     memtrace[0x92a6d80->0x92a6df8]: $<-.data.frame $<- statistic boot
     memtrace[0x9abd5e0->0x9271318]: statistic boot
     memtrace[0x9271318->0x9271390]: $<-.data.frame $<- statistic boot
     memtrace[0x9271390->0x9271408]: $<-.data.frame $<- statistic boot
     memtrace[0x9abd5e0->0x914f558]: statistic boot
     memtrace[0x914f558->0x914f5f8]: $<-.data.frame $<- statistic boot
     memtrace[0x914f5f8->0x914f670]: $<-.data.frame $<- statistic boot
     memtrace[0x9abd5e0->0x972cbf0]: statistic boot
     memtrace[0x972cbf0->0x972cc68]: $<-.data.frame $<- statistic boot
     memtrace[0x972cc68->0x972cd08]: $<-.data.frame $<- statistic boot
     memtrace[0x9abd5e0->0x98ead98]: statistic boot
     memtrace[0x98ead98->0x98eae10]: $<-.data.frame $<- statistic boot
     memtrace[0x98eae10->0x98eae88]: $<-.data.frame $<- statistic boot

The object is duplicated fifteen times, three times for each of the
`R+1' calls to `storm.bf'.  This is surprising, since none of the
duplications happen inside `nls'. Stepping through `storm.bf' in the
debugger shows that all three happen in the line

     st$Time <- st$fit + rs[i]

   Data frames are slower than matrices and this is an example of why.
Using `tracemem(st$Viscosity)' does not reveal any additional copying.


File: R-exts.info,  Node: Profiling compiled code,  Prev: Profiling R code for memory use,  Up: Tidying and profiling R code

3.4 Profiling compiled code
===========================

Profiling compiled code is highly system-specific, but this section
contains some hints gleaned from various R users.  Some methods need to
be different for a compiled executable and for dynamic/shared
libraries/objects as used by R packages.  We know of no good way to
profile DLLs on Windows.

* Menu:

* Linux::
* Solaris::
* Mac OS X::


File: R-exts.info,  Node: Linux,  Next: Solaris,  Prev: Profiling compiled code,  Up: Profiling compiled code

3.4.1 Linux
-----------

Options include using `sprof' for a shared object, and `oprofile' (see
`http://oprofile.sourceforge.net/') for any executable or shared object.

3.4.1.1 sprof
.............

You can select shared objects to be profiled with `sprof' by setting
the environment variable `LD_PROFILE'.  For example

     % setenv LD_PROFILE /path/to/R_HOME/library/stats/libs/stats.so
     R
     ... run the boot example
     % sprof /path/to/R_HOME/library/stats/libs/stats.so \
       /var/tmp/path/to/R_HOME/library/stats/libs/stats.so.profile

     Flat profile:

     Each sample counts as 0.01 seconds.
       %   cumulative   self              self     total
      time   seconds   seconds    calls  us/call  us/call  name
      76.19      0.32     0.32        0     0.00           numeric_deriv
      16.67      0.39     0.07        0     0.00           nls_iter
       7.14      0.42     0.03        0     0.00           getListElement

     rm /path/to/R_HOME/library/stats/libs/stats.so.profile
     ... to clean up ...

   It is possible that root access is needed to create the directories
used for the profile data.

3.4.1.2 oprofile
................

`oprofile' works by running a daemon which collects information.  The
daemon must be started as root, e.g.

     % su
     % opcontrol --no-vmlinux
     % (optional, some platforms) opcontrol --callgraph=5
     % opcontrol --start
     % exit

   Then as a user

     % R
     ... run the boot example
     % opcontrol --dump
     % opreport -l /path/to/R_HOME/library/stats/libs/stats.so
     ...
     samples  %        symbol name
     1623     75.5939  anonymous symbol from section .plt
     349      16.2552  numeric_deriv
     113       5.2632  nls_iter
     62        2.8878  getListElement
     % opreport -l /path/to/R_HOME/bin/exec/R
     ...
     samples  %        symbol name
     76052    11.9912  Rf_eval
     54670     8.6198  Rf_findVarInFrame3
     37814     5.9622  Rf_allocVector
     31489     4.9649  Rf_duplicate
     28221     4.4496  Rf_protect
     26485     4.1759  Rf_cons
     23650     3.7289  Rf_matchArgs
     21088     3.3250  Rf_findFun
     19995     3.1526  findVarLocInFrame
     14871     2.3447  Rf_evalList
     13794     2.1749  R_Newhashpjw
     13522     2.1320  R_gc_internal
     ...

   Shutting down the profiler and clearing the records needs to be done
as root.  You can use `opannotate' to annotate the source code with the
times spent in each section, if the appropriate source code was
compiled with debugging support, and `opreport -c' to generate a
callgraph (if collection was enabled and the platform supports this).


File: R-exts.info,  Node: Solaris,  Next: Mac OS X,  Prev: Linux,  Up: Profiling compiled code

3.4.2 Solaris
-------------

On 64-bit (only) Solaris, the standard profiling tool `gprof' collects
information from shared libraries compiled with `-pg'.


File: R-exts.info,  Node: Mac OS X,  Prev: Solaris,  Up: Profiling compiled code

3.4.3 Mac OS X
--------------

Developers have recommended `sample' (or `Sampler.app', which is a GUI
version) and `Shark' (see
`http://developer.apple.com/tools/sharkoptimize.html' and
`http://developer.apple.com/tools/shark_optimize.html').


File: R-exts.info,  Node: Debugging,  Next: System and foreign language interfaces,  Prev: Tidying and profiling R code,  Up: Top

4 Debugging
***********

This chapter covers the debugging of R extensions, starting with the
ways to get useful error information and moving on to how to deal with
errors that crash R.  For those who prefer other styles there are
contributed packages such as *debug* on CRAN (described in an article in
R-News 3/3 (http://cran.r-project.org/doc/Rnews/Rnews_2003-3.pdf)).
(There are notes from 2002 provided by Roger Peng at
`http://www.biostat.jhsph.edu/~rpeng/docs/R-debug-tools.pdf' which
provide complementary examples to those given here.)

* Menu:

* Browsing::
* Debugging R code::
* Using gctorture and valgrind::
* Debugging compiled code::


File: R-exts.info,  Node: Browsing,  Next: Debugging R code,  Prev: Debugging,  Up: Debugging

4.1 Browsing
============

Most of the R-level debugging facilities are based around the built-in
browser.  This can be used directly by inserting a call to `browser()'
into the code of a function (for example, using `fix(my_function)' ).
When code execution reaches that point in the function, control returns
to the R console with a special prompt.  For example

     > fix(summary.data.frame) ## insert browser() call after for() loop
     > summary(women)
     Called from: summary.data.frame(women)
     Browse[1]> ls()
      [1] "digits" "i"      "lbs"    "lw"     "maxsum" "nm"     "nr"     "nv"
      [9] "object" "sms"    "z"
     Browse[1]> maxsum
     [1] 7
     Browse[1]>
          height         weight
      Min.   :58.0   Min.   :115.0
      1st Qu.:61.5   1st Qu.:124.5
      Median :65.0   Median :135.0
      Mean   :65.0   Mean   :136.7
      3rd Qu.:68.5   3rd Qu.:148.0
      Max.   :72.0   Max.   :164.0
     > rm(summary.data.frame)

At the browser prompt one can enter any R expression, so for example
`ls()' lists the objects in the current frame, and entering the name of
an object will(1) print it.  The following commands are also accepted

   * `n'

     Enter `step-through' mode.  In this mode, hitting return executes
     the next line of code (more precisely one line and any
     continuation lines).  Typing `c' will continue to the end of the
     current context, e.g.  to the end of the current loop or function.

   * `c'

     In normal mode, this quits the browser and continues execution,
     and just return works in the same way.  `cont' is a synonym.

   * `where'

     This prints the call stack.  For example

          > summary(women)
          Called from: summary.data.frame(women)
          Browse[1]> where
          where 1: summary.data.frame(women)
          where 2: summary(women)

          Browse[1]>

   * `Q'

     Quit both the browser and the current expression, and return to the
     top-level prompt.

   Errors in code executed at the browser prompt will normally return
control to the browser prompt.  Objects can be altered by assignment,
and will keep their changed values when the browser is exited.  If
really necessary, objects can be assigned to the workspace from the
browser prompt (by using `<<-' if the name is not already in scope).

   ---------- Footnotes ----------

   (1) With the exceptions of the commands listed below: an object of
such a name can be printed _via_ an explicit call to `print'.


File: R-exts.info,  Node: Debugging R code,  Next: Using gctorture and valgrind,  Prev: Browsing,  Up: Debugging

4.2 Debugging R code
====================

Suppose your R program gives an error message.  The first thing to find
out is what R was doing at the time of the error, and the most useful
tool is `traceback()'.  We suggest that this is run whenever the cause
of the error is not immediately obvious.  Daily, errors are reported to
the R mailing lists as being in some package when `traceback()' would
show that the error was being reported by some other package or base R.
Here is an example from the regression suite.

     > success <- c(13,12,11,14,14,11,13,11,12)
     > failure <- c(0,0,0,0,0,0,0,2,2)
     > resp <- cbind(success, failure)
     > predictor <- c(0, 5^(0:7))
     > glm(resp ~ 0+predictor, family = binomial(link="log"))
     Error: no valid set of coefficients has been found: please supply starting values
     > traceback()
     3: stop("no valid set of coefficients has been found: please supply
              starting values", call. = FALSE)
     2: glm.fit(x = X, y = Y, weights = weights, start = start, etastart = etastart,
            mustart = mustart, offset = offset, family = family, control = control,
            intercept = attr(mt, "intercept") > 0)
     1: glm(resp ~ 0 + predictor, family = binomial(link ="log"))

The calls to the active frames are given in reverse order (starting with
the innermost).  So we see the error message comes from an explicit
check in `glm.fit'.  (`traceback()' shows you all the lines of the
function calls, which can be limited by setting `option'
`"deparse.max.lines"'.)

   Sometimes the traceback will indicate that the error was detected
inside compiled code, for example (from `?nls')

     Error in nls(y ~ a + b * x, start = list(a = 0.12345, b = 0.54321), trace = TRUE) :
             step factor 0.000488281 reduced below 'minFactor' of 0.000976563
     >  traceback()
     2: .Call(R_nls_iter, m, ctrl, trace)
     1: nls(y ~ a + b * x, start = list(a = 0.12345, b = 0.54321), trace = TRUE)

This will be the case if the innermost call is to `.C', `.Fortran',
`.Call', `.External' or `.Internal', but as it is also possible for
such code to evaluate R expressions, this need not be the innermost
call, as in

     > traceback()
     9: gm(a, b, x)
     8: .Call(R_numeric_deriv, expr, theta, rho, dir)
     7: numericDeriv(form[[3]], names(ind), env)
     6: getRHS()
     5: assign("rhs", getRHS(), envir = thisEnv)
     4: assign("resid", .swts * (lhs - assign("rhs", getRHS(), envir = thisEnv)),
            envir = thisEnv)
     3: function (newPars)
        {
            setPars(newPars)
            assign("resid", .swts * (lhs - assign("rhs", getRHS(), envir = thisEnv)),
                envir = thisEnv)
            assign("dev", sum(resid^2), envir = thisEnv)
            assign("QR", qr(.swts * attr(rhs, "gradient")), envir = thisEnv)
            return(QR$rank < min(dim(QR$qr)))
        }(c(-0.00760232418963883, 1.00119632515036))
     2: .Call(R_nls_iter, m, ctrl, trace)
     1: nls(yeps ~ gm(a, b, x), start = list(a = 0.12345, b = 0.54321))

   Occasionally `traceback()' does not help, and this can be the case
if S4 method dispatch is involved.  Consider the following example

     > xyd <- new("xyloc", x=runif(20), y=runif(20))
     Error in as.environment(pkg) : no item called "package:S4nswv"
     on the search list
     Error in initialize(value, ...) : S language method selection got
     an error when called from internal dispatch for function 'initialize'
     > traceback()
     2: initialize(value, ...)
     1: new("xyloc", x = runif(20), y = runif(20))

which does not help much, as there is no call to `as.environment' in
`initialize' (and the note "called from internal dispatch" tells us
so).  In this case we searched the R sources for the quoted call, which
occurred in only one place, `methods:::.asEnvironmentPackage'.  So now
we knew where the error was occurring.  (This was an unusually opaque
example.)

   The error message

     evaluation nested too deeply: infinite recursion / options(expressions=)?

can be hard to handle with the default value (5000).  Unless you know
that there actually is deep recursion going on, it can help to set
something like

     options(expressions=500)

and re-run the example showing the error.

   Sometimes there is warning that clearly is the precursor to some
later error, but it is not obvious where it is coming from.  Setting
`options(warn = 2)' (which turns warnings into errors) can help here.

   Once we have located the error, we have some choices.  One way to
proceed is to find out more about what was happening at the time of the
crash by looking a _post-mortem_ dump.  To do so, set `options(error=dump.frames)'
and run the code again.  Then invoke `debugger()' and explore the dump.
Continuing our example:

     > options(error = dump.frames)
     > glm(resp ~ 0 + predictor, family = binomial(link ="log"))
     Error: no valid set of coefficients has been found: please supply starting values

which is the same as before, but an object called `last.dump' has
appeared in the workspace.  (Such objects can be large, so remove it
when it is no longer needed.)  We can examine this at a later time by
calling the function `debugger'.  

     > debugger()
     Message:  Error: no valid set of coefficients has been found: please supply starting values
     Available environments had calls:
     1: glm(resp ~ 0 + predictor, family = binomial(link = "log"))
     2: glm.fit(x = X, y = Y, weights = weights, start = start, etastart = etastart, mus
     3: stop("no valid set of coefficients has been found: please supply starting values
     Enter an environment number, or 0 to exit  Selection:

which gives the same sequence of calls as `traceback', but in
outer-first order and with only the first line of the call, truncated to
the current width.  However, we can now examine in more detail what was
happening at the time of the error.  Selecting an environment opens the
browser in that frame.  So we select the function call which spawned the
error message, and explore some of the variables (and execute two
function calls).

     Enter an environment number, or 0 to exit  Selection: 2
     Browsing in the environment with call:
        glm.fit(x = X, y = Y, weights = weights, start = start, etas
     Called from: debugger.look(ind)
     Browse[1]> ls()
      [1] "aic"        "boundary"   "coefold"    "control"    "conv"
      [6] "dev"        "dev.resids" "devold"     "EMPTY"      "eta"
     [11] "etastart"   "family"     "fit"        "good"       "intercept"
     [16] "iter"       "linkinv"    "mu"         "mu.eta"     "mu.eta.val"
     [21] "mustart"    "n"          "ngoodobs"   "nobs"       "nvars"
     [26] "offset"     "start"      "valideta"   "validmu"    "variance"
     [31] "varmu"      "w"          "weights"    "x"          "xnames"
     [36] "y"          "ynames"     "z"
     Browse[1]> eta
                 1             2             3             4             5
      0.000000e+00 -2.235357e-06 -1.117679e-05 -5.588393e-05 -2.794197e-04
                 6             7             8             9
     -1.397098e-03 -6.985492e-03 -3.492746e-02 -1.746373e-01
     Browse[1]> valideta(eta)
     [1] TRUE
     Browse[1]> mu
             1         2         3         4         5         6         7         8
     1.0000000 0.9999978 0.9999888 0.9999441 0.9997206 0.9986039 0.9930389 0.9656755
             9
     0.8397616
     Browse[1]> validmu(mu)
     [1] FALSE
     Browse[1]> c
     Available environments had calls:
     1: glm(resp ~ 0 + predictor, family = binomial(link = "log"))
     2: glm.fit(x = X, y = Y, weights = weights, start = start, etastart = etastart
     3: stop("no valid set of coefficients has been found: please supply starting v

     Enter an environment number, or 0 to exit  Selection: 0
     > rm(last.dump)

   Because `last.dump' can be looked at later or even in another R
session, post-mortem debugging is possible even for batch usage of R.
We do need to arrange for the dump to be saved: this can be done either
using the command-line flag `--save' to save the workspace at the end
of the run, or _via_ a setting such as

     > options(error = quote({dump.frames(to.file=TRUE); q()}))

See the help on `dump.frames' for further options and a worked example.

   An alternative error action is to use the function `recover()':

     > options(error = recover)
     > glm(resp ~ 0 + predictor, family = binomial(link = "log"))
     Error: no valid set of coefficients has been found: please supply starting values

     Enter a frame number, or 0 to exit

     1: glm(resp ~ 0 + predictor, family = binomial(link = "log"))
     2: glm.fit(x = X, y = Y, weights = weights, start = start, etastart = etastart

     Selection:

which is very similar to `dump.frames'.  However, we can examine the
state of the program directly, without dumping and re-loading the dump.
As its help page says, `recover' can be routinely used as the error
action in place of `dump.calls' and `dump.frames', since it behaves
like `dump.frames' in non-interactive use.

   Post-mortem debugging is good for finding out exactly what went
wrong, but not necessarily why.  An alternative approach is to take a
closer look at what was happening just before the error, and a good way
to do that is to use `debug'.  This inserts a call to the browser at
the beginning of the function, starting in step-through mode.  So in
our example we could use

     > debug(glm.fit)
     > glm(resp ~ 0 + predictor, family = binomial(link ="log"))
     debugging in: glm.fit(x = X, y = Y, weights = weights, start = start, etastart = etastart,
         mustart = mustart, offset = offset, family = family, control = control,
         intercept = attr(mt, "intercept") > 0)
     debug: {
     ## lists the whole function
     Browse[1]>
     debug: x <- as.matrix(x)
     ...
     Browse[1]> start
     [1] -2.235357e-06
     debug: eta <- drop(x %*% start)
     Browse[1]> eta
                 1             2             3             4             5
      0.000000e+00 -2.235357e-06 -1.117679e-05 -5.588393e-05 -2.794197e-04
                 6             7             8             9
     -1.397098e-03 -6.985492e-03 -3.492746e-02 -1.746373e-01
     Browse[1]>
     debug: mu <- linkinv(eta <- eta + offset)
     Browse[1]> mu
             1         2         3         4         5         6         7         8
     1.0000000 0.9999978 0.9999888 0.9999441 0.9997206 0.9986039 0.9930389 0.9656755
             9
     0.8397616

(The prompt `Browse[1]>' indicates that this is the first level of
browsing: it is possible to step into another function that is itself
being debugged or contains a call to `browser()'.)

   `debug' can be used for hidden functions and S3 methods by e.g.
`debug(stats:::predict.Arima)'.  (It cannot be used for S4 methods, but
an alternative is given on the help page for `debug'.)  Sometimes you
want to debug a function defined inside another function, e.g. the
function `arimafn' defined inside `arima'.  To do so, set `debug' on
the outer function (here `arima') and step through it until the inner
function has been defined.  Then call `debug' on the inner function
(and use `c' to get out of step-through mode in the outer function).

   To remove debugging of a function, call `undebug' with the argument
previously given to `debug'; debugging otherwise lasts for the rest of
the R session (or until the function is edited or otherwise replaced).

   `trace' can be used to temporarily insert debugging code into a
function, for example to insert a call to `browser()' just before the
point of the error.  To return to our running example

     ## first get a numbered listing of the expressions of the function
     > page(as.list(body(glm.fit)), method="print")
     > trace(glm.fit, browser, at=22)
     Tracing function "glm.fit" in package "stats"
     [1] "glm.fit"
     > glm(resp ~ 0 + predictor, family = binomial(link ="log"))
     Tracing glm.fit(x = X, y = Y, weights = weights, start = start,
        etastart = etastart,  .... step 22
     Called from: eval(expr, envir, enclos)
     Browse[1]> n
     ## and single-step from here.
     > untrace(glm.fit)
   For your own functions, it may be as easy to use `fix' to insert
temporary code, but `trace' can help with functions in a name space (as
can `fixInNamespace').  Alternatively, use `trace(,edit=TRUE)' to
insert code visually.


File: R-exts.info,  Node: Using gctorture and valgrind,  Next: Debugging compiled code,  Prev: Debugging R code,  Up: Debugging

4.3 Using gctorture and valgrind
================================

Errors in memory allocation and reading/writing outside arrays are very
common causes of crashes (e.g., segfaults) on some machines.  Often the
crash appears long after the invalid memory access: in particular
damage to the structures which R itself has allocated may only become
apparent at the next garbage collection (or even at later garbage
collections after objects have been deleted).

* Menu:

* Using gctorture::
* Using valgrind::


File: R-exts.info,  Node: Using gctorture,  Next: Using valgrind,  Prev: Using gctorture and valgrind,  Up: Using gctorture and valgrind

4.3.1 Using gctorture
---------------------

We can help to detect memory problems earlier by running garbage
collection as often as possible.  This is achieved by
`gctorture(TRUE)', which as described on its help page

     Provokes garbage collection on (nearly) every memory allocation.
     Intended to ferret out memory protection bugs.  Also makes R run
     _very_ slowly, unfortunately.

The reference to `memory protection' is to missing C-level calls to
`PROTECT'/`UNPROTECT' (*note Garbage Collection::) which if missing
allow R objects to be garbage-collected when they are still in use.
But it can also help with other memory-related errors.

   Normally running under `gctorture(TRUE)' will just produce a crash
earlier in the R program, hopefully close to the actual cause. See the
next section for how to decipher such crashes.

   It is possible to run all the examples, tests and vignettes covered
by `R CMD check' under `gctorture(TRUE)' by using the option
`--use-gct'.


File: R-exts.info,  Node: Using valgrind,  Prev: Using gctorture,  Up: Using gctorture and valgrind

4.3.2 Using valgrind
--------------------

If you have access to Linux on an `ix86', `x86_64', `ppc32' or `ppc64'
platform, or Mac OS 10.5.x (`Leopard') on `i386' you can use `valgrind'
(`http://www.valgrind.org/', pronounced to rhyme with `tinned') to
check for possible problems.  To run some examples under `valgrind' use
something like

     R -d valgrind --vanilla < mypkg-Ex.R
     R -d "valgrind --tool=memcheck --leak-check=full" --vanilla < mypkg-Ex.R

where `mypkg-Ex.R' is a set of examples, e.g. the file created in
`mypkg.Rcheck' by `R CMD check'.  Occasionally this reports memory
reads of `uninitialised values' that are the result of compiler
optimization, so can be worth checking under an unoptimized compile.  We
know there will be some small memory leaks from `readline' and R itself
-- these are memory areas that are in use right up to the end of the R
session.  Expect this to run around 20x slower than without `valgrind',
and in some cases even slower than that.  Earlier versions (at least)
of `valgrind' are not happy with many optimized BLASes that use
CPU-specific instructions (3D now, SSE, SSE2, SSE3 and similar) so you
may need to build a version of R specifically to use with `valgrind'.

   On platforms supported by `valgrind' you can build a version of R
with extra instrumentation to help `valgrind' detect errors in the use
of memory allocated from the R heap.  The configure option is
`--with-valgrind-instrumentation=LEVEL', where LEVEL is 0, 1, or 2.
Level 0 is the default and does not add any anything.  Level 1 will
detect use of uninitialised memory and has little impact on speed.
Level 2 will detect many other memory use bugs but makes R much slower
when running under `valgrind'.  Using this in conjunction with
`gctorture' can be even more effective (and even slower).

   An example of `valgrind' output is
     ==12539== Invalid read of size 4
     ==12539==    at 0x1CDF6CBE: csc_compTr (Mutils.c:273)
     ==12539==    by 0x1CE07E1E: tsc_transpose (dtCMatrix.c:25)
     ==12539==    by 0x80A67A7: do_dotcall (dotcode.c:858)
     ==12539==    by 0x80CACE2: Rf_eval (eval.c:400)
     ==12539==    by 0x80CB5AF: R_execClosure (eval.c:658)
     ==12539==    by 0x80CB98E: R_execMethod (eval.c:760)
     ==12539==    by 0x1B93DEFA: R_standardGeneric (methods_list_dispatch.c:624)
     ==12539==    by 0x810262E: do_standardGeneric (objects.c:1012)
     ==12539==    by 0x80CAD23: Rf_eval (eval.c:403)
     ==12539==    by 0x80CB2F0: Rf_applyClosure (eval.c:573)
     ==12539==    by 0x80CADCC: Rf_eval (eval.c:414)
     ==12539==    by 0x80CAA03: Rf_eval (eval.c:362)
     ==12539==  Address 0x1C0D2EA8 is 280 bytes inside a block of size 1996 alloc'd
     ==12539==    at 0x1B9008D1: malloc (vg_replace_malloc.c:149)
     ==12539==    by 0x80F1B34: GetNewPage (memory.c:610)
     ==12539==    by 0x80F7515: Rf_allocVector (memory.c:1915)
     ...
   This example is from an instrumented version of R, while tracking
down a bug in the *Matrix* package in January, 2006.  The first line
indicates that R has tried to read 4 bytes from a memory address that
it does not have access to. This is followed by a C stack trace showing
where the error occurred. Next is a description of the memory that was
accessed. It is inside a block allocated by `malloc', called from
`GetNewPage', that is, in the internal R heap.  Since this memory all
belongs to R, `valgrind' would not (and did not) detect the problem in
an uninstrumented build of R.  In this example the stack trace was
enough to isolate and fix the bug, which was in `tsc_transpose', and in
this example running under `gctorture()' did not provide any additional
information.  When the stack trace is not sufficiently informative the
option `--db-attach=yes' to `valgrind' may be helpful.  This starts a
post-mortem debugger (by default `gdb') so that variables in the C code
can be inspected (*note Inspecting R objects::).

   It is possible to run all the examples, tests and vignettes covered
by `R CMD check' under `valgrind' by using the option `--use-valgrind'.
If you do this you will need to select the `valgrind' options some
other way, for example by having a `~/.valgrindrc' file containing

     --tool=memcheck
     --memcheck:leak-check=full

or setting the environment variable `VALGRIND_OPTS'.


File: R-exts.info,  Node: Debugging compiled code,  Prev: Using gctorture and valgrind,  Up: Debugging

4.4 Debugging compiled code
===========================

Sooner or later programmers will be faced with the need to debug
compiled code loaded into R.   This section is geared to platforms
using `gdb' with code compiled by `gcc', but similar things are
possible with front-ends to `gdb' such as `ddd' and `insight', and
other debuggers such as Sun's `dbx'.

   Consider first `crashes', that is when R terminated unexpectedly with
an illegal memory access (a `segfault' or `bus error'), illegal
instruction or similar.  Unix-alike versions of R use a signal handler
which aims to give some basic information.  For example

      *** caught segfault ***
     address 0x20000028, cause 'memory not mapped'

     Traceback:
      1: .identC(class1[[1]], class2)
      2: possibleExtends(class(sloti), classi, ClassDef2 = getClassDef(classi,
     where = where))
      3: validObject(t(cu))
      4: stopifnot(validObject(cu <- as(tu, "dtCMatrix")), validObject(t(cu)),
     validObject(t(tu)))

     Possible actions:
     1: abort (with core dump)
     2: normal R exit
     3: exit R without saving workspace
     4: exit R saving workspace
     Selection: 3

Since the R process may be damaged, the only really safe option is the
first.

   Another cause of a `crash' is to overrun the C stack.  R tries to
track that in its own code, but it may happen in third-party compiled
code.  For modern POSIX-compliant OSes we can safely catch that and
return to the top-level prompt.

     > .C("aaa")
     Error: segfault from C stack overflow
     >

However, C stack overflows are fatal under Windows and normally defeat
attempts at debugging on that platform.

   If you have a crash which gives a core dump you can use something
like

     gdb /path/to/R/bin/exec/R core.12345

to examine the core dump.  If core dumps are disabled or to catch errors
that do not generate a dump one can run R directly under a debugger by
for example

     $ R -d gdb --vanilla
     ...
     gdb> run

at which point R will run normally, and hopefully the debugger will
catch the error and return to its prompt.  This can also be used to
catch infinite loops or interrupt very long-running code.  For a simple
example

     > for(i in 1:1e7) x <- rnorm(100)
     [hit Ctrl-C]
     Program received signal SIGINT, Interrupt.
     0x00397682 in _int_free () from /lib/tls/libc.so.6
     (gdb) where
     #0  0x00397682 in _int_free () from /lib/tls/libc.so.6
     #1  0x00397eba in free () from /lib/tls/libc.so.6
     #2  0xb7cf2551 in R_gc_internal (size_needed=313)
         at /users/ripley/R/svn/R-devel/src/main/memory.c:743
     #3  0xb7cf3617 in Rf_allocVector (type=13, length=626)
         at /users/ripley/R/svn/R-devel/src/main/memory.c:1906
     #4  0xb7c3f6d3 in PutRNGstate ()
         at /users/ripley/R/svn/R-devel/src/main/RNG.c:351
     #5  0xb7d6c0a5 in do_random2 (call=0x94bf7d4, op=0x92580e8, args=0x9698f98,
         rho=0x9698f28) at /users/ripley/R/svn/R-devel/src/main/random.c:183
     ...

   Some "tricks" are worth knowing.

* Menu:

* Finding entry points::
* Inspecting R objects::


File: R-exts.info,  Node: Finding entry points,  Next: Inspecting R objects,  Prev: Debugging compiled code,  Up: Debugging compiled code

4.4.1 Finding entry points in dynamically loaded code
-----------------------------------------------------

Under most compilation environments, compiled code dynamically loaded
into R cannot have breakpoints set within it until it is loaded.  To
use a symbolic debugger on such dynamically loaded code under
Unix-alikes use

   * Call the debugger on the R executable, for example by `R -d gdb'.

   * Start R.

   * At the R prompt, use `dyn.load' or `library' to load your shared
     object.

   * Send an interrupt signal.  This will put you back to the debugger
     prompt.

   * Set the breakpoints in your code.

   * Continue execution of R by typing `signal 0<RET>'.

   Under Windows signals may not be able to be used, and if so the
procedure is more complicated.  See the rw-FAQ and
`www.stats.uwo.ca/faculty/murdoch/software/debuggingR/gdb.shtml'
(http://www.stats.uwo.ca/faculty/murdoch/software/debuggingR/gdb.shtml).


File: R-exts.info,  Node: Inspecting R objects,  Prev: Finding entry points,  Up: Debugging compiled code

4.4.2 Inspecting R objects when debugging
-----------------------------------------

The key to inspecting R objects from compiled code is the function
`PrintValue(SEXP S)' which uses the normal R printing mechanisms to
print the R object pointed to by S, or the safer version `R_PV(SEXP S)'
which will only print `objects'.

   One way to make use of `PrintValue' is to insert suitable calls into
the code to be debugged.

   Another way is to call `R_PV' from the symbolic debugger.
(`PrintValue' is hidden as `Rf_PrintValue'.)  For example, from `gdb'
we can use

     (gdb) p R_PV(ab)

using the object `ab' from the convolution example, if we have placed a
suitable breakpoint in the convolution C code.

   To examine an arbitrary R object we need to work a little harder.
For example, let

     R> DF <- data.frame(a = 1:3, b = 4:6)

By setting a breakpoint at `do_get' and typing `get("DF")' at the R
prompt, one can find out the address in memory of `DF', for example

     Value returned is $1 = (SEXPREC *) 0x40583e1c
     (gdb) p *$1
     $2 = {
       sxpinfo = {type = 19, obj = 1, named = 1, gp = 0,
         mark = 0, debug = 0, trace = 0, = 0},
       attrib = 0x40583e80,
       u = {
         vecsxp = {
           length = 2,
           type = {c = 0x40634700 "0>X@D>X@0>X@", i = 0x40634700,
             f = 0x40634700, z = 0x40634700, s = 0x40634700},
           truelength = 1075851272,
         },
         primsxp = {offset = 2},
         symsxp = {pname = 0x2, value = 0x40634700, internal = 0x40203008},
         listsxp = {carval = 0x2, cdrval = 0x40634700, tagval = 0x40203008},
         envsxp = {frame = 0x2, enclos = 0x40634700},
         closxp = {formals = 0x2, body = 0x40634700, env = 0x40203008},
         promsxp = {value = 0x2, expr = 0x40634700, env = 0x40203008}
       }
     }

(Debugger output reformatted for better legibility).

   Using `R_PV()' one can "inspect" the values of the various elements
of the SEXP, for example,

     (gdb) p R_PV($1->attrib)
     $names
     [1] "a" "b"

     $row.names
     [1] "1" "2" "3"

     $class
     [1] "data.frame"

     $3 = void

   To find out where exactly the corresponding information is stored,
one needs to go "deeper":

     (gdb) set $a = $1->attrib
     (gdb) p $a->u.listsxp.tagval->u.symsxp.pname->u.vecsxp.type.c
     $4 = 0x405d40e8 "names"
     (gdb) p $a->u.listsxp.carval->u.vecsxp.type.s[1]->u.vecsxp.type.c
     $5 = 0x40634378 "b"
     (gdb) p $1->u.vecsxp.type.s[0]->u.vecsxp.type.i[0]
     $6 = 1
     (gdb) p $1->u.vecsxp.type.s[1]->u.vecsxp.type.i[1]
     $7 = 5


File: R-exts.info,  Node: System and foreign language interfaces,  Next: The R API,  Prev: Debugging,  Up: Top

5 System and foreign language interfaces
****************************************

* Menu:

* Operating system access::
* Interface functions .C and .Fortran::
* dyn.load and dyn.unload::
* Registering native routines::
* Creating shared objects::
* Interfacing C++ code::
* Fortran I/O::
* Linking to other packages::
* Handling R objects in C::
* Interface functions .Call and .External::
* Evaluating R expressions from C::
* Parsing R code from C::
* External pointers and weak references::
* Vector accessor functions::
* Character encoding issues::


File: R-exts.info,  Node: Operating system access,  Next: Interface functions .C and .Fortran,  Prev: System and foreign language interfaces,  Up: System and foreign language interfaces

5.1 Operating system access
===========================

Access to operating system functions is _via_ the R function `system'.  The
details will differ by platform (see the on-line help), and about all
that can safely be assumed is that the first argument will be a string
`command' that will be passed for execution (not necessarily by a
shell) and the second argument will be `internal' which if true will
collect the output of the command into an R character vector.

   The function `system.time' is available for timing (although the
information available may be limited on non-Unix-like platforms: these
days only on the obsolete Windows 9x/ME).


File: R-exts.info,  Node: Interface functions .C and .Fortran,  Next: dyn.load and dyn.unload,  Prev: Operating system access,  Up: System and foreign language interfaces

5.2 Interface functions `.C' and `.Fortran'
===========================================

These two functions provide a standard interface to compiled code that
has been linked into R, either at build time or _via_ `dyn.load' (*note
dyn.load and dyn.unload::).  They are primarily intended for compiled C
and FORTRAN 77 code respectively, but the `.C' function can be used
with other languages which can generate C interfaces, for example C++
(*note Interfacing C++ code::).

   The first argument to each function is a character string given the
symbol name as known to C or FORTRAN, that is the function or subroutine
name.  (That the symbol is loaded can be tested by, for example,
`is.loaded("cg")': it is no longer necessary nor correct to use
`symbol.For', which is defunct as from R 2.5.0.)  (Note that the
underscore is not a valid character in a FORTRAN 77 subprogram name, and
on versions of R prior to 2.4.0 `.Fortran' may not correctly translate
names containing underscores.)

   There can be up to 65 further arguments giving R objects to be passed
to compiled code.  Normally these are copied before being passed in, and
copied again to an R list object when the compiled code returns.  If
the arguments are given names, these are used as names for the
components in the returned list object (but not passed to the compiled
code).

   The following table gives the mapping between the modes of R vectors
and the types of arguments to a C function or FORTRAN subroutine.

     R storage mode     C type                   FORTRAN type
     --------------------------------------------------------------- 
     `logical'          `int *'                  `INTEGER'
     `integer'          `int *'                  `INTEGER'
     `double'           `double *'               `DOUBLE PRECISION'
     `complex'          `Rcomplex *'             `DOUBLE COMPLEX'
     `character'        `char **'                `CHARACTER*255'
     `raw'              `unsigned char *'        none

   Do please note the first two.  On the 64-bit Unix/Linux platforms,
`long' is 64-bit whereas `int' and `INTEGER' are 32-bit.  Code ported
from S-PLUS (which uses `long *' for `logical' and `integer') will not
work on all 64-bit platforms (although it may appear to work on some).
Note also that if your compiled code is a mixture of C functions and
FORTRAN subprograms the argument types must match as given in the table
above.

   C type `Rcomplex' is a structure with `double' members `r' and `i'
defined in the header file `R_ext/Complex.h' included by `R.h'.  (On
most platforms which have it, this is compatible withe C99 `double
complex' type.)  Only a single character string can be passed to or
from FORTRAN, and the success of this is compiler-dependent.  Other R
objects can be passed to `.C', but it is better to use one of the other
interfaces.  An exception is passing an R function for use with
`call_R', when the object can be handled as `void *' en route to
`call_R', but even there `.Call' is to be preferred.  Similarly,
passing an R list as an argument to a C routine should be done using
the `.Call' interface.  If one does use the `.C' function to pass a
list as an argument, it is visible to the routine as an array in C of
`SEXP' types (i.e., `SEXP *').  The elements of the array correspond
directly to the elements of the R list.  However, this array must be
treated as read-only and one must not assign values to its elements
within the C routine -- doing so bypasses R's memory management
facilities and will corrupt the object and the R session.

   It is possible to pass numeric vectors of storage mode `double' to C
as `float *' or to FORTRAN as `REAL' by setting the attribute
`Csingle', most conveniently by using the R functions `as.single',
`single' or `mode'.  This is intended only to be used to aid
interfacing to existing C or FORTRAN code.

   Unless formal argument `NAOK' is true, all the other arguments are
checked for missing values `NA' and for the IEEE special values `NaN',
`Inf' and `-Inf', and the presence of any of these generates an error.
If it is true, these values are passed unchecked.

   Argument `DUP' can be used to suppress copying.  It is dangerous:
see the on-line help for arguments against its use.  It is not possible
to pass numeric vectors as `float *' or `REAL' if `DUP=FALSE', and
character vectors cannot be used.

   Argument `PACKAGE' confines the search for the symbol name to a
specific shared object (or use `"base"' for code compiled into R).  Its
use is highly desirable, as there is no way to avoid two package
writers using the same symbol name, and such name clashes are normally
sufficient to cause R to crash.  (If it is not present and the call is
from the body of a function defined in a package with a name space, the
shared object loaded by the first (if any) `useDynLib' directive will
be used.)

   For `.C' and `.Fortran' you can specify an `ENCODING' argument: this
requests that (unless `DUP = FALSE') character vectors be re-encoded to
the requested encoding before being passed in, and re-encoded from the
requested encoding when passed back.  Note that encoding names are not
standardized, and not all R builds support re-encoding.  But this can
be useful to allow code to work in a UTF-8 locale by specifying
`ENCODING = "latin1"'.

   Note that the compiled code should not return anything except through
its arguments: C functions should be of type `void' and FORTRAN
subprograms should be subroutines.

   To fix ideas, let us consider a very simple example which convolves
two finite sequences. (This is hard to do fast in interpreted R code,
but easy in C code.)  We could do this using `.C' by

     void convolve(double *a, int *na, double *b, int *nb, double *ab)
     {
       int i, j, nab = *na + *nb - 1;

       for(i = 0; i < nab; i++)
         ab[i] = 0.0;
       for(i = 0; i < *na; i++)
         for(j = 0; j < *nb; j++)
           ab[i + j] += a[i] * b[j];
     }

called from R by

     conv <- function(a, b)
       .C("convolve",
          as.double(a),
          as.integer(length(a)),
          as.double(b),
          as.integer(length(b)),
          ab = double(length(a) + length(b) - 1))$ab

   Note that we take care to coerce all the arguments to the correct R
storage mode before calling `.C'; mistakes in matching the types can
lead to wrong results or hard-to-catch errors.

   Special care is needed in handling `character' vector arguments in C
(or C++).  Since only `DUP = TRUE' is allowed, on entry the contents of
the elements are duplicated and assigned to the elements of a `char **'
array, and on exit the elements of the C array are copied to create new
elements of a character vector.  This means that the contents of the
character strings of the `char **' array can be changed, including to
`\0' to shorten the string, but the strings cannot be lengthened.  It
is possible to allocate a new string _via_ `R_alloc' and replace an
entry in the `char **' array by the new string.  However, when
character vectors are used other than in a read-only way, the `.Call'
interface is much to be preferred.

   Passing character strings to FORTRAN code needs even more care, and
should be avoided where possible.  Only the first element of the
character vector is passed in, as a fixed-length (255) character array.
Up to 255 characters are passed back to a length-one character vector.
How well this works (or even if it works at all) depends on the C and
FORTRAN compilers on each platform.


File: R-exts.info,  Node: dyn.load and dyn.unload,  Next: Registering native routines,  Prev: Interface functions .C and .Fortran,  Up: System and foreign language interfaces

5.3 `dyn.load' and `dyn.unload'
===============================

Compiled code to be used with R is loaded as a shared object (Unix and
Mac OS X, *note Creating shared objects:: for more information) or DLL
(Windows).

   The shared object/DLL is loaded by `dyn.load' and unloaded by
`dyn.unload'.  Unloading is not normally necessary, but it is needed to
allow the DLL to be re-built on some platforms, including Windows.

   The first argument to both functions is a character string giving the
path to the object.  Programmers should not assume a specific file
extension for the object/DLL (such as `.so') but use a construction like

     file.path(path1, path2, paste("mylib", .Platform$dynlib.ext, sep=""))

for platform independence.  On Unix-alike systems the path supplied to
`dyn.load' can be an absolute path, one relative to the current
directory or, if it starts with `~', relative to the user's home
directory.

   Loading is most often done _via_ a call to `library.dynam' in the
`.First.lib' function of a package.  This has the form

     library.dynam("libname", package, lib.loc)

where `libname' is the object/DLL name _with the extension omitted_.
Note that the first argument, `chname', should *not* be `package' since
this will not work if the package is installed under another name.

   Under some Unix-alike systems there is a choice of how the symbols
are resolved when the object is loaded, governed by the arguments
`local' and `now'.  Only use these if really necessary: in particular
using `now=FALSE' and then calling an unresolved symbol will terminate
R unceremoniously.

   R provides a way of executing some code automatically when a
object/DLL is either loaded or unloaded.  This can be used, for
example, to register native routines with R's dynamic symbol mechanism,
initialize some data in the native code, or initialize a third party
library.  On loading a DLL, R will look for a routine within that DLL
named `R_init_LIB' where LIB is the name of the DLL file with the
extension removed.  For example, in the command

     library.dynam("mylib", package, lib.loc)

R looks for the symbol named `R_init_mylib'.  Similarly, when unloading
the object, R looks for a routine named `R_unload_LIB', e.g.,
`R_unload_mylib'.  In either case, if the routine is present, R will
invoke it and pass it a single argument describing the DLL.  This is a
value of type `DllInfo' which is defined in the `Rdynload.h' file in
the `R_ext' directory.

   The following example shows templates for the initialization and
unload routines for the `mylib' DLL.

          #include <R.h>
          #include <Rinternals.h>
          #include <R_ext/Rdynload.h>

          void
          R_init_mylib(DllInfo *info)
          {
            /* Register routines, allocate resources. */
          }

          void
          R_unload_mylib(DllInfo *info)
          {
            /* Release resources. */
          }

   If a shared object/DLL is loaded more than once the most recent
version is used.  More generally, if the same symbol name appears in
several libraries, the most recently loaded occurrence is used.  The
`PACKAGE' argument and registration (see the next section) provide good
ways to avoid any ambiguity in which occurrence is meant.

   On Unix-alikes the paths used to resolve dynamically linked dependent
libraries are fixed (for security reasons) when the process is launched,
so `dyn.load' will only look for such libraries in the locations set by
the `R' shell script (_via_ `etc/ldpaths') and in the OS-specific
defaults.

   Windows allows more control (and less security) over where dependent
DLLs are looked for.  On all versions this includes the `PATH'
environment variable, but with lowest priority: note that it does not
include the directory from which the DLL was loaded.  On XP and later it
is possible(1) to add a single path with quite high priority _via_ the
`DLLpath' argument to `dyn.load'.  This is (by default) used by
`library.dynam' to include the package's `libs' directory in the DLL
search path.

   ---------- Footnotes ----------

   (1) and we provide an emulation on Windows 2000: see `?dyn.load'.


File: R-exts.info,  Node: Registering native routines,  Next: Creating shared objects,  Prev: dyn.load and dyn.unload,  Up: System and foreign language interfaces

5.4 Registering native routines
===============================

By `native' routine, we mean an entry point in compiled code.

   In calls to `.C', `.Call', `.Fortran' and `.External', R must locate
the specified native routine by looking in the appropriate shared
object/DLL.  By default, R uses the operating system-specific dynamic
loader to lookup the symbol.  Alternatively, the author of the DLL can
explicitly register routines with R and use a single,
platform-independent mechanism for finding the routines in the DLL.
One can use this registration mechanism to provide additional
information about a routine, including the number and type of the
arguments, and also make it available to R programmers under a different
name.  In the future, registration may be used to implement a form of
"secure" or limited native access.

   To register routines with R, one calls the C routine
`R_registerRoutines'.  This is typically done when the DLL is first
loaded within the initialization routine `R_init_DLL NAME' described in
*Note dyn.load and dyn.unload::.  `R_registerRoutines' takes 5
arguments.  The first is the `DllInfo' object passed by R to the
initialization routine. This is where R stores the information about
the methods.  The remaining 4 arguments are arrays describing the
routines for each of the 4 different interfaces: `.C', `.Call',
`.Fortran' and `.External'.  Each argument is a `NULL'-terminated array
of the element types given in the following table:

     `.C'            `R_CMethodDef'
     `.Call'         `R_CallMethodDef'
     `.Fortran'      `R_FortranMethodDef'
     `.External'     `R_ExternalMethodDef'

   Currently, the `R_ExternalMethodDef' is the same as
`R_CallMethodDef' type and contains fields for the name of the routine
by which it can be accessed in R, a pointer to the actual native symbol
(i.e., the routine itself), and the number of arguments the routine
expects.  For routines with a variable number of arguments invoked
_via_ the `.External' interface, one specifies `-1' for the number of
arguments which tells R not to check the actual number passed.  For
example, if we had a routine named `myCall' defined as

     SEXP myCall(SEXP a, SEXP b, SEXP c);

we would describe this as

     R_CallMethodDef callMethods[]  = {
       {"myCall", &myCall, 3},
       {NULL, NULL, 0}
     };

along with any other routines for the `.Call' interface.

   Routines for use with the `.C' and `.Fortran' interfaces are
described with similar data structures, but which have two additional
fields for describing the type and "style" of each argument.  Each of
these can be omitted. However, if specified, each should be an array
with the same number of elements as the number of parameters for the
routine.  The types array should contain the `SEXP' types describing
the expected type of the argument. (Technically, the elements of the
types array are of type `R_NativePrimitiveArgType' which is just an
unsigned integer.)  The R types and corresponding type identifiers are
provided in the following table:

     `numeric'       `REALSXP'
     `integer'       `INTSXP'
     `logical'       `LGLSXP'
     `single'        `SINGLESXP'
     `character'     `STRSXP'
     `list'          `VECSXP'

   Consider a C routine, `myC', declared as

     void myC(double *x, int *n, char **names, int *status);

   We would register it as

     R_CMethodDef cMethods[] = {
        {"myC", &myC, 4, {REALSXP, INTSXP, STRSXP, LGLSXP}},
        {NULL, NULL, 0}
     };

   One can also specify whether each argument is used simply as input,
or as output, or as both input and output.  The style field in the
description of a method is used for this.  The purpose is to allow R to
transfer values more efficiently across the R-C/FORTRAN interface by
avoiding copying values when it is not necessary. Typically, one omits
this information in the registration data.

   Having created the arrays describing each routine, the last step is
to actually register them with R.  We do this by calling
`R_registerRoutines'.  For example, if we have the descriptions above
for the routines accessed by the `.C' and `.Call' we would use the
following code:

     void
     R_init_myLib(DllInfo *info)
     {
        R_registerRoutines(info, cMethods, callMethods, NULL, NULL);
     }

   This routine will be invoked when R loads the shared object/DLL named
`myLib'.  The last two arguments in the call to `R_registerRoutines'
are for the routines accessed by `.Fortran' and `.External' interfaces.
In our example, these are given as `NULL' since we have no routines of
these types.

   When R unloads a shared object/DLL, any registered routines are
automatically removed. There is no (direct) facility for unregistering
a symbol.

   Examples of registering routines can be found in the different
packages in the R source tree (e.g., *stats*).  Also, there is a brief,
high-level introduction in _R News_ (volume 1/3, September 2001, pages
20-23).

   In addition to registering C routines to be called by R, it can at
times be useful for one package to make some of its C routines available
to be called by C code in another package.  An interface to support this
has been provided since R 2.4.0.  The interface consists of two
routines declared as

     void R_RegisterCCallable(const char *package, const char *name,
                              DL_FUNC fptr);
     DL_FUNC R_GetCCallable(const char *package, const char *name);

   A package *packA* that wants to make a C routine `myCfun' available
to C code in other packages would include the call

     R_RegisterCCallable("packA", "myCfun", myCfun);

   in its initialization function `R_init_packA'.  A package *packB*
that wants to use this routine would retrieve the function pointer with
a call of the form

     p_myCfun = R_GetCCallable("packA", "myCfun");

   The author of *packB* is responsible for ensuring that `p_myCfun'
has an appropriate declaration. In the future R may provide some
automated tools to simplify exporting larger numbers of routines.

   A package that wishes to make use of header files in other packages
needs to declare them as a comma-separated list in the field `LinkingTo'
in the `DESCRIPTION' file.  For example

     Depends: link2, link3
     LinkingTo: link2, link3

   It should also `Depend' on those packages for they have to be
installed prior to this one, and loaded prior to this one (so the path
to their compiled code can be found).

   This then arranges that the `include' directories in the installed
linked-to packages are added to the include paths for C and C++ code.

   A CRAN example of the use of this mechanism is package *lme4*, which
links to *Matrix*.


File: R-exts.info,  Node: Creating shared objects,  Next: Interfacing C++ code,  Prev: Registering native routines,  Up: System and foreign language interfaces

5.5 Creating shared objects
===========================

Shared objects for loading into R can be created using `R CMD SHLIB'.
This accepts as arguments a list of files which must be object files
(with extension `.o') or sources for C, C++, FORTRAN 77, Fortran 9x,
Objective C or Objective C++ (with extensions `.c', `.cc' or `.cpp' or
`.C', `.f', `.f90' or `.f95', `.m', and `.mm' or `.M', respectively), or
commands to be passed to the linker.  See `R CMD SHLIB --help' (or the
R help for `SHLIB') for usage information.

   If compiling the source files does not work "out of the box", you can
specify additional flags by setting some of the variables `PKG_CPPFLAGS'
(for the C preprocessor, typically `-I' flags), `PKG_CFLAGS',
`PKG_CXXFLAGS', `PKG_FFLAGS', `PKG_FCFLAGS', and `PKG_OBJCFLAGS' (for
the C, C++, FORTRAN 77, Fortran 9x, and Objective C compilers,
respectively) in the file `Makevars' in the compilation directory (or,
of course, create the object files directly from the command line).  Similarly,
variable `PKG_LIBS' in `Makevars' can be used for additional `-l' and
`-L' flags to be passed to the linker when building the shared object.
(Supplying linker commands as arguments to `R CMD SHLIB' will override
`PKG_LIBS' in `Makevars'.)

   It is possible to arrange to include compiled code from other
languages by setting the macro `OBJECTS' in file `Makevars', together
with suitable rules to make the objects.

   Flags which are already set (for example in file
`etcR_ARCH/Makeconf' on Unix-alikes) can be overridden by the
environment variable `MAKEFLAGS' (at least for systems using a
POSIX-compliant `make'), as in (Bourne shell syntax)

     MAKEFLAGS="CFLAGS=-O3" R CMD SHLIB *.c

   It is also possible to set such variables in personal `Makevars'
files, which are read after the local `Makevars' and the system
makefiles.  *Note Customizing package compilation: (R Installation and
Administration)Customizing package compilation,

   Note that as `R CMD SHLIB' uses Make, it will not remake a shared
object just because the flags have changed, and if `test.c' and
`test.f' both exist in the current directory

     R CMD SHLIB test.f

will compile `test.c'!

   If the `src' subdirectory of an add-on package contains source code
with one of the extensions listed above or a file `Makevars' but *not*
a file `Makefile', `R CMD INSTALL' creates a shared object (for loading
into R in the `.First.lib' or `.onLoad' function of the package) using
the `R CMD SHLIB' mechanism.  If file `Makevars' exists it is read
first, then the system makefile and then any personal `Makevars' files.

   If the `src' subdirectory of package contains a file `Makefile',
this is used by `R CMD INSTALL' in place of the `R CMD SHLIB'
mechanism.  `make' is called with makefiles
`R_HOME/etcR_ARCH/Makeconf', `src/Makefile' and any personal `Makevars'
files (in that order).  The first target found in `src/Makefile' is
used.

   It is better to make use of a `Makevars' file rather than a
`Makefile': the latter should be needed only exceptionally.

   Under Windows the same commands work, but `Makevars.win' will be
used in preference to `Makevars', and only `src/Makefile.win' will be
used by `R CMD INSTALL' with `src/Makefile' being ignored.  For details
of building DLLs with a variety of compilers, see file
`README.packages' and
`http://www.stats.uwo.ca/faculty/murdoch/software/compilingDLLs/' .
Under Windows you can supply an exports definitions file called
`DLLNAME-win.def': otherwise all entry points in objects (but not
libraries) supplied to `R CMD SHLIB' will be exported from the DLL.  An
example is `stats-win.def' for the *stats* package: a CRAN example in
package *fastICA*.

   If you feel tempted to read the source code and subvert these
mechanisms, please resist.  Far too much developer time has been wasted
in chasing down errors caused by failures to follow this documentation,
and even more by package authors demanding explanations as to why their
packages not longer work.  In particular, undocumented environment or
make variables are not for use by package writers and are subject to
change without notice.


File: R-exts.info,  Node: Interfacing C++ code,  Next: Fortran I/O,  Prev: Creating shared objects,  Up: System and foreign language interfaces

5.6 Interfacing C++ code
========================

Suppose we have the following hypothetical C++ library, consisting of
the two files `X.hh' and `X.cc', and implementing the two classes `X'
and `Y' which we want to use in R.

          // X.hh

          class X {
          public: X (); ~X ();
          };

          class Y {
          public: Y (); ~Y ();
          };

          // X.cc

          #include <iostream>
          #include "X.hh"

          static Y y;

          X::X()  { std::cout << "constructor X" << std::endl; }
          X::~X() { std::cout << "destructor X"  << std::endl; }
          Y::Y()  { std::cout << "constructor Y" << std::endl; }
          Y::~Y() { std::cout << "destructor Y"  << std::endl; }

   To use with R, the only thing we have to do is writing a wrapper
function and ensuring that the function is enclosed in

     extern "C" {

     }

   For example,

          // X_main.cc:

          #include "X.hh"

          extern "C" {

          void X_main () {
            X x;
          }

          } // extern "C"

   Compiling and linking should be done with the C++ compiler-linker
(rather than the C compiler-linker or the linker itself); otherwise, the
C++ initialization code (and hence the constructor of the static
variable `Y') are not called.  On a properly configured system, one can
simply use

     R CMD SHLIB X.cc X_main.cc

to create the shared object, typically `X.so' (the file name extension
may be different on your platform).  Now starting R yields

     R : Copyright 2000, The R Development Core Team
     Version 1.1.0 Under development (unstable) (April 14, 2000)
     ...
     Type    "q()" to quit R.

     R> dyn.load(paste("X", .Platform$dynlib.ext, sep = ""))
     constructor Y
     R> .C("X_main")
     constructor X
     destructor X
     list()
     R> q()
     Save workspace image? [y/n/c]: y
     destructor Y

   The R for Windows FAQ (`rw-FAQ') contains details of how to compile
this example under various Windows compilers.

   Using C++ iostreams, as in this example, is best avoided.  There is
no guarantee that the output will appear in the R console, and indeed it
will not on the R for Windows console.  Use R code or the C entry points
(*note Printing::) for all I/O if at all possible.

   Most R header files can be included within C++ programs, and they
should *not* be included within an `extern "C"' block (as they include
C++ system headers).  It may not be possible to include some R headers
as they in turn include C header files that may cause conflicts--if
this happens, define `NO_C_HEADERS' before including the R headers, and
include C++ versions (such as `cmath') of the appropriate headers
yourself before the R headers.


File: R-exts.info,  Node: Fortran I/O,  Next: Linking to other packages,  Prev: Interfacing C++ code,  Up: System and foreign language interfaces

5.7 Fortran I/O
===============

We have already warned against the use of C++ iostreams not least
because output is not guaranteed to appear on the R console, and this
warning applies equally to Fortran (77 or 9x) output to units `*' and
`6'. *Note Printing from FORTRAN::, which describes workarounds.

   In the past most Fortran compilers implemented I/O on top of the C
I/O system and so the two interworked successfully.  This was true of
`g77', but it is less true of `gfortran' as used in `gcc 4.y.z'.  In
particular, any package that makes use of Fortran I/O will when
compiled on Windows interfere with C I/O: when the Fortran I/O is
initialized (typically when the package is loaded) the C `stdout' and
`stderr' are switched to LF line endings.  (Function `La_Init' in file
`src/main/lapack.c' shows how to mitigate this.)  Even worse, prior to
R 2.6.2 using Fortran output when running under the Windows GUI console
(`Rgui') would hang the R session.  This is now avoided by ensuring
that the Fortran output is written to a file (`fort.6' in the working
directory).


File: R-exts.info,  Node: Linking to other packages,  Next: Handling R objects in C,  Prev: Fortran I/O,  Up: System and foreign language interfaces

5.8 Linking to other packages
=============================

It is not in general possible to link a DLL in package *packA* to a DLL
provided by package *packB* (for the security reasons mentioned in
*Note dyn.load and dyn.unload::, and also because some platforms
distinguish between shared and dynamic libraries), but it is on Windows.

   Note that there can be tricky versioning issues here, as package
*packB* could be re-installed after package *packA* -- it is desirable
that the API provided by package *packB* remains backwards-compatible.

* Menu:

* Unix-alikes::
* Windows::


File: R-exts.info,  Node: Unix-alikes,  Next: Windows,  Prev: Linking to other packages,  Up: Linking to other packages

5.8.1 Unix-alikes
-----------------

It is possible to link a shared object in package *packA* to a library
provided by package *packB* under limited circumstances on a Unix-alike
OS.  There are severe portability issues, so this is not recommended
for a distributed package.

   This is easiest if *packB* provides a static library
`packB/libs/libpackB.a'.  (This will need to be compiled with `PIC'
flags on platforms where it matters.)  Then as the code from package
*packB* is incorporated when package *packA* is installed, we only need
to find the static library at install time for package *packB*.  The
only issue is to find package *packB*, and for that we can ask R by
something like

     PKGB_PATH=`echo 'library(packB); cat(system.file("libs", package="packB"))' \
      | R --vanilla --slave`
     PKG_LIBS=$(PKGB_PATH)/libpackB.a

(If `libpackB.a' itself depends on other libraries these will need to
be included in `PKG_LIBS'.)

   For a dynamic library `packB/libs/libpackB.so'
(`packB/libs/libpackB.dylib' on Mac OS X) we could use

     PKGB_PATH=`echo 'library(packB); cat(system.file("libs", package="packB"))' \
      | R --vanilla --slave`
     PKG_LIBS=-L"$(PKGB_PATH)" -lpackB

This will work for installation, but very likely not when package
`packB' is loaded, as the path to package *packB*'s `libs' directory is
not in the `ld.so'(1)  search path.  You can arrange to put it there
*before* R is launched by setting (on some platforms) `LD_RUN_PATH' or
`LD_LIBRARY_PATH' or adding to the `ld.so' cache (see `man ldconfig').
On platforms that support it, the path to the dynamic library can be
hardcoded at install time (which assumes that the location of package
*packB* will not be changed).  On systems with the GNU linker (e.g.
Linux) and some others (e.g. Mac OS X) this can be done by

     PKGB_PATH=`echo 'library(packB); cat(system.file("libs", package="packB"))' \
      | R --vanilla --slave`
     PKG_LIBS=-L"$(PKGB_PATH)" -rpath "$(PKGB_PATH)" -lpackB

and on some other systems (e.g. Solaris with its native linker) use
`-R' rather than `-rpath'.

   It may be possible to figure out what is required semi-automatically
from the result of `R CMD libtool --config' (look for `hardcode').

   Making headers provided by package *packB* available to the code to
be compiled in package *packA* can be done by the `LinkingTo' mechanism
(*note Registering native routines::).

   ---------- Footnotes ----------

   (1) `dyld' on Mac OS X, and `DYLD_LIBRARY_PATHS' below.


File: R-exts.info,  Node: Windows,  Prev: Unix-alikes,  Up: Linking to other packages

5.8.2 Windows
-------------

Suppose package *packA* wants to make use of compiled code provided by
*packB* in DLL `packB/libs/exB.dll', possibly the package's DLL
`packB/libs/packB.dll'.  (This can be extended to linking to more than
one package in a similar way.)  There are three issues to be addressed:

   * Making headers provided by package *packB* available to the code to
     be compiled in package *packA*.

     This is done by the `LinkingTo' mechanism (*note Registering
     native routines::).

   * preparing `packA.dll' to link to `packB/libs/exB.dll'.

     This needs an entry in `Makevars.win' of the form

          PKG_LIBS= -L<something> -lexB

     and one possibility is that `<something>' is the path to the
     installed `pkgB/libs' directory.  To find that we need to ask R
     where it is by something like

          PKGB_PATH=`echo 'library(packB); cat(system.file("libs", package="packB"))' \
           | rterm --vanilla --slave`
          PKG_LIBS= -L"$(PKGB_PATH)" -lexB

     Another possibility is to use an import library, shipping with
     package *packA* an exports file `exB.def'.  Then `Makevars.win'
     could contain

          PKG_LIBS= -L. -lexB

          all: $(SHLIB) before

          before: libexB.dll.a
          libexB.dll.a: exB.def

     and then installing package *packA* will make and use the import
     library for `exB.dll'.  (One way to prepare the exports file is to
     use `pexports.exe'.)

   * loading `packA.dll' which depends on `exB.dll'.

     If `exB.dll' was used by package *packB* (because it is in fact
     `packB.dll' or `packB.dll' depends on it) and *packB* has been
     loaded before *packA*, then nothing more needs to be done as
     `exB.dll' will already be loaded into the R executable.  (This is
     the most common scenario).

     More generally, we can use the `DLLpath' argument to
     `library.dynam' to ensure that `exB.dll' is found, for example by
     setting

          library.dynam("packA", pkg, lib,
                        DLLpath = system.file("libs", package="packB"))

     Note that `DLLpath' can only set one path, and so for linking to
     two or more packages you would need to resort to setting `PATH'.



File: R-exts.info,  Node: Handling R objects in C,  Next: Interface functions .Call and .External,  Prev: Linking to other packages,  Up: System and foreign language interfaces

5.9 Handling R objects in C
===========================

Using C code to speed up the execution of an R function is often very
fruitful.  Traditionally this has been done _via_ the `.C' function in
R.  One restriction of this interface is that the R objects can not be
handled directly in C.  This becomes more troublesome when one wishes to
call R functions from within the C code.  There is a C function
provided called `call_R' (also known as `call_S' for compatibility with
S) that can do that, but it is cumbersome to use, and the mechanisms
documented here are usually simpler to use, as well as more powerful.

   If a user really wants to write C code using internal R data
structures, then that can be done using the `.Call' and `.External'
function.  The syntax for the calling function in R in each case is
similar to that of `.C', but the two functions have different C
interfaces.  Generally the `.Call' interface (which is modelled on the
interface of the same name in S version 4) is a little simpler to use,
but `.External' is a little more general.  

   A call to `.Call' is very similar to `.C', for example

     .Call("convolve2", a, b)

The first argument should be a character string giving a C symbol name
of code that has already been loaded into R.  Up to 65 R objects can
passed as arguments.  The C side of the interface is

     #include <R.h>
     #include <Rinternals.h>

     SEXP convolve2(SEXP a, SEXP b)
      ...

   A call to `.External' is almost identical

     .External("convolveE", a, b)

but the C side of the interface is different, having only one argument

     #include <R.h>
     #include <Rinternals.h>

     SEXP convolveE(SEXP args)
      ...

Here `args' is a `LISTSXP', a Lisp-style pairlist from which the
arguments can be extracted.

   In each case the R objects are available for manipulation _via_ a set
of functions and macros defined in the header file `Rinternals.h' or
some S4-compatibility macros defined in `Rdefines.h'.  See *Note
Interface functions .Call and .External:: for details on `.Call' and
`.External'.

   Before you decide to use `.Call' or `.External', you should look at
other alternatives.  First, consider working in interpreted R code; if
this is fast enough, this is normally the best option.  You should also
see if using `.C' is enough.  If the task to be performed in C is
simple enough requiring no call to R, `.C' suffices.  The new
interfaces are relatively recent additions to S and R, and a great deal
of useful code has been written using just `.C' before they were
available.  The `.Call' and `.External' interfaces allow much more
control, but they also impose much greater responsibilities so need to
be used with care.  Neither `.Call' nor `.External' copy their
arguments.  You should treat arguments you receive through these
interfaces as read-only.

   There are two approaches that can be taken to handling R objects from
within C code.  The first (historically) is to use the macros and
functions that have been used to implement the core parts of R through
`.Internal' calls.  A public(1)  subset of these is defined in the
header file `Rinternals.h' in the directory `R_INCLUDE_DIR' (default
`R_HOME/include') that should be available on any R installation.

   Another approach is to use R versions of the macros and functions
defined for the S version 4 interface `.Call', which are defined in the
header file `Rdefines.h'.  This is a somewhat simpler approach, and is
to be preferred if the code is intended to be shared with S.  However,
it is less well documented and even less tested.  Note too that some
idiomatic S4 constructions with these macros (such as assigning
elements of character vectors or lists) are invalid in R.

   A substantial amount of R is implemented using the functions and
macros described here, so the R source code provides a rich source of
examples and "how to do it": indeed many of the examples here were
developed by examining closely R system functions for similar tasks.
Do make use of the source code for inspirational examples.

   It is necessary to know something about how R objects are handled in
C code.  All the R objects you will deal with will be handled with the
type "SEXP"(2), which is a pointer to a structure with typedef
`SEXPREC'.  Think of this structure as a _variant type_ that can handle
all the usual types of R objects, that is vectors of various modes,
functions, environments, language objects and so on.  The details are
given later in this section and in *Note R Internal Structures:
(R-ints)R Internal Structures, but for most purposes the programmer
does not need to know them.  Think rather of a model such as that used
by Visual Basic, in which R objects are handed around in C code (as
they are in interpreted R code) as the variant type, and the
appropriate part is extracted for, for example, numerical calculations,
only when it is needed.  As in interpreted R code, much use is made of
coercion to force the variant object to the right type.

* Menu:

* Garbage Collection::
* Allocating storage::
* Details of R types::
* Attributes::
* Classes::
* Handling lists::
* Handling character data::
* Finding and setting variables::
* Some convenience functions::
* Named objects and copying::

   ---------- Footnotes ----------

   (1)  *note The R API::: note that these are not all part of the API.

   (2) SEXP is an acronym for _S_imple _EXP_ression, common in
LISP-like language syntaxes.


File: R-exts.info,  Node: Garbage Collection,  Next: Allocating storage,  Prev: Handling R objects in C,  Up: Handling R objects in C

5.9.1 Handling the effects of garbage collection
------------------------------------------------

We need to know a little about the way R handles memory allocation.
The memory allocated for R objects is not freed by the user; instead,
the memory is from time to time "garbage collected".  That is, some or
all of the allocated memory not being used is freed.

   The R object types are represented by a C structure defined by a
typedef `SEXPREC' in `Rinternals.h'.  It contains several things among
which are pointers to data blocks and to other `SEXPREC's.  A `SEXP' is
simply a pointer to a `SEXPREC'.

   If you create an R object in your C code, you must tell R that you
are using the object by using the `PROTECT' macro on a pointer to the
object. This tells R that the object is in use so it is not destroyed
during garbage collection.  Notice that it is the object which is
protected, not the pointer variable.  It is a common mistake to believe
that if you invoked `PROTECT(P)' at some point then P is protected from
then on, but that is not true once a new object is assigned to P.

   Protecting an R object automatically protects all the R objects
pointed to in the corresponding `SEXPREC', for example all elements of
a protected list are automatically protected.

   The programmer is solely responsible for housekeeping the calls to
`PROTECT'.  There is a corresponding macro `UNPROTECT' that takes as
argument an `int' giving the number of objects to unprotect when they
are no longer needed.  The protection mechanism is stack-based, so
`UNPROTECT(N)' unprotects the last N objects which were protected.  The
calls to `PROTECT' and `UNPROTECT' must balance when the user's code
returns.  R will warn about `"stack imbalance in .Call"' (or
`.External') if the housekeeping is wrong.

   Here is a small example of creating an R numeric vector in C code.
First we use the macros in `Rinternals.h':

     #include <R.h>
     #include <Rinternals.h>

       SEXP ab;
         ....
       PROTECT(ab = allocVector(REALSXP, 2));
       REAL(ab)[0] = 123.45;
       REAL(ab)[1] = 67.89;
       UNPROTECT(1);

and then those in `Rdefines.h':

     #include <R.h>
     #include <Rdefines.h>

       SEXP ab;
         ....
       PROTECT(ab = NEW_NUMERIC(2));
       NUMERIC_POINTER(ab)[0] = 123.45;
       NUMERIC_POINTER(ab)[1] = 67.89;
       UNPROTECT(1);

   Now, the reader may ask how the R object could possibly get removed
during those manipulations, as it is just our C code that is running.
As it happens, we can do without the protection in this example, but in
general we do not know (nor want to know) what is hiding behind the R
macros and functions we use, and any of them might cause memory to be
allocated, hence garbage collection and hence our object `ab' to be
removed. It is usually wise to err on the side of caution and assume
that any of the R macros and functions might remove the object.

   In some cases it is necessary to keep better track of whether
protection is really needed.  Be particularly aware of situations where
a large number of objects are generated.  The pointer protection stack
has a fixed size (default 10,000) and can become full.  It is not a
good idea then to just `PROTECT' everything in sight and `UNPROTECT'
several thousand objects at the end. It will almost invariably be
possible to either assign the objects as part of another object (which
automatically protects them) or unprotect them immediately after use.

   Protection is not needed for objects which R already knows are in
use.  In particular, this applies to function arguments.

   There is a less-used macro `UNPROTECT_PTR(S)' that unprotects the
object pointed to by the `SEXP' S, even if it is not the top item on
the pointer protection stack. This is rarely needed outside the parser
(the R sources have one example, in `src/main/plot3d.c').  

   Sometimes an object is changed (for example duplicated, coerced or
grown) yet the current value needs to be protected.  For these cases
`PROTECT_WITH_INDEX' saves an index of the protection location that can
be used to replace the protected value using `REPROTECT'.  For example
(from the internal code for `optim')

         PROTECT_INDEX ipx;

         ....
         PROTECT_WITH_INDEX(s = eval(OS->R_fcall, OS->R_env), &ipx);
         REPROTECT(s = coerceVector(s, REALSXP), ipx);


File: R-exts.info,  Node: Allocating storage,  Next: Details of R types,  Prev: Garbage Collection,  Up: Handling R objects in C

5.9.2 Allocating storage
------------------------

For many purposes it is sufficient to allocate R objects and manipulate
those.  There are quite a few `allocXXX' functions defined in
`Rinternals.h'--you may want to explore them.  These allocate R objects
of various types, and for the standard vector types there are
equivalent `NEW_XXX' macros defined in `Rdefines.h'.

   If storage is required for C objects during the calculations this is
best allocating by calling `R_alloc'; *note Memory allocation::.  All
of these memory allocation routines do their own error-checking, so the
programmer may assume that they will raise an error and not return if
the memory cannot be allocated.


File: R-exts.info,  Node: Details of R types,  Next: Attributes,  Prev: Allocating storage,  Up: Handling R objects in C

5.9.3 Details of R types
------------------------

Users of the `Rinternals.h' macros will need to know how the R types
are known internally: if the `Rdefines.h' macros are used then
S4-compatible names are used.

   The different R data types are represented in C by "SEXPTYPE".  Some
of these are familiar from R and some are internal data types.  The
usual R object modes are given in the table.

     SEXPTYPE   R equivalent
     ------------------------------------------------------- 
     `REALSXP'  numeric with storage mode `double'
     `INTSXP'   integer
     `CPLXSXP'  complex
     `LGLSXP'   logical
     `STRSXP'   character
     `VECSXP'   list (generic vector)
     `LISTSXP'  "dotted-pair" list
     `DOTSXP'   a `...' object
     `NILSXP'   NULL
     `SYMSXP'   name/symbol
     `CLOSXP'   function or function closure
     `ENVSXP'   environment

Among the important internal `SEXPTYPE's are `LANGSXP', `CHARSXP',
`PROMSXP', etc.  (*Note*: although it is possible to return objects of
internal types, it is unsafe to do so as assumptions are made about how
they are handled which may be violated at user-level evaluation.)  More
details are given in *Note R Internal Structures: (R-ints)R Internal
Structures.

   Unless you are very sure about the type of the arguments, the code
should check the data types.  Sometimes it may also be necessary to
check data types of objects created by evaluating an R expression in
the C code.  You can use functions like `isReal', `isInteger' and
`isString' to do type checking.  See the header file `Rinternals.h' for
definitions of other such functions.  All of these take a `SEXP' as
argument and return 1 or 0 to indicate TRUE or FALSE.  Once again there
are two ways to do this, and `Rdefines.h' has macros such as
`IS_NUMERIC'.

   What happens if the `SEXP' is not of the correct type?  Sometimes
you have no other option except to generate an error.  You can use the
function `error' for this.  It is usually better to coerce the object
to the correct type.  For example, if you find that an `SEXP' is of the
type `INTEGER', but you need a `REAL' object, you can change the type
by using, equivalently,

     PROTECT(NEWSEXP = coerceVector(OLDSEXP, REALSXP));

or

     PROTECT(NEWSEXP = AS_NUMERIC(OLDSEXP));

Protection is needed as a new _object_ is created; the object formerly
pointed to by the `SEXP' is still protected but now unused.

   All the coercion functions do their own error-checking, and generate
`NA's with a warning or stop with an error as appropriate.

   Note that these coercion functions are _not_ the same as calling
`as.numeric' (and so on) in R code, as they do not dispatch on the
class of the object.  Thus it is normally preferable to do the coercion
in the calling R code.

   So far we have only seen how to create and coerce R objects from C
code, and how to extract the numeric data from numeric R vectors.
These can suffice to take us a long way in interfacing R objects to
numerical algorithms, but we may need to know a little more to create
useful return objects.


File: R-exts.info,  Node: Attributes,  Next: Classes,  Prev: Details of R types,  Up: Handling R objects in C

5.9.4 Attributes
----------------

Many R objects have attributes: some of the most useful are classes and
the `dim' and `dimnames' that mark objects as matrices or arrays.  It
can also be helpful to work with the `names' attribute of vectors.

   To illustrate this, let us write code to take the outer product of
two vectors (which `outer' and `%o%' already do).  As usual the R code
is simple

     out <- function(x, y)
     {
        storage.mode(x) <- storage.mode(y) <- "double"
        .Call("out", x, y)
     }

where we expect `x' and `y' to be numeric vectors (possibly integer),
possibly with names.  This time we do the coercion in the calling R
code.

   C code to do the computations is

     #include <R.h>
     #include <Rinternals.h>

     SEXP out(SEXP x, SEXP y)
     {
       int i, j, nx, ny;
       double tmp, *rx = REAL(x), *ry = REAL(y), *rans;
       SEXP ans;

       nx = length(x); ny = length(y);
       PROTECT(ans = allocMatrix(REALSXP, nx, ny));
       rans = REAL(ans);
       for(i = 0; i < nx; i++) {
         tmp = rx[i];
         for(j = 0; j < ny; j++)
           rans[i + nx*j] = tmp * ry[j];
       }
       UNPROTECT(1);
       return(ans);
     }

Note the way `REAL' is used: as it is a function call it can be
considerably faster to store the result and index that.

   However, we would like to set the `dimnames' of the result.
Although `allocMatrix' provides a short cut, we will show how to set
the `dim' attribute directly.

     #include <R.h>
     #include <Rinternals.h>

     SEXP out(SEXP x, SEXP y)
     {
       R_len_t i, j, nx, ny;
       double tmp, *rx = REAL(x), *ry = REAL(y), *rans;
       SEXP ans, dim, dimnames;

       nx = length(x); ny = length(y);
       PROTECT(ans = allocVector(REALSXP, nx*ny));
       rans = REAL(ans);
       for(i = 0; i < nx; i++) {
         tmp = rx[i];
         for(j = 0; j < ny; j++)
           rans[i + nx*j] = tmp * ry[j];
       }

       PROTECT(dim = allocVector(INTSXP, 2));
       INTEGER(dim)[0] = nx; INTEGER(dim)[1] = ny;
       setAttrib(ans, R_DimSymbol, dim);

       PROTECT(dimnames = allocVector(VECSXP, 2));
       SET_VECTOR_ELT(dimnames, 0, getAttrib(x, R_NamesSymbol));
       SET_VECTOR_ELT(dimnames, 1, getAttrib(y, R_NamesSymbol));
       setAttrib(ans, R_DimNamesSymbol, dimnames);

       UNPROTECT(3);
       return(ans);
     }

   This example introduces several new features.  The `getAttrib' and
`setAttrib' functions get and set individual attributes.  Their second
argument is a `SEXP' defining the name in the symbol table of the
attribute we want; these and many such symbols are defined in the
header file `Rinternals.h'.

   There are shortcuts here too: the functions `namesgets', `dimgets'
and `dimnamesgets' are the internal versions of the default methods of
`names<-', `dim<-' and `dimnames<-' (for vectors and arrays), and there
are functions such as `GetMatrixDimnames' and `GetArrayDimnames'.

   What happens if we want to add an attribute that is not pre-defined?
We need to add a symbol for it _via_ a call to `install'.  Suppose for
illustration we wanted to add an attribute `"version"' with value
`3.0'.  We could use

       SEXP version;
       PROTECT(version = allocVector(REALSXP, 1));
       REAL(version)[0] = 3.0;
       setAttrib(ans, install("version"), version);
       UNPROTECT(1);

   Using `install' when it is not needed is harmless and provides a
simple way to retrieve the symbol from the symbol table if it is already
installed.


File: R-exts.info,  Node: Classes,  Next: Handling lists,  Prev: Attributes,  Up: Handling R objects in C

5.9.5 Classes
-------------

In R the (S3) class is just the attribute named `"class"' so it can be
handled as such, but there is a shortcut `classgets'.  Suppose we want
to give the return value in our example the class `"mat"'.  We can use

     #include <R.h>
     #include <Rdefines.h>
         ....
       SEXP ans, dim, dimnames, class;
         ....
       PROTECT(class = allocVector(STRSXP, 1));
       SET_STRING_ELT(class, 0, mkChar("mat"));
       classgets(ans, class);
       UNPROTECT(4);
       return(ans);
     }

As the value is a character vector, we have to know how to create that
from a C character array, which we do using the function `mkChar'.


File: R-exts.info,  Node: Handling lists,  Next: Handling character data,  Prev: Classes,  Up: Handling R objects in C

5.9.6 Handling lists
--------------------

Some care is needed with lists, as R moved early on from using
LISP-like lists (now called "pairlists") to S-like generic vectors.  As
a result, the appropriate test for an object of mode `list' is
`isNewList', and we need `allocVector(VECSXP, N') and _not_
`allocList(N)'.

   List elements can be retrieved or set by direct access to the
elements of the generic vector.  Suppose we have a list object

     a <- list(f=1, g=2, h=3)

Then we can access `a$g' as `a[[2]]' by

       double g;
         ....
       g = REAL(VECTOR_ELT(a, 1))[0];

   This can rapidly become tedious, and the following function (based on
one in package *stats*) is very useful:

     /* get the list element named str, or return NULL */

     SEXP getListElement(SEXP list, const char *str)
     {
       SEXP elmt = R_NilValue, names = getAttrib(list, R_NamesSymbol);
       int i;

       for (i = 0; i < length(list); i++)
         if(strcmp(CHAR(STRING_ELT(names, i)), str) == 0) {
           elmt = VECTOR_ELT(list, i);
           break;
         }
       return elmt;
     }

and enables us to say

       double g;
       g = REAL(getListElement(a, "g"))[0];


File: R-exts.info,  Node: Handling character data,  Next: Finding and setting variables,  Prev: Handling lists,  Up: Handling R objects in C

5.9.7 Handling character data
-----------------------------

R character vectors are stored as `STRSXP's, a vector type like
`VECSXP' where every element is of type `CHARSXP'.  The `CHARSXP'
elements of `STRSXP's are accessed using `STRING_ELT' and
`SET_STRING_ELT'.

   As of R 2.6.0, `CHARSXP's are read-only objects and must never be
modified.  In particular, the C-style string contained in a `CHARSXP'
should be treated as read-only and for this reason the `CHAR' function
used to access the character data of a `CHARSXP' returns `(const char
*)' (this also allows compilers to issue warnings about improper use).
Since `CHARSXP's are immutable, the same `CHARSXP' can be shared by any
`STRSXP' needing an element representing the same string.  As of R
2.6.0, R maintains a global cache of `CHARSXP's so that there is only
ever one `CHARSXP' representing a given string in memory.

   You can obtain a `CHARSXP' by calling `mkChar' and providing a
nul-terminated C-style string.  This function will return a pre-existing
`CHARSXP' if one with a matching string already exists, otherwise it
will create a new one and add it to the cache before returning it to
you.   The variant `mkCharLen' can be used to create a `CHARSXP' from
part of a buffer and will ensure null-termination.

   Currently, it is still possible to create `CHARSXP's using
`allocVector'; `CHARSXP's created in this way will not be captured by
the global `CHARSXP' cache and this should be avoided.  In the future,
all `CHARSXP's will be captured by the cache and this will allow
further optimizations, for example, replacing calls to `strcmp' with
pointer comparisons.  A helper macro, `CallocCharBuf', can be used to
obtain a temporary character buffer for in-place string manipulation:
this memory must be released using `Free'.


File: R-exts.info,  Node: Finding and setting variables,  Next: Some convenience functions,  Prev: Handling character data,  Up: Handling R objects in C

5.9.8 Finding and setting variables
-----------------------------------

It will be usual that all the R objects needed in our C computations
are passed as arguments to `.Call' or `.External', but it is possible
to find the values of R objects from within the C given their names.
The following code is the equivalent of `get(name, envir = rho)'.

     SEXP getvar(SEXP name, SEXP rho)
     {
       SEXP ans;

       if(!isString(name) || length(name) != 1)
         error("name is not a single string");
       if(!isEnvironment(rho))
         error("rho should be an environment");
       ans = findVar(install(CHAR(STRING_ELT(name, 0))), rho);
       Rprintf("first value is %f\n", REAL(ans)[0]);
       return(R_NilValue);
     }

   The main work is done by `findVar', but to use it we need to install
`name' as a name in the symbol table.  As we wanted the value for
internal use, we return `NULL'.

   Similar functions with syntax

     void defineVar(SEXP symbol, SEXP value, SEXP rho)
     void setVar(SEXP symbol, SEXP value, SEXP rho)

can be used to assign values to R variables.  `defineVar' creates a new
binding or changes the value of an existing binding in the specified
environment frame; it is the analogue of `assign(symbol, value, envir =
rho, inherits = FALSE)', but unlike `assign', `defineVar' does not make
a copy of the object `value'.(1)  `setVar' searches for an existing
binding for `symbol' in `rho' or its enclosing environments.  If a
binding is found, its value is changed to `value'.  Otherwise, a new
binding with the specified value is created in the global environment.
This corresponds to `assign(symbol, value, envir = rho, inherits =
TRUE)'.

   ---------- Footnotes ----------

   (1) You can assign a _copy_ of the object in the environment frame
`rho' using `defineVar(symbol, duplicate(value), rho)').


File: R-exts.info,  Node: Some convenience functions,  Next: Named objects and copying,  Prev: Finding and setting variables,  Up: Handling R objects in C

5.9.9 Some convenience functions
--------------------------------

Some operations are done so frequently that there are convenience
functions to handle them.  Suppose we wanted to pass a single logical
argument `ignore_quotes': we could use

         int ign;

         ign = asLogical(ignore_quotes);
         if(ign == NA_LOGICAL) error("'ignore_quotes' must be TRUE or FALSE");

which will do any coercion needed (at least from a vector argument), and
return `NA_LOGICAL' if the value passed was `NA' or coercion failed.
There are also `asInteger', `asReal' and `asComplex'.  The function
`asChar' returns a `CHARSXP'.  All of these functions ignore any
elements of an input vector after the first.

   To return a length-one real vector we can use

         double x;

         ...
         return ScalarReal(x);

and there are versions of this for all the atomic vector types (those
for a length-one character vector being `ScalarString' with argument a
`CHARSXP' and `mkString' with argument `const char *').

   Some of the `isXXXX' functions differ from their apparent R-level
counterparts: for example `isVector' is true for any atomic vector type
(`isVectorAtomic') and for lists and expressions (`isVectorList') (with
no check on attributes).  `isMatrix' is a test of a length-2 `"dim"'
attribute.

   There are a series of small macros/functions to help construct
pairlists and language objects (whose internal structures just differ by
`SEXPTYPE').  Function `CONS(u, v)' is the basic building block: is
constructs a pairlist from `u' followed by `v' (which is a pairlist or
`R_NilValue').  `LCONS' is a variant that constructs a language object.
Functions `list1' to `list4' construct a pairlist from one to four
items, and `lang1' to `lang4' do the same for a language object (a
function to call plus zero to three arguments).  Functions `elt' and
`lastElt' find the Ith element and the last element of a pairlist, and
`nthcdr' returns a pointer to the Nth position in the pairlist (whose
`CAR' is the Nth item).

   Functions `str2type' and `type2str' map R length-one character
strings to and from `SEXPTYPE' numbers, and `type2char' maps numbers to
C character strings.


File: R-exts.info,  Node: Named objects and copying,  Prev: Some convenience functions,  Up: Handling R objects in C

5.9.10 Named objects and copying
--------------------------------

When assignments are done in R such as

     x <- 1:10
     y <- x

the named object is not necessarily copied, so after those two
assignments `y' and `x' are bound to the same `SEXPREC' (the structure
a `SEXP' points to).  This means that any code which alters one of them
has to make a copy before modifying the copy if the usual R semantics
are to apply.  Note that whereas `.C' and `.Fortran' do copy their
arguments (unless the dangerous `dup = FALSE' is used), `.Call' and
`.External' do not.  So `duplicate' is commonly called on arguments to
`.Call' before modifying them.

   However, at least some of this copying is unneeded.  In the first
assignment shown, `x <- 1:10', R first creates an object with value
`1:10' and then assigns it to `x' but if `x' is modified no copy is
necessary as the temporary object with value `1:10' cannot be referred
to again.  R distinguishes between named and unnamed objects _via_ a
field in a `SEXPREC' that can be accessed _via_ the macros `NAMED' and
`SET_NAMED'.  This can take values

`0'
     The object is not bound to any symbol

`1'
     The object has been bound to exactly one symbol

`2'
     The object has potentially been bound to two or more symbols, and
     one should act as if another variable is currently bound to this
     value.

Note the past tenses: R does not do full reference counting and there
may currently be fewer bindings.

   It is safe to modify the value of any `SEXP' for which `NAMED(foo)'
is zero, and if `NAMED(foo)' is two, the value should be duplicated
(_via_ a call to `duplicate') before any modification.  Note that it is
the responsibility of the author of the code making the modification to
do the duplication, even if it is `x' whose value is being modified
after `y <- x'.

   The case `NAMED(foo) == 1' allows some optimization, but it can be
ignored (and duplication done whenever `NAMED(foo) > 0').  (This
optimization is not currently usable in user code.)  It is intended for
use within assignment functions.  Suppose we used

     x <- 1:10
     foo(x) <- 3

which is computed as

     x <- 1:10
     x <- "foo<-"(x, 3)

Then inside `"foo<-"' the object pointing to the current value of `x'
will have `NAMED(foo)' as one, and it would be safe to modify it as the
only symbol bound to it is `x' and that will be rebound immediately.
(Provided the remaining code in `"foo<-"' make no reference to `x', and
no one is going to attempt a direct call such as `y <- "foo<-"(x)'.)

   Currently all arguments to a `.Call' call will have `NAMED' set to
2, and so users must assume that they need to be duplicated before
alteration.


File: R-exts.info,  Node: Interface functions .Call and .External,  Next: Evaluating R expressions from C,  Prev: Handling R objects in C,  Up: System and foreign language interfaces

5.10 Interface functions `.Call' and `.External'
================================================

In this section we consider the details of the R/C interfaces.

   These two interfaces have almost the same functionality. `.Call' is
based on the interface of the same name in S version 4, and `.External'
is based on `.Internal'.  `.External' is more complex but allows a
variable number of arguments.

* Menu:

* Calling .Call::
* Calling .External::
* Missing and special values::


File: R-exts.info,  Node: Calling .Call,  Next: Calling .External,  Prev: Interface functions .Call and .External,  Up: Interface functions .Call and .External

5.10.1 Calling `.Call'
----------------------

Let us convert our finite convolution example to use `.Call', first
using the `Rdefines.h' macros.  The calling function in R is

     conv <- function(a, b) .Call("convolve2", a, b)

which could hardly be simpler, but as we shall see all the type checking
must be transferred to the C code, which is

     #include <R.h>
     #include <Rdefines.h>

     SEXP convolve2(SEXP a, SEXP b)
     {
       int i, j, na, nb, nab;
       double *xa, *xb, *xab;
       SEXP ab;

       PROTECT(a = AS_NUMERIC(a));
       PROTECT(b = AS_NUMERIC(b));
       na = LENGTH(a); nb = LENGTH(b); nab = na + nb - 1;
       PROTECT(ab = NEW_NUMERIC(nab));
       xa = NUMERIC_POINTER(a); xb = NUMERIC_POINTER(b);
       xab = NUMERIC_POINTER(ab);
       for(i = 0; i < nab; i++) xab[i] = 0.0;
       for(i = 0; i < na; i++)
         for(j = 0; j < nb; j++) xab[i + j] += xa[i] * xb[j];
       UNPROTECT(3);
       return(ab);
     }

   Note that unlike the macros in S version 4, the R versions of these
macros do check that coercion can be done and raise an error if it
fails.  They will raise warnings if missing values are introduced by
coercion.  Although we illustrate doing the coercion in the C code here,
it often is simpler to do the necessary coercions in the R code.

   Now for the version in R-internal style.  Only the C code changes.

     #include <R.h>
     #include <Rinternals.h>

     SEXP convolve2(SEXP a, SEXP b)
     {
       R_len_t i, j, na, nb, nab;
       double *xa, *xb, *xab;
       SEXP ab;

       PROTECT(a = coerceVector(a, REALSXP));
       PROTECT(b = coerceVector(b, REALSXP));
       na = length(a); nb = length(b); nab = na + nb - 1;
       PROTECT(ab = allocVector(REALSXP, nab));
       xa = REAL(a); xb = REAL(b);
       xab = REAL(ab);
       for(i = 0; i < nab; i++) xab[i] = 0.0;
       for(i = 0; i < na; i++)
         for(j = 0; j < nb; j++) xab[i + j] += xa[i] * xb[j];
       UNPROTECT(3);
       return(ab);
     }

This is called in exactly the same way.


File: R-exts.info,  Node: Calling .External,  Next: Missing and special values,  Prev: Calling .Call,  Up: Interface functions .Call and .External

5.10.2 Calling `.External'
--------------------------

We can use the same example to illustrate `.External'.  The R code
changes only by replacing `.Call' by `.External'

     conv <- function(a, b) .External("convolveE", a, b)

but the main change is how the arguments are passed to the C code, this
time as a single SEXP.  The only change to the C code is how we handle
the arguments.

     #include <R.h>
     #include <Rinternals.h>

     SEXP convolveE(SEXP args)
     {
       int i, j, na, nb, nab;
       double *xa, *xb, *xab;
       SEXP a, b, ab;

       PROTECT(a = coerceVector(CADR(args), REALSXP));
       PROTECT(b = coerceVector(CADDR(args), REALSXP));
         ...
     }

Once again we do not need to protect the arguments, as in the R side of
the interface they are objects that are already in use.  The macros

       first = CADR(args);
       second = CADDR(args);
       third = CADDDR(args);
       fourth = CAD4R(args);

provide convenient ways to access the first four arguments.  More
generally we can use the `CDR' and `CAR' macros as in

       args = CDR(args); a = CAR(args);
       args = CDR(args); b = CAR(args);

which clearly allows us to extract an unlimited number of arguments
(whereas `.Call' has a limit, albeit at 65 not a small one).

   More usefully, the `.External' interface provides an easy way to
handle calls with a variable number of arguments, as `length(args)'
will give the number of arguments supplied (of which the first is
ignored).  We may need to know the names (`tags') given to the actual
arguments, which we can by using the `TAG' macro and using something
like the following example, that prints the names and the first value
of its arguments if they are vector types.

     #include <R_ext/PrtUtil.h>

     SEXP showArgs(SEXP args)
     {
       int i, nargs;
       Rcomplex cpl;
       const char *name;
       SEXP el;

       args = CDR(args); /* skip 'name' */
       for(i = 0; args != R_NilValue; i++, args = CDR(args)) {
         args = CDR(args);
         name = CHAR(PRINTNAME(TAG(args)));
         switch(TYPEOF(CAR(args))) {
         case REALSXP:
           Rprintf("[%d] '%s' %f\n", i+1, name, REAL(CAR(args))[0]);
           break;
         case LGLSXP:
         case INTSXP:
           Rprintf("[%d] '%s' %d\n", i+1, name, INTEGER(CAR(args))[0]);
           break;
         case CPLXSXP:
           cpl = COMPLEX(CAR(args))[0];
           Rprintf("[%d] '%s' %f + %fi\n", i+1, name, cpl.r, cpl.i);
           break;
         case STRSXP:
           Rprintf("[%d] '%s' %s\n", i+1, name,
                  CHAR(STRING_ELT(CAR(args), 0)));
           break;
         default:
           Rprintf("[%d] '%s' R type\n", i+1, name);
         }
       }
       return(R_NilValue);
     }

   This can be called by the wrapper function

     showArgs <- function(...) .External("showArgs", ...)

Note that this style of programming is convenient but not necessary, as
an alternative style is

     showArgs1 <- function(...) .Call("showArgs1", list(...))

The (very similar) C code is in the scripts.


File: R-exts.info,  Node: Missing and special values,  Prev: Calling .External,  Up: Interface functions .Call and .External

5.10.3 Missing and special values
---------------------------------

One piece of error-checking the `.C' call does (unless `NAOK' is true)
is to check for missing (`NA') and IEEE special values (`Inf', `-Inf'
and `NaN') and give an error if any are found.  With the `.Call'
interface these will be passed to our code.  In this example the
special values are no problem, as IEEE arithmetic will handle them
correctly.  In the current implementation this is also true of `NA' as
it is a type of `NaN', but it is unwise to rely on such details.  Thus
we will re-write the code to handle `NA's using macros defined in
`R_exts/Arith.h' included by `R.h'.

   The code changes are the same in any of the versions of `convolve2'
or `convolveE':

         ...
       for(i = 0; i < na; i++)
         for(j = 0; j < nb; j++)
             if(ISNA(xa[i]) || ISNA(xb[j]) || ISNA(xab[i + j]))
               xab[i + j] = NA_REAL;
             else
               xab[i + j] += xa[i] * xb[j];
         ...

   Note that the `ISNA' macro, and the similar macros `ISNAN' (which
checks for `NaN' or `NA') and `R_FINITE' (which is false for `NA' and
all the special values), only apply to numeric values of type `double'.
Missingness of integers, logicals and character strings can be tested
by equality to the constants `NA_INTEGER', `NA_LOGICAL' and
`NA_STRING'.  These and `NA_REAL' can be used to set elements of R
vectors to `NA'.

   The constants `R_NaN', `R_PosInf', `R_NegInf' and `R_NaReal' can be
used to set `double's to the special values.


File: R-exts.info,  Node: Evaluating R expressions from C,  Next: Parsing R code from C,  Prev: Interface functions .Call and .External,  Up: System and foreign language interfaces

5.11 Evaluating R expressions from C
====================================

We noted that the `call_R' interface could be used to evaluate R
expressions from C code, but the current interfaces are much more
convenient to use.  The main function we will use is

     SEXP eval(SEXP expr, SEXP rho);

the equivalent of the interpreted R code `eval(expr, envir = rho)',
although we can also make use of `findVar', `defineVar' and `findFun'
(which restricts the search to functions).

   To see how this might be applied, here is a simplified internal
version of `lapply' for expressions, used as

     a <- list(a = 1:5, b = rnorm(10), test = runif(100))
     .Call("lapply", a, quote(sum(x)), new.env())

with C code

     SEXP lapply(SEXP list, SEXP expr, SEXP rho)
     {
       R_len_t i, n = length(list);
       SEXP ans;

       if(!isNewList(list)) error("'list' must be a list");
       if(!isEnvironment(rho)) error("'rho' should be an environment");
       PROTECT(ans = allocVector(VECSXP, n));
       for(i = 0; i < n; i++) {
         defineVar(install("x"), VECTOR_ELT(list, i), rho);
         SET_VECTOR_ELT(ans, i, eval(expr, rho));
       }
       setAttrib(ans, R_NamesSymbol, getAttrib(list, R_NamesSymbol));
       UNPROTECT(1);
       return(ans);
     }

   It would be closer to `lapply' if we could pass in a function rather
than an expression.  One way to do this is _via_ interpreted R code as
in the next example, but it is possible (if somewhat obscure) to do
this in C code.  The following is based on the code in
`src/main/optimize.c'.

     SEXP lapply2(SEXP list, SEXP fn, SEXP rho)
     {
       R_len_t i, n = length(list);
       SEXP R_fcall, ans;

       if(!isNewList(list)) error("'list' must be a list");
       if(!isFunction(fn)) error("'fn' must be a function");
       if(!isEnvironment(rho)) error("'rho' should be an environment");
       PROTECT(R_fcall = lang2(fn, R_NilValue));
       PROTECT(ans = allocVector(VECSXP, n));
       for(i = 0; i < n; i++) {
         SETCADR(R_fcall, VECTOR_ELT(list, i));
         SET_VECTOR_ELT(ans, i, eval(R_fcall, rho));
       }
       setAttrib(ans, R_NamesSymbol, getAttrib(list, R_NamesSymbol));
       UNPROTECT(2);
       return(ans);
     }

used by

     .Call("lapply2", a, sum, new.env())

Function `lang2' creates an executable pairlist of two elements, but
this will only be clear to those with a knowledge of a LISP-like
language.

   As a more comprehensive example of constructing an R call in C code
and evaluating, consider the following fragment of `printAttributes' in
`src/main/print.c'.

         /* Need to construct a call to
            print(CAR(a), digits=digits)
            based on the R_print structure, then eval(call, env).
            See do_docall for the template for this sort of thing.
         */
         SEXP s, t;
         PROTECT(t = s = allocList(3));
         SET_TYPEOF(s, LANGSXP);
         SETCAR(t, install("print")); t = CDR(t);
         SETCAR(t,  CAR(a)); t = CDR(t);
         SETCAR(t, ScalarInteger(digits));
         SET_TAG(t, install("digits"));
         eval(s, env);
         UNPROTECT(1);

At this point `CAR(a)' is the R object to be printed, the current
attribute.  There are three steps: the call is constructed as a
pairlist of length 3, the list is filled in, and the expression
represented by the pairlist is evaluated.

   A pairlist is quite distinct from a generic vector list, the only
user-visible form of list in R.  A pairlist is a linked list (with
`CDR(t)' computing the next entry), with items (accessed by `CAR(t)')
and names or tags (set by `SET_TAG').  In this call there are to be
three items, a symbol (pointing to the function to be called) and two
argument values, the first unnamed and the second named.  Setting the
type to `LANGSXP' makes this a call which can be evaluated.

* Menu:

* Zero-finding::
* Calculating numerical derivatives::


File: R-exts.info,  Node: Zero-finding,  Next: Calculating numerical derivatives,  Prev: Evaluating R expressions from C,  Up: Evaluating R expressions from C

5.11.1 Zero-finding
-------------------

In this section we re-work the example of `call_S' in Becker, Chambers
& Wilks (1988) on finding a zero of a univariate function, The R code
and an example are

     zero <- function(f, guesses, tol = 1e-7) {
       f.check <- function(x) {
         x <- f(x)
         if(!is.numeric(x)) stop("Need a numeric result")
         as.double(x)
       }
       .Call("zero", body(f.check), as.double(guesses), as.double(tol),
             new.env())
     }

     cube1 <- function(x) (x^2 + 1) * (x - 1.5)
     zero(cube1, c(0, 5))

where this time we do the coercion and error-checking in the R code.
The C code is

     SEXP mkans(double x)
     {
         SEXP ans;
         PROTECT(ans = allocVector(REALSXP, 1));
         REAL(ans)[0] = x;
         UNPROTECT(1);
         return ans;
     }

     double feval(double x, SEXP f, SEXP rho)
     {
         defineVar(install("x"), mkans(x), rho);
         return(REAL(eval(f, rho))[0]);
     }

     SEXP zero(SEXP f, SEXP guesses, SEXP stol, SEXP rho)
     {
         double x0 = REAL(guesses)[0], x1 = REAL(guesses)[1],
                tol = REAL(stol)[0];
         double f0, f1, fc, xc;

         if(tol <= 0.0) error("non-positive tol value");
         f0 = feval(x0, f, rho); f1 = feval(x1, f, rho);
         if(f0 == 0.0) return mkans(x0);
         if(f1 == 0.0) return mkans(x1);
         if(f0*f1 > 0.0) error("x[0] and x[1] have the same sign");

         for(;;) {
             xc = 0.5*(x0+x1);
             if(fabs(x0-x1) < tol) return  mkans(xc);
             fc = feval(xc, f, rho);
             if(fc == 0) return  mkans(xc);
             if(f0*fc > 0.0) {
                 x0 = xc; f0 = fc;
             } else {
                 x1 = xc; f1 = fc;
             }
         }
     }

The C code is essentially unchanged from the `call_R' version, just
using a couple of functions to convert from `double' to `SEXP' and to
evaluate `f.check'.



Local Variables:
coding: iso-8859-1
End:
